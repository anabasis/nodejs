# Convert log data to metrics

## Convert event logs to metric data points

Metrics are often buried in unstructured or semi-structured log data. The Splunk platform can automatically convert log data to metrics data points and then insert that data into a metrics index that you specify. It can perform this conversion when your log data is ingested into your Splunk platform deployment, or when you run a search on the log data with the mcollect or meventcollect commands.

This functionality follows older features for the Splunk platform that enable the extraction of fields from events at ingest time and search time. When you set up a log-to-metrics conversion, you look at the field-value pairs that are pulled out of your unstructured events and identify the fields with numeric values that the search head can transform into measurements.

You can optionally identify extracted fields for the Splunk platform to blacklist so they do not appear in the metric data points.

Extracted fields in your events that you have not identified as measurements or blacklisted fields are added by the search head to metric data points as dimensions.

>> Certain log-to-metrics feature extensions, such as the ability to create log-to-metric configurations that automatically process numeric fields as measures, can only be managed through manual configuration file edits or REST API operations.

### Conversion of events into metric data points with multiple measurements

Here are two log events that contain metrics data. Both of these events have the internaldata source type.

|_time|Event|
|:--:|:--:|
|08-05-2017 20:26:29.073 -0700|INFO Metrics - group=queue, name=aeq, max_size_kb=500, current_size_kb=300, current_size=53|
|08-05-2017 20:26:29.075 -0700|INFO Metrics - group=queue, name=indexqueue, max_size_kb=500, current_size_kb=200, current_size=55|

After you set up the log-to-metrics configuration, the Splunk platform runs a process that extracts field-value pairs from events with the internaldata source type. It converts the numeric fields into measurement fields that follow this syntax: metric_name:<metric name>=<value>. It treats the remaining fields (group and name) as dimensions.

|_time|group|name|metric_name:max_size_kb|metric_name:current_size_kb|metric_name:current_size|
|:--:|:--:|:--:|:--:|:--:|:--:|
|08-05-2017 20:26:29.073 -0700|queue|aeq|500|300|53|
|08-05-2017 20:26:29.075 -0700|queue|indexqueue|500|200|55|

### Anatomy of a log-to-metrics metric data point

Each metric data point contains a _time field and one or more measurement fields. Metric data points can also have one or more dimension fields. Learn more about metric data points in Overview of metrics.

The following table explains how the log-to-metrics process derives the values of each metric data point field:

|Metric field|Example|Origin of value|
|:--:|:--:|:--|
|_time|08-05-2017 20:26:29.075 -0700|Uses the _time value from the original event. If multiple metric data points are generated from a single event, they all share the same _time value.|
|measurement field|metric_name:current_size=53|Transforms a field with a numeric value into a measurement field with this syntax: metric_name:<metric_name>=<numeric_value>.|
|metric_name|current_size|Uses the name of the field that provides the numeric_value for the measurement. In this case, the measurement is based on current_size=53.|
|numeric_value|53|Uses the value of the numeric field that the measurement is based on. In this case, the measurement is based on current_size=85.|
|dimension field|group=queue, name=indexqueue|Any fields in a log event besides _time that are not otherwise identified as measurement fields or blacklisted fields become dimension fields. All metric data points generated from the same log event share the same timestamps and dimension field-value pairs.|

### Set up basic ingest-time log-to-metric conversions through Splunk Web

Use Splunk Web to set up ingest-time conversion of logs to metric data points when all of the events in the log being ingested share the same fields.

There are two stages to the Splunk Web process for setting up log-to-metrics conversion:

1. Create a new source type of the Log to Metrics category on the Source Types listing page in Settings.
2. Associate that Log to Metrics source type with an appropriate log data input when you create or edit the input.
For more information, see Set up ingest-time log-to-metrics conversion in Splunk Web.

### Create sophisticated ingest-time log-to-metric conversions with props.conf and transforms.conf

Manually create configurations in transforms.conf and props.conf for ingest-time conversion of logs to metric data points when the events in the log being ingested have different sets of measurement fields. For example, you can design configurations that sort events by the values of a shared field and then apply specific log-to-metric conversion rules to each of those event groups.

For more information, see Set up ingest-time log-to-metrics conversion with configuration files.

### Numeric fields that are never converted to metric measures

Certain numeric field names are reserved. The Splunk software cannot convert indexed fields with these names to metric measures. If you use these names for your indexed measure fields, you should arrange to have them renamed before they undergo log-to-metric processing. Such renaming will require changes to your transforms.conf configurations.

This is the list of reserved field names:

- _event_status
- _indextime
- _subsecond
- _value
- date_hour
- date_mday
- date_minute
- date_month
- date_second
- date_wday
- date_year
- date_zone
- linecount
- timeendpos
- timestartpos
- metric_timestamp
- punct
- time
- timestamp

## Set up ingest-time log-to-metrics conversion in Splunk Web

You can set up ingest-time log-to-metrics conversion through Splunk Web. You might want log-to-metrics conversion to take place at ingest time if you want the Splunk platform to preserve the metric data points that result from the conversion in a specific metrics index.

Complete the following two tasks to set up log-to-metrics conversion at ingest time:

- Create a source type in the Log to Metrics category.
- Apply this source type to a log data input.

>> To use this functionality, your role must have the edit_metric_schema capability. If your role does not have it, and you need to set up ingest-time logs-to-metrics conversion through Splunk Web, contact your Splunk administrator.

### Know your log data

Creation of a Log to Metrics source type requires you to have basic knowledge about the log data that you wish to convert into metric data points. You need to know the fields in your log data and the categories that those fields fit into.

|Field category|Description|
|:--:|:--|
|Measurement|A field that provides the numeric value for a specific metric. A single metric data point can contain mulitiple measurements.|
|Dimension|A field that provides additional metadata for a metric data point. The Splunk platform counts as dimensions any fields it extracts from a log event that you have not already identified as measurements or blacklist fields. A single metric data point can contain multiple dimensions.|
|Blacklisted field|A field in a log event that does not appear in the metric data point generated from that event. High-cardinality fields that are unimportant for the purposes of metric data point collection are good candidates for field blacklisting.|

For example, say you have an event with a timestamp and the following five fields: max_kb, min_kb, server_model, group, and division. If you identify max_kb and min_kb as measurements, and you identify group and division as blacklist fields, the Splunk platform generates one metric data point that has metric_name:max_kb and metric_name:min_kb as measurements and server_model as a dimension field.

### Create a Log to Metrics source type

You can create a source type in the Log to Metrics category with the Source Types listing page in Settings.

Prerequisites

- See Convert event logs to metric data points
- See Manage source types in Getting Data In for a full overview of the Source Types listing page and the process for adding a new source type.

Steps

1. Select Settings > Source types to open the Source Types listing page.
2. Click New Source Type to open the Create Source Type dialog.
3. Enter a Name for your new source type.
4. (Optional) Enter a source type Description for your new source type. Select a 1. different Destination app if necessary.
5. Select Category > Log to Metrics.
6. Select an appropriate Indexed Extractions value for your data.

For example, if you are working with structured CSV- or JSON-formatted data, select csv or json, as appropriate. Use field_extraction if your data is technically unstructured but its events are strings of field-value pairs.

If you select field_extraction the Splunk software automatically adds WRITE_META=true to the transforms.conf stanza for the field extraction. See How the Splunk software builds indexed fields in Getting Data In.
7. (Optional) Change the settings on the Event Breaks, Timestamp, and Advanced tabs as necessary for your log data.
8. Click on the Metrics tab to reveal the Log to Metrics source type settings.

<table>

<tr><td>Text box label</td><td>Optional?</td><td>Description</td></tr>
<tr><td>Measures</td><td>No</td><td>Enter one or more comma-separated names of numeric measurement fields from the event data associated with the selected source type. The Splunk platform transforms each listed field into a measurement with a metric_name:<metric_name>::&lt;numeric_value&gt; syntax and then puts those measurements into the finished metric data point.

You can use the wildcard character (*) to match multiple numeric measurement fields in your event data. For example, if your events contain max_size_kb, min_size_kb, and current_size_kb, you can include *_size_kb in the set of dimension field names. This adds all three fields to the set of measures.

Alternatively, if you want the Splunk platform to treat all numeric fields in your event data as measures, just enter _ALLNUMS_ in the Measures field.

If you want the Splunk platform to treat all but some numeric fields in your event data as measures, enter _NUMS_EXCEPT_ in the Measures field. Follow it with a space and then a comma-separated list of numeric fields from your event data that you do not want to extract as measures. These fields will instead be extracted as dimensions.</td></tr>
<tr><td>Blacklist</td><td>Yes</td><td>Enter one or more comma-separated names of dimension fields that you want to blacklist from the metric data points generated from the log events associated with this source type. You might want to blacklist high-cardinality dimension fields that are unnecessary for your metric collection.

You can use the wildcard character (*) to match multiple dimension field values in your event data. For example, if your event data contains customer_id, employee_id, and consultant_id as dimensions and you want to blacklist all of them, you can add *_id to the set of dimension field names, and this will add all three dimensions to the blacklist.</td></tr>
</table>

9. Click Save.

### Apply a Log to Metrics source type to the data from an uploaded file or directory

After you create a source type in the Log to Metrics category, you can use the Set Source Type step of the Add Data workflow to apply the source type to data inputs that specify a single file as a source of data. When you set Log to Metric category source types to such inputs, a Metrics drop-down tab appears in the left pane of the Set Source Type page. Use this tab to enter or update lists of measures and blacklist dimensions for the source type.

The Add Data workflow is documented in full detail in Getting Data In.

Prerequisites

- See Overview of log-to-metrics functionality.
- See Create a Log to Metrics source type.
- See Monitor files and directories with Splunk Web in Getting Data In to review the Add Data workflow for inputs that specify a single file as a source of data.
- See The Set Sourcetype page in Getting Data In for an overview of the Set Source Type step of the Add Data workflow.

Steps

1. Follow the Add Data workflow for uploading or monitoring a file or directory until you get to the Select Source Type page.
2. On the Select Source Type page, select Source type > Log to Metrics and choose an appropriate source type from the list.
When you select a Log to Metrics source type, the right-hand preview panel does not populate with a preview of the metrics data. You can see a preview for other source types.
3. (Optional) Open the Event Breaks, Timestamp, and Advanced drop-down tabs and update their settings as necessary for your data input.
4. (Optional) Open the Metrics drop-down tab to enter or update field lists in the Measures and Blacklist text boxes. Measures requires at least one field.

<table>
<tr><td>Text box label</td><td>Description</td></tr>
<tr><td>Measures</td><td>Review the entry in this text box and update it if neccessary. It can contain a comma-separated list of numeric measurement fields from the event data that matches the selected source type. The Splunk platform transforms each listed field into a measurement with a metric_name:&lt;metric_name&gt;::&lt;numeric_value&gt; syntax and then puts those measurements into the finished metric data point.

You can use the wildcard character (*) to match multiple numeric measurement fields in your event data. For example, if your events contain max_size_kb, min_size_kb, and current_size_kb, you can include *_size_kb in the set of dimension field names. This adds all three fields to the set of measures.

It can contain just the term _ALLNUMS_. This tells the Splunk platform to transform all of the numeric fields in your event data into measures.

Or it can contain the term _NUMS_EXCEPT_ followed by a space and a comma-separated list of numeric measurement fields. This tells the Splunk platform to convert all numeric fields in your event data into measurements except for the listed fields, which are instead extracted as dimensions.</td></tr>
<tr><td>Blacklist</td><td>This text box can contain a comma-separated list of dimension fields that you want to blacklist from the metric data points generated from the log events associated with this source type. You might want to blacklist high-cardinality dimension fields that are unnecessary for your metric collection.

You can use the wildcard character (*) to match multiple dimension field values in your event data. For example, if your event data contains the dimensions customer_id, employee_id, and consultant_id and you have *_id in the Blacklist text box, all three of those dimensions are blacklisted.</td></tr>
</table>

5. Click Next to continue with the Add Data workflow for your data input.

## Set up ingest-time log-to-metrics conversion with configuration files

If you have access to the props.conf and transforms.conf files for your deployment, you can manually configure log-to-metrics transformations that are more sophisticated than the ones you can set up with Splunk Web. For example, you can design log-to-metrics transformations that can handle logs where not all of the events have the same sets of measurement and dimension fields.

To configure a log-to-metrics conversion, you need to add stanzas to your props.conf and transforms.conf files.

1. Specify the schema for log-to-metrics transformations in transforms.conf.
2. Configure log-to-metrics settings in props.conf.

For an overview of ingest-time conversion of logs to metric data points, see Convert event logs to metric data points.

### Log-to-metric feature extensions that are not available in Splunk Web

When you manage log-to-metric processing through direct edits to configuration files, you can take advantage of optional feature extensions that are not yet available in Splunk Web.

<table>
<tr><td>Extended feature</td><td>In Splunk Web</td><td>Through configuration file edits</td><td>Setting</td></tr>
<tr><td>Whitelist filtering for dimensions</td><td>You can filter dimensions only by providing a dimension blacklist. This is a set of dimensions that must be excluded from the metric data points generated by the log-to-metrics configuration.</td><td>Alternatively, you can filter out dimensions with a dimension whitelist. All dimensions not in the whitelist are excluded from the metric data points generated by the log-to-metrics configuration.</td><td>METRIC-SCHEMA-WHITELIST-DIMS</td></tr>
<tr><td>Sort events by the values of a shared field and target different log-to-metric conversion rules to each set of events.</td><td>The log-to-metric conversion rules are applied to all events that belong to the selected source type.</td><td>If all of the events belonging to the selected source type all share a metric_name field, you can devise log-to-metric rules for events with specific values of that field.</td><td>METRIC-SCHEMA-MEASURES-&lt;unique_metric_name_prefix&gt;, METRIC-SCHEMA-BLACKLIST-DIMS-&lt;unique_metric_name_prefix&gt;, and METRIC-SCHEMA-WHITELIST-DIMS-&lt;unique_metric_name_prefix&gt;.</td></tr>
</table>

### Considerations for forwarders

When processing log-to-metrics conversions, the type of forwarder that you are using and the type of data that you are ingesting require specific indexer versions and locations for the transforms.conf and props.conf files with the log-to-metrics configurations.

The following configurations apply whether the data involved is structured or unstructured. Structured data includes formats like CSV and JSON. For more information, see Set up field extractions for the log data source.

|Forwarder version and type|Location of log-to-metrics configuration files|Indexer version required|
|:--:|:--:|:--:|
|7.3.x Universal Forwarder|Universal Forwarder|8.x|
|7.3.x Heavy Forwarder|Heavy Forwarder|8.x|
|7.3.x Universal Forwarder|Indexer|8.x|
|7.3.x Heavy Forwarder|Indexer|8.x|

### Specify the schema for log-to-metrics transformations in transforms.conf

Use configurations in the transforms.conf file to identify which events in a log contain metrics data points that you want to extract, and then specify how to extract the metrics from the log events.

1. Identify which events in a log contain metrics data points that you want to extract, and then apply the relevant settings in the configuration.
- Apply log-to-metrics settings to all events in a log.
- Apply log-to-metrics settings to specific events in a log.
2. Specify how to extract measures from log events.
3. Determine which event fields are transformed into metric dimensions.

#### Log-to-metrics metric schema settings reference

The metric schema settings determine how the log events associated with the stanza are transformed into metric data points. This table describes the syntax for the available settings when configuring log-to-metrics in transforms.conf:

|Metric schema setting syntax|Description|Required|
|:--|:--|:--:|
|METRIC-SCHEMA-MEASURES = (_ALLNUMS_ \| (_NUMS_EXCEPT_ )? <field1>, <field2>,... )|Identifies how to extract numeric fields in events as measures in the metric data points that correspond to those events. You can identify the numeric fields that should be turned into measures, or you can process all numeric fields in an event as measures.|Yes|
|METRIC-SCHEMA-BLACKLIST-DIMS = <dimension_field1>, <dimension_field2>,...|Identifies blacklisted dimension fields. These are fields in your event data that cannot appear as dimensions in the metric data points that are generated from an event associated with the [metric-schema] stanza. You might want to set up a blacklist if some of the fields in your event data are high-cardinality dimension fields that are unnecessary for your metric collection.|No|
|METRIC-SCHEMA-WHITELIST-DIMS = <dimension_field1>,<dimension_field2>,...|Identifies whitelisted dimension fields. These are fields in your event data that must appear as dimensions in the metric data points that are generated from an event associated with the [metric-schema] stanza. You might want to set up a whitelist if most of the fields in your event data are high-cardinality or otherwise unnecessary for your metrics.|No|

#### Apply log-to-metrics settings to all events in a log

Use the METRIC-SCHEMA-MEASURES setting to apply log-to-metrics processing to all events in a log. You can optionally use the METRIC-SCHEMA-BLACKLIST-DIMS and METRIC-SCHEMA-WHITELIST-DIMS settings to filter unnecessary dimension fields out of the resulting metric data points.

This configuration syntax is as follows:

```properties
[metric-schema:<unique_transforms_stanza_name]
METRIC-SCHEMA-MEASURES = (_ALLNUMS_ | (_NUMS_EXCEPT_ )? <field1>, <field2>,... )
METRIC-SCHEMA-BLACKLIST-DIMS = <dimension_field1>, <dimension_field2>,...
METRIC-SCHEMA-WHITELIST-DIMS = <dimension_field1>,<dimension_field2>,...
```

Replace (_ALLNUMS_ | (_NUMS_EXCEPT_ )? <field1>, <field2>,... ) with the specific setting you choose from Specify how to extract metrics from log events.

#### Apply log-to-metrics settings to specific events in a log

Use the METRIC-SCHEMA-MEASURES-<unique_metric_name_prefix> setting to apply log-to-metrics processing to specific events within a log. It will target a subset of events according to the value of a field shared by all of the events in the log.

Optionally use the METRIC-SCHEMA-BLACKLIST-DIMS-<unique_metric_name_prefix> and METRIC-SCHEMA-WHITELIST-DIMS-<unique_metric_name_prefix> parameters to filter unnecessary dimension fields out of the resulting metric data points.

This configuration syntax is as follows:

```properties
[metric-schema:<unique_transforms_stanza_name>]
METRIC-SCHEMA-MEASURES-<unique_metric_name_prefix> = (_ALLNUMS_ | (_NUMS_EXCEPT_ )? <field1>, <field2>,... )
METRIC-SCHEMA-BLACKLIST-DIMS-<unique_metric_name_prefix> = <dimension_field1>, <dimension_field2>,...
METRIC-SCHEMA-WHITELIST-DIMS-<unique_metric_name_prefix> = <dimension_field1>,<dimension_field2>,...
```

Replace (_ALLNUMS_ | (_NUMS_EXCEPT_ )? <field1>, <field2>,... ) with the specific setting you choose from Specify how to extract metrics from log events.

The <unique_metric_name_prefix> must match the value of a metric_name field that is shared by all of the events associated with the [metric-schema] stanza. The values of the metric_name field must correspond to the different event types present in the metric-schema stanza.

If a metric_name field is not already shared by your log events, there are ways to add it to your events:

- Create an index-time field extraction named metric_name.
- Use the INGEST_EVAL setting to add a metric_name field to the events at ingest time. For an example that shows you how to configure this, see Example of targeted log-to-metrics conversions.

When configured correctly, the METRIC-SCHEMA-MEASURES-<unique_metric_name_prefix> setting produces metric data points with measurements that follow this syntax: metric_name:<unique_metric_name_prefix>.<measure_field_name>=<numeric_measure_field_value>.

Always use the METRIC-SCHEMA-BLACKLIST-DIMS-<unique_metric_name_prefix> and METRIC-SCHEMA-WHITELIST-DIMS-<unique_metric_name_prefix> settings in conjunction with a corresponding METRIC-SCHEMA-MEASURES-<unique_metric_name_prefix> setting.

#### Specify how to extract measures from log events

There are several options to extract measures from log events:

- You can extract all numeric fields in events as measures.
- You can extract numeric fields with some exclusions as measures, or blacklist specific fields from being extracted as measures.
- You can extract specific fields as measures, or whitelist specific fields to be extracted as measures.

These options are available whether you apply log-to-metrics settings to all events in a log or only to specific events in a log.

<table>
<tr><td>Method for extracting measures</td><td>Description</td><td>Syntax example</td><td>Fields with numeric and non-numeric values</td></tr>
<tr><td>Extract all numeric fields as measures.</td><td>Set up a [metric-schema] stanza using the _ALLNUMS_ setting.</td><td>[metric-schema:&lt;unique_transforms_stanza_name&gt;]
METRIC-SCHEMA-MEASURES = _ALLNUMS_</td><td>
The _ALLNUMS_ setting extracts numeric values as measures for the field. Due to the non-numeric values, the same field is also used as a dimension field. If you want that field to be used only as a measure, blacklist it as a dimension field. See Determine which event fields are transformed into metric dimensions.</td></tr>
<tr><td>Extract numeric fields with some exclusions as measures.</td><td>Set up a [metric-schema] stanza using the _NUMS_EXCEPT_ setting to define a blacklist of fields that you do not want extracted as measures. You must have a space between _NUMS_EXCEPT_ and the field name for the setting to function.</td><td>
[metric-schema:&lt;unique_transforms_stanza_name&gt;]
METRIC-SCHEMA-MEASURES = _NUMS_EXCEPT_ <measure_field1>, <measure_field2>,...</td><td>The _NUMS_EXCEPT_ setting extracts the numeric values as measures for the field. If you want a field with both numeric and non-numeric fields to only be a dimension field, exclude it from being extracted as a measure using the _NUMS_EXCEPT_ setting.</td></tr>
<tr><td>Extract specific fields as measures.</td><td>In transforms.conf, set up a [metric-schema] stanza that identifies lists of fields that contain measurement values to extract only those fields as measures.</td><td>
[metric-schema:&lt;unique_transforms_stanza_name&gt;]
METRIC-SCHEMA-MEASURES = <measure_field1>, <measure_field2>,...</td><td>If you specify a field that has both numeric and non-numeric values with this setting, the numeric values are extracted as measures and the non-numeric values are ignored. The field is not used as a dimension field with the non-numeric values.</td></tr>
</table>

You can use the wildcard character to match multiple similar numeric fields in your data. For example, say your event data contains the following numeric fields max_size_kb, min_size_kb, and current_size_kb. You can set a <measure_field> value of *_size_kb to include all three of those numeric fields in the list of measures without listing each one separately.

#### Determine which event fields are transformed into metric dimensions

Any event field that the METRIC-SCHEMA-MEASURES setting does not identify as a measure can appear in the metric data point that is generated from that event as a dimension.

However, you can optionally use the METRIC-SCHEMA-BLACKLIST-DIMS and METRIC-SCHEMA-WHITELIST-DIMS settings to filter dimensions out of the metric data point.

- If you provide a list of event fields for METRIC-SCHEMA-BLACKLIST-DIMS, the search head transforms all unlisted non-measure fields into metric data point dimensions.
- If you provide a list of event fields for METRIC-SCHEMA-WHITELIST-DIMS, the fields in that list are the only fields that the search head transforms into metric data point dimensions. It ignores all other non-measure fields

The syntax for this configuration looks like this:

```properties
[metric-schema:<unique_transforms_stanza_name>]
METRIC-SCHEMA-MEASURES = <your_measures_setting>
METRIC-SCHEMA-BLACKLIST-DIMS = <dimension_field1>, <dimension_field2>,...
METRIC-SCHEMA-WHITELIST-DIMS = <dimension_field1>, <dimension_field2>,...
```

The search processor uses the following evaluation logic when a metric schema has fields defined for both METRIC-SCHEMA-BLACKLIST-DIMS and METRIC-SCHEMA-WHITELIST-DIMS:

- If a dimension is listed in the BLACKLIST, it won't be present in the resulting metric data point, even if it also appears in the WHITELIST.
- If a dimension is not listed in the WHITELIST, it won't be present in the resulting metric data point, even if it also does not appear in the BLACKLIST.

You can use the wildcard character to match multiple similar dimension fields in your data. For example, say your event data contains the following dimensions customer_id, employee_id, and consultant_id. You can set a <dimension_name> value of *_id to include all three of those dimensions in the dimension field list without listing each one separately.

>> If you have a field with both numeric and non-numeric values and you are using the _ALNUMS_ setting or the _NUMS_EXCEPT_ setting, the field is extracted as a measure by the setting and again as a dimension due to the non-numeric values. If you want that field to be used only as a measure, blacklist it as a dimension field.

#### About extracting new fields from unstructured data or renaming fields

The Log to Metrics feature works by going over indexed fields in _meta to convert them to metric measurements or include or exclude them as dimensions. If you use structured data indexed field extraction methods (such as CSV or JSON extractions) you do not have to do extra setup beyond what we have provided here. However, if you are designing a more complex configuration that involves the extraction of fields from unstructured data, or the renaming of existing fields, you will need to make sure the fields are indexed. You can do this by setting WRITE_META=true in the transforms.conf stanza for the extraction.

See How Splunk software builds indexed fields, in Getting Data In.

### Configure log-to-metrics settings in props.conf

After configuring the metrics schema for a source type in transforms.conf, finish configuring the log-to-metrics settings in props.conf. Configure log-to-metrics settings in the props.conf file:

#### Reference the metric schema from transforms.conf.

Set up field extractions for the log data source.
Reference the metric schema from transforms.conf
To associate the log-to-metrics schema with a specific log source type, reference the transforms.conf configuration in the stanza for the log source type in props.conf. Use the METRIC-SCHEMA-TRANSFORMS setting, which has the following syntax:

```properties
[ <sourcetype> ]
METRIC-SCHEMA-TRANSFORMS = <metric-schema:stanza_name>[,<metric-schema:stanza_name>]...
```

Type the names of the log-to-metrics transform stanzas in the <stanza_name> part of the METRIC-SCHEMA-TRANSFORMS setting.

#### Set up field extractions for the log data source

To use log-to-metrics configurations, you must design a configuration that extracts fields from your log data. The configuration that you use depends on whether the data is structured or unstructured.

If your log data is in a structured format like a CSV file or JSON, add the INDEXED_EXTRACTIONS setting to the props.conf stanza. See Extract fields from files with structured data in Getting Data In.

If your log data is technically unstructured but is organized into field-value pairs that can easily be extracted, add TRANSFORMS-<class>=field_extraction to the stanza. This references the [field_extraction] stanza in transforms.conf, which is included by default with the Splunk platform. The [field_extraction] stanza uses a simple regular expression to extract field-value pairs from log data.

### Order of operations for log-to-metrics conversion settings

The Splunk platform processes all METRIC-SCHEMA-MEASURES-<unique_metric_name_prefix> and METRIC-SCHEMA-BLACKLIST-DIMS-<unique_metric_name_prefix> settings ahead of basic METRIC-SCHEMA-MEASURES and METRIC-SCHEMA-BLACKLIST-DIMS settings.

In other words, the Splunk platform processes all of the event-targeting log-to-metrics settings before it processes the event-agnostic log-to-metrics settings. This allows the latter group of settings to process remaining events that were not targeted by the <unique_metric_name_prefix> settings.

### Example of targeted log-to-metrics conversions

Use targeted log-to-metrics conversions when one log source type contains multiple event schemas with different sets of measurements and dimension fields. The following event collection example contains two event schemas. The events share a group field, and the values of group identify the two event schemas.

|_time|Event|
|:--|:--|
|08-05-2017 20:26:29.073 -0700|INFO Metrics - group=queue, location=sf, corp=splunk, name=udp_queue, max_size_kb=0, current_size_kb=0, current_size=0, largest_size=0, smallest_size=0|
|08-05-2017 20:26:29.073 -0700|INFO Metrics - group=queue, location=sf, corp=splunk, name=aggqueue, max_size_kb=1024, current_size_kb=1, current_size=5, largest_size=35, smallest_size=0|
|08-05-2017 20:26:29.073 -0700|INFO Metrics - group=queue, location=sf, corp=splunk, name=auditqueue, max_size_kb=500, current_size_kb=0, current_size=0, largest_size=1, smallest_size=0|
|08-05-2017 20:26:29.075 -0700|INFO Metrics - group=pipeline, name=indexerpipe, processor=indexin, cpu_seconds=0, executes=171, cumulative_hits=2214401|
|08-05-2017 20:26:29.075 -0700|INFO Metrics - group=pipeline, name=indexerpipe, processor=index_thruput, cpu_seconds=0, executes=171, cumulative_hits=2214401|
|08-05-2017 20:26:29.075 -0700|INFO Metrics - group=pipeline, name=indexerpipe, processor=indexandforward, cpu_seconds=0, executes=171, cumulative_hits=2214401|

After examining these events, you decide that you need to define a set of configurations in transforms.conf and props.conf that perform the following tasks:

- Set TRANSFORMS-<class>=field_extraction to extract field-value pairs from the log lines at ingest time.
- Use INGEST_EVAL to add a metric_name field to every event with a group field at ingest time. The new metric_name fields get the same values as their corresponding group fields.
- Provide separate log-to-metrics settings for the metric_name=queue events and the metric_name=pipeline events. Extract all of the numeric fields from the metric_name=queue events as measures.
- Blacklist the group, location, and corp fields from the dimensions for the metric_name=queue metric data points. Blacklist the group field from the dimensions for the metric_name=pipeline events.
- Associate the log-to-metrics settings with events that have the metrics_log source type.

Those configurations look as follows:

#### transforms.conf

```properties
[eval_pipeline]
INGEST_EVAL = metric_name=group

[metric-schema:extract_metrics]
METRIC-SCHEMA-MEASURES-queue=_ALLNUMS_
METRIC-SCHEMA-BLACKLIST-DIMS-queue=group,location,corp
METRIC-SCHEMA-MEASURES-pipeline=cpu_seconds,executes,cumulative_hits
METRIC-SCHEMA-BLACKLIST-DIMS-pipeline=group
```

#### props.conf

```properties
[metrics_log]
TRANSFORMS-fieldvalue=field_extraction
TRANSFORMS-metricslog=eval_pipeline
METRIC-SCHEMA-TRANSFORMS=metric-schema:extract_metrics
```

The metric data points created by these configurations look like the following examples:

<table>

<tr><td>_time</td><td>measures</td><td>dimensions</td></tr>
<tr><td>08-05-2017 20:26:29.073 -0700</td><td>metric_name:queue.max_size_kb=0, metric_name:queue.current_size_kb=0, metric_name:queue.current_size=0, metric_name:queue.largest_size=0, metric_name:queue.smallest_size=0</td><td>name=udp_queue</td></tr>
<tr><td>08-05-2017 20:26:29.073 -0700</td><td>metric_name:queue.max_size_kb=1024, metric_name:queue.current_size_kb=1, metric_name:queue.current_size=5, metric_name:queue.largest_size=35, metric_name:queue.smallest_size=0</td><td>name=aggqueue</td></tr>
<tr><td>08-05-2017 20:26:29.073 -0700</td><td>metric_name:queue.max_size_kb=500, metric_name:queue.current_size_kb=0, metric_name:queue.current_size=0, metric_name:queue.largest_size=1, metric_name:queue.smallest_size=0</td><td>name=auditqueue</td></tr>
<tr><td>08-05-2017 20:26:29.075 -0700</td><td>metric_name:pipeline.cpu_seconds=0, metric_name:pipeline.executes=171, metric_name:pipeline.cumulative_hits=2214401</td><td>name=indexerpipe, processor=indexin</td></tr>
<tr><td>08-05-2017 20:26:29.075 -0700</td><td>metric_name:pipeline.cpu_seconds=0, metric_name:pipeline.executes=171, metric_name:pipeline.cumulative_hits=2214401,</td><td>name=indexerpipe, processor=index_thruput</td></tr>
<tr><td>08-05-2017 20:26:29.075 -0700</td><td>metric_name:pipeline.cpu_seconds=0, metric_name:pipeline.executes=171, metric_name:pipeline.cumulative_hits=2214401,</td><td>name=indexerpipe, processor=indexandforward</td></tr>
</table>
