# 카프카 데이터 플랫폼의 최강자

## 1부 카프카를 시작하며

## 1장 카프카란 무엇인가

1.1 카프카의 탄생 배경
1.2 카프카의 동작 방식과 원리
1.3 카프카의 특징
1.4 카프카의 확장과 발전
1.5 정리

## 2장 카프카와 주키퍼 설치

2.1 카프카 관리를 위한 주키퍼
2.2 주키퍼 설치
__2.2.1 주키퍼 다운로드
__2.2.2 주키퍼 실행
2.3 카프카 설치
__2.3.1 카프카 다운로드
__2.3.2 카프카 환경설정
__2.3.3 카프카 실행
2.4 카프카 상태 확인
__2.4.1 TCP 포트 확인
__2.4.2 주키퍼 지노드를 이용한 카프카 정보 확인
__2.4.3 카프카 로그 확인
2.5 카프카 시작하기
2.6 정리

## 2부 기본 개념과 운영 가이드

## 3장 카프카 디자인

3.1 카프카 디자인의 특징 
__3.1.1 분산 시스템 
__3.1.2 페이지 캐시
__3.1.3 배치 처리
3.2 카프카 데이터 모델 
__3.2.1 토픽의 이해
__3.2.2 파티션의 이해
__3.2.3 오프셋과 메시지 순서
3.3 카프카의 고가용성과 리플리케이션
__3.3.1 리플리케이션 팩터와 리더, 팔로워의 역할
__3.3.2 리더와 팔로워의 관리
3.4 모든 브로커가 다운된다면
3.5 카프카에서 사용하는 주키퍼 지노드 역할
3.6 정리

## 4장 카프카 프로듀서

4.1 콘솔 프로듀서로 메시지 보내기
4.2 자바와 파이썬을 이용한 프로듀서
__4.2.1 메시지를 보내고 확인하지 않기
__4.2.2 동기 전송
__4.2.3 비동기 전송
4.3 프로듀서 활용 예제
4.4 프로듀서 주요 옵션
4.5 메시지 전송 방법
__4.5.1 메시지 손실 가능성이 높지만 빠른 전송이 필요한 경우
__4.5.1 메시지 손실 가능성이 적고, 적당한 속도의 전송이 필요한 경우
__4.5.2 전송 속도는 느리지만, 메시지 손실이 없어야 하는 경우
4.6 정리

## 5장 카프카 컨슈머

5.1 컨슈머 주요 옵션
5.2 콘솔 컨슈머로 메시지 가져오기
5.3 자바와 파이썬을 이용한 컨슈머
5.4 파티션과 메시지 순서
__5.4.1 파티션3개로 구성한 peter-01토픽과 메시지 순서
__5.4.2 파티션1개로 구성한 peter-02토픽과 메시지 순서
5.5 컨슈머 그룹
5.6 커밋과 오프셋
__5.6.1 자동 커밋
__5.6.2 수동 커밋
__5.6.3 특정 파티션 할당
__5.6.4 특정 오프셋부터 메시지 가져오기
5.7 정리

## 6장 카프카 운영 가이드

6.1 필수 카프카 명령어
__6.1.1 토픽 생성 
__6.1.2 토픽 리스트 확인
__6.1.3 토픽 상세보기
__6.1.4 토픽 설정 변경
__6.1.5 토픽의 파티션 수 변경
__6.1.6 토픽의 리플리케이션 팩터 변경
__6.1.7 컨슈머 그룹 리스트 확인
__6.1.8 컨슈머 상태와 오프셋 확인
6.2 주키퍼 스케일 아웃
6.3 카프카 스케일 아웃
6.4 카프카 모니터링
__6.4.1 카프카 JMX 설정 방법
__6.4.2 JMX 모니터링 지표
6.5 카프카 매니저
__6.5.1 카프카 매니저 설치
__6.5.2 카프카 클러스터 등록
__6.5.3 카프카 매니저 메뉴 설명
6.6 카프카 운영에 대한 Q&A
6.7 정리

## 3부 카프카의 확장과 응용

## 7장 카프카를 활용한 데이터 파이프라인 구축

7.1 카프카를 활용한 데이터 흐름도
7.2 파일비트를 이용한 메시지 전송
__7.2.1 파일비트 설치
__7.2.2 파일비트 설정
__7.2.3 카프카 토픽의 메시지 유입 확인
7.3 나이파이를 이용해 메시지 가져오기
__7.3.1 나이파이 설치
__7.3.2 나이파이 설정
__7.3.3 나이파이를 이용한 컨슈머 설정
7.4 실시간 분석을 위해 엘라스틱서치에 메시지 저장
__7.4.1 엘라스틱서치 설치
__7.4.2 엘라스틱서치 설정
__7.4.3 나이파이를 이용해 엘라스틱서치로 데이터 전송
7.5 키바나를 이용해 엘라스틱서치에 저장된 데이터 확인
__7.5.1 키바나 설치
__7.5.2 키바나 설정
7.6 현재의 토픽을 이용해 새로운 토픽으로 메시지 재생산
__7.6.1 나이파이를 이용한 카프카 컨슈머 추가
__7.6.2 나이파이를 이용한 토픽별 라우팅 작업
7.7 정리

## 8장 카프카 스트림즈 API

8.1 스트림 프로세싱 기초
__8.1.1 스트림 프로세싱과 배치 프로세싱
__8.1.2 상태 기반과 무상태 스트림 처리
8.2 카프카 스트림즈
__8.2.1 카프카 스트림즈의 특징과 개념
__8.2.2 카프카 스트림즈 아키텍처
8.3 카프카 스트림즈를 위한 환경설정
8.4 파이프 예제 프로그램 만들기 
8.5 행 분리 예제 프로그램 만들기
8.6 단어 빈도수 세기 예제 프로그램 만들기
8.7 정리

## 9장 카프카 SQL을 이용한 스트리밍 처리

9.1 KSQL의 등장 배경
9.2 KSQL과 카파 아키텍처
9.3 KSQL 아키텍처
__9.3.1 KSQL 서버
__9.3.2 KSQL 클라이언트
9.4 도커를 이용한 KSQL 클러스터 설치
9.5 KSQL을 이용한 스트림 분석
__9.5.1 데이터 준비
__9.5.2 기본 스트림과 테이블 생성
__9.5.3 쿼리를 이용한 새로운 스트림과 테이블 생성
9.6 정리

## 10장 그 밖의 클라우드 기반 메시징 서비스

10.1 구글의 펍/섭 서비스 소개
10.2 구글의 펍/섭 서비스 연동
__10.2.1 구글 SDK 설치
__10.2.2 구글 펍/섭 CLI로 토픽 사용
10.3 펍/섭 파이썬 SDK 사용하기
__10.3.1 펍/섭 파이썬 라이브러리 설치
__10.3.2 구글 서비스 계정 인증정보 생성
__10.3.3 파이썬 SDK 사용하기
10.4 아마존 키네시스 서비스 소개
10.5 아마존 키네시스 연동
__10.5.1 아마존 CLI 설치
__10.5.2 아마존 CLI로 키네시스 사용하기
10.6 아마존 키네시스 자바 SDK 사용하기
__10.6.1 컨슈머 코드 예제
__10.6.2 프로듀서 코드 예제
10.7 카프카와 클라우드 서비스와의 비교
10.8 정리

부록 도커를 이용한 카프카 설치
A.1 도커 설치
__A.1.1 리눅스 버전 도커 설치
__A.1.2 맥 버전 도커 설치
__A.1.3 윈도우 버전 도커 설치
A.2 도커 버전 카프카 설치