# Troubleshooting

## Splunk Add-on for AWS Troubleshooting

### 일반적인 Troubleshooting

모든 Add-on에 적용 할 수 있는 유용한 Troubleshooting 정보는 [Troubleshoot add-ons](http://docs.splunk.com/Documentation/AddOns/released/Overview/Troubleshootadd-ons). You can also access these [support and resource links](http://docs.splunk.com/Documentation/AddOns/latest/Overview/Learnmoreandgethelp) 참조

### Health Check 대시보드

**Health Check** 메뉴에서 대시보드를 선택하여 데이터 수집 오류 및 성능 문제를 해결할 수 있음.

**Health Overview** 대시보드는 모든 입력 유형에 대한 데이터 수집 오류 및 성능 측정 항목을 한눈에 볼 수 있음.

- 오류 카테고리별 오류 수
- 입력 유형, 호스트, 데이터 입력 및 오류 범주에 따른 시간별 오류 카운트
- 호스트, 입력 유형 및 데이터 입력에 따른 시간 경과에 따른 처리량

**S3Health Details** 대시보드는 General, Increametal 및 SQS-Based S3입력 유형에 중점을 두고 인덱싱 시간 지연 및 이러한 다목적 입력에 대한 자세한 오류 정보를 제공함.

건강 대시보드를 사용자 정의 할 수 있음. [About the Dashboard Editor](http://docs.splunk.com/Documentation/Splunk/7.1.1/Viz/CreateandeditdashboardsviatheUI) 항목을 참조. [Dashboards and Visualizations](http://docs.splunk.com/Documentation/Splunk/7.1.1/Viz/Aboutthismanual) 매뉴얼을 참조.

### Internal Logs

Troubleshooting을 위해 Internal Logs 데이터에 직접 액세스 할 수 있음. 이러한 원본 유형으로 수집된 데이터는 Health Check 대시보드에서 사용됨.

<table>
<tr><td>Data source</td><td>Source type</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudtrail_cloudtrail_{input_name}.log.</td><td>aws:cloudtrail:log</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudwatch.log.</td><td>aws:cloudwatch:log</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudwatch_logs.log.</td><td>aws:cloudwatchlogs:log</td></tr>
<tr><td>Logs from splunk_ta_aws_config_{input_name}.log.</td><td>aws:config:log</td></tr>
<tr><td>Logs from splunk_ta_aws_config_rule.log.</td><td>aws:configrule:log</td></tr>
<tr><td>Logs from splunk_ta_aws_inspector_main.log, splunk_ta_aws_inspector_app_env.log, splunk_ta_aws_inspector_proxy_conf.log, and splunk_ta_aws_inspector_util.log.</td><td>aws:inspector:log</td></tr>
<tr><td>Logs from splunk_ta_aws_description.log.</td><td>aws:description:log</td></tr>
<tr><td>Logs from splunk_ta_aws_billing_{input_name}.log.</td><td>aws:billing:log</td></tr>
<tr><td>Logs from splunk_ta_aws_generic_s3_{input_name}.</td><td>aws:s3:log</td></tr>
<tr><td>Logs from splunk_ta_aws_logs_{input_name}.log, each incremental S3input has one log file with the input name in the log file.</td><td>aws:logs:log</td></tr>
<tr><td>Logs from splunk_ta_aws_kinesis.log.</td><td>aws:kinesis:log</td></tr>
<tr><td>Logs from splunk_ta_aws_ sqs_based_s3_{input_name} .</td><td>aws:sqsbaseds3:log</td></tr>
<tr><td>Logs from splunk_ta_aws_sns_alert_modular.log and splunk_ta_aws_sns_alert_search.log.</td><td>aws:sns:alert:log</td></tr>
<tr><td>Logs from splunk_ta_aws_rest.log, populated by REST API handlers called when setting up the add-on or data input.</td><td>aws:resthandler:log</td></tr>
<tr><td>Logs from splunk_ta_aws_proxy_conf.log, the proxy handler used in all AWS data inputs.</td><td>aws:proxy-conf:log</td></tr>
<tr><td>Logs from splunk_ta_aws_s3util.log, populated by the S3, CloudWatch, and SQS connectors.</td><td>aws:resthandler:log</td></tr>
<tr><td>Logs from splunk_ta_aws_util.log, a shared utilities library.</td><td>aws:util:log</td></tr>
</table>

### Log Levels 구성

1. Splunk Web의 홈 페이지 왼쪽 탐색 모음에서 **Splunk Add-on for AWS**을 클릭.
2. 앱 탐색 바에서 **Configuration**을 클릭.
3. **Logging** 탭을 클릭.
4. `INFO`의 기본값을 다른 사용 가능한 옵션 중 하나인 `DEBUG` 또는 `ERROR`로 변경하여 필요에 따라 각 AWS 서비스의 Log Levels을 조정.

> Note : 이러한 Log Levels 구성은 런타임 로그에만 적용. DEBUG의 구성 활동 로그에있는 일부 REST 엔드포인트 로그 및 일부 유효성 검증 로그는 ERROR에 로그함. 이 레벨은 구성 할 수 없음.

### 계정 또는 입력 구성 중 문제를 저장하는 중

설정 페이지에서 AWS 계정을 구성하는 동안 오류가 발생하거나 저장하는데 문제가 있으면 `$SPLUNK_HOME/etc/system/local/web.conf`로 이동하여 아래 표시된대로 timeout 설정을 변경.

```properties
  [settings]
  splunkdConnectionTimeout = 300
```

### 배포 서버로 배포할 때의 문제

배포 서버를 사용하여 Splunk Add-on for Amazon Web Services을 여러 Heavy Forwarder에 배포하는 경우 배포 서버가 인스턴스간에 sharing hashed password storage를 지원하지 않기 때문에 각 인스턴스에 대한 Splunk Web 설치 UI를 별도로 사용하여 Amazon Web Services 계정을 구성.

### S3문제

#### S3input 성능 문제

단일 S3Bucket에 대해 여러 개의 S3입력을 구성하여 성능을 향상시킬 수 있음. Splunk 플랫폼은 각 데이터 입력에 대해 하나의 프로세스를 수행하므로 시스템의 처리 능력이 충분하면 여러 입력으로 성능이 향상됨. [Performance reference for the S3input in the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/S3PerformanceReference) 참조.

> Note : 중복 데이터 인덱싱을 방지하려면 동일한 버킷에 대한 여러 입력의 S3키 이름이 겹치지 않도록 함.

#### S3key name whitelist/blacklist filtering issues

화이트리스트와 블랙리스트는 마지막 세그먼트뿐만 아니라 전체 키 이름과 일치함.

Whitelist .*abc/.* will match /a/b/abc/e.gz.

regex에 대한 추가 도움말 :

- 이 블로그 게시물의 비디오보기 : <http://blogs.splunk.com/2008/10/22/all-my-regexs-live-in-texas/>
- Splunk Enterprise 설명서의 일부인 Knowledge Manager 설명서에서 "[About Splunk regular expressions](http://docs.splunk.com/Documentation/Splunk/7.1.1/Knowledge/AboutSplunkregularexpressions)"를 참조

#### S3event line breaking issues

인덱싱된 S3데이터의 줄 바꿈이 잘못된 경우 'props.conf'에 사용자 지정 소스 유형을 구성하여 이벤트에 대한 줄을 끊는 방법을 제어함.

S3이벤트가 너무 길어서 잘리는 경우 `props.conf`에 `TRUNCATE = 0` 설정하여 줄 잘림을 방지.

자세한 내용은 Splunk Enterprise 설명서의 데이터 가져 오기 설명서에서 [Configure event line breaking](http://docs.splunk.com/Documentation/Splunk/latest/Data/Configureeventlinebreaking) 참조.

### CloudWatch configuration issues

#### Throttling

CloudWatch 데이터가 많은 경우 `index = _internal Throttling` 검색하여 API 조절 문제가 발생하는지 확인. 그렇다면 AWS 지원 팀에 문의하여 CloudWatch API 속도를 높임. 수집하는 메트릭 수를 줄이거나 세분화하여 API 호출을 줄임.

#### Granularity(세분성)

인덱싱된 데이터의 Granularity(세분성)이 예상과 다를 경우 구성된 Granularity(세분성)이 선택한 측정 항목에 대해 AWS에서 지원하는 범위 내에 있는지 확인. 서로 다른 AWS 메트릭은 AWS에서 해당 메트릭을 허용하는 샘플링 기간을 기준으로 다른 최소 Granularity(세분성)을 지원. 예를 들어 CPUUtilization은 5분의 샘플링 기간을 가지지만 Billing Estimated Charge는 4시간의 샘플링 기간을 가짐.

선택한 메트릭의 샘플링 기간보다 작은 Granularity(세분성)을 구성한 경우 인덱싱된 데이터의 보고된 Granularity(세분성)이 실제 세분화된 Granularity(세분성)을 반영하지만 구성된 Granularity(세분성)으로 레이블이 지정됨. 문제가있는 `local/inputs.conf` Cloudwatch 스탠자를 지우고 새로 인덱싱된 데이터가 정확하도록 지원되는 샘플링 Granularity(세분성)과 일치하도록 Granularity(세분성) 구성을 조정하고 데이터를 다시 색인화함.

### CloudTrail 데이터 색인 문제

Splunk 플랫폼에서 CloudTrail 데이터가 표시되지 않는 경우이 Troubleshooting 프로세스를 따름.

1. 다음을 검색하여 Internal Logs를 검토함. `index=_internal source=*cloudtrail*`
2. "Connected to SQS"문자열을 검색하여 Splunk 플랫폼이 SQS에 성공적으로 연결되어 있는지 확인.
3. Splunk 플랫폼이 메시지를 성공적으로 처리하는지 확인. "X 완료, Y 통보 일괄 처리 중 실패"패턴을 따르는 문자열을 찾음.
4. Splunk 플랫폼이 메시지를 삭제하는지 확인. 패턴 "X를 가져 왔고, Y를 쓰고, 버려진 Z"를 따르는 문자열을 찾음.
5. Amazon Web Services 구성을 검토하여 SQS 메시지가 대기열에 있는지 확인. 메시지가 제거되고 로그에 입력 내용이 제거되지 않는다고 표시되지 않으면 큐에서 다른 스크립트나 입력 메시지를 사용할 수 있음. 데이터 입력을 검토하여 동일한 대기열을 사용하도록 구성된 다른 입력이 없는지 확인.
6. AWS 콘솔로 이동하여 세부 정보가 1분으로 설정된 CloudWatch 메트릭을 확인하여 추세를 확인. 자세한 내용은 <https://aws.amazon.com/blogs/aws/amazon-cloudwatch-search-and-browse-metrics-in-the-console/>을 참조. 소비된 메시지가 표시되지만 Splunk 플랫폼 입력이 메시지를 소비하지 않는 경우 동일한 대기열에 액세스하는 원격 서비스가 있는지 확인.

### Billing Report issues

#### AWS에서 Billing Report에 액세스하는데 문제

Billing 입력을 구성 할 때 선택한 S3Bucket에서 사용할 수 있는 Billing Report가 있는지, 지정한 AWS 계정에 해당 버킷 내부의 파일을 읽을 수 있는 권한이 있는지 확인.

#### Billing Report 데이터 이해 문제

Splunk은 Add-on에 포함된 [accessing the saved searches](http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata#Access_saved_searches) 권장하여 Billing Report 데이터를 분석함.

#### Billing data interval 구성 문제

> Note : Billing Report 데이터의 기본 Billing 데이터 수집 수집 간격은 라이센스 사용을 최소화하도록 설계됨. 기본 동작을 검토하고 조심해서 조정.

Splunk Enterprise가 Monthly and Detailed Billing Report를 가져 오는 간격을 구성하려면 다음을 수행.

1. Splunk Web에서 AWS 입력 용 Splunk Add-on 화면으로 이동.
2. 새로운 대금 Billing input을 생성하거나 클릭하여 기존 입력을 편집.
3. 설정 탭을 클릭.
4. 간격 필드에서 값을 사용자 정의.

### SNS 알림 문제

modular input 모듈은 비활성 상태이므로 AWS가 AWS SNS에 올 바르고 올바른지 확인할 수 없음. AWS SNS 계정으로 메시지를 보낼 수없는 경우 다음 절차를 수행 할 수 있음.

- AWS에 SNS 주제 이름이 존재하고 region ID가 올바르게 구성되었는지 확인.
- AWS의 Splunk Add-on에서 AWS 계정이 올바르게 구성되었는지 확인.

그래도 문제가 지속되면 다음 검색을 수행하여 AWS SNS 로그를 확인할 수 있음

`index=_internal sourcetype=aws:sns:alert:log"`

### Proxy settings for VPC endpoints

VPC 엔드포인트와 함께 프록시를 사용하는 경우 `$SPLUNK_HOME/etc/splunk-launch.conf`에 정의된 프록시 설정을 확인. 예를 들면 다음과 같음.

`no_proxy = 169.254.169.254,127.0.0.1,s3.amazonaws.com,[s3-ap-southeast-2.amazonaws.com|http://s3-ap-southeast-2.amazonaws.com/]`

각 S3region 엔드포인트를 no_proxy 설정에 추가하고 s3-\<your_aws_region\>.amazonaws.com의 올바른 호스트 이름을 사용해야 함. no_proxy 설정은 IP 주소 사이에 공백을 허용하지 않음.

## Splunk Add-on for AWS에 대한 Billing 데이터 액세스

Splunk Add-on for Amazon Web Services은 S3Bucket에서 일반 데이터 추출을 지원. S3Bucket에서 추출하려는데이터의 한 예는 AWS Billing Report 데이터임. Billing input을 사용하여 AWS Billing Report를 수집 한 다음이 Add-on에 포함된 사전 작성된 리포트를 사용하여 유용한 정보를 추출함. Add-on의 사전 빌드된 보고서는 AWS 보고서 형식을 기반으로 하므로 이 데이터에 쉽게 액세스하고 작업할 수 있음. 이 보고서를 Splunk 플랫폼을 사용하여 다른 S3데이터를 탐색하는 방법의 예로 사용할 수 있음.

> Note : Billing input은 AWS Marketplace 요금에 대한 Billing Report를 수집하지 않음.

### Billing Report 수집 행동

Amazon Web Services는 AWS 설명서에서 자세한 내용을 볼 수 있는 4가지 고유 한 Billing Report를 제공 (<http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/detailed-billing-reports.html#d0e2817>). Splunk Add-on for AWS을 사용하여 네 가지 유형의 Billing Report를 수집할 수 있음.

AWS Billing 서비스는 이 월간 마지막 날이 며칠 후에 최종 보고서가 완성 될 때까지 이 보고서 4개 모두를 지속적으로 업데이트함. 보고서가 완료될 때까지 일일 업데이트는 가장 최근 날짜의 활동에 대한 새로운 결제 정보를 추가하고 이전에 보고 된 광고 항목을 업데이트함. 예를 들어 Billing 서비스는 이미 통과한 이벤트에 대한 가격 할인을 다시 계산할 수 있음.

보고서의 모든 데이터가 업데이트 될 수 있기 때문에 Add-on은 네 가지 보고서 유형 중 하나를 가져올 때마다 전체 Billing Report를 가져옴. Monthly Report 및 월별 비용 할당 보고서는 매우 작기 때문에 기본적으로 Add-on이 매일 이러한 정보를 검색하므로 같은 (작은) 보고서가 여러 번 생성됨. 그러나 자세한 보고서는 매우 크기 때문에 Add-on은 당월 이전 달 동안이 보고서만 수집.

기본적으로 Add-on은 사용 가능한 모든 달에 대한 수집 기준과 일치하는 사용 가능한 모든 보고서를 수집. 예를 들어 Splunk Add-on for AWS을 2016년 2월 15일에 설치하고 Monthly cost allocation Report와 리소스 및 태그가 포함된 Detailed Billing Report를 모두 수집하도록 입력을 구성한다고 가정함. 첫날 Add-on은 2016년 2월 현재의 Monthly Report를 2015년 2월 16일까지 수집하고 이전 달의 모든 Monthly Report를 계정에 사용할 수있게함. Add-on은 2016년 1월의 상세 보고서와 계정에서 사용할 수 있는 이전 달의 모든 세부 보고서도 수집. 이후의 모든 날에는 최신 버전의 Monthly Report가 최신 날짜로 다운로드됨. 또한 가장 최근에 완료 한 달 (이 경우에는 1월)의 etag을 확인. AWS Billing 서비스에서 제공되는 최신 1월 세부 보고서에 대한 자세한 보고서를 확인. 동일하면 월이 끝날 때까지 상세 보고서를 다시 다운로드하지 않음. 3월 1일에 Add-on은 2월에 대한 상세 보고서를 매일 보고서의 etag가 변경되지 않을 때까지 다운로드하기 시작.

cron 일정 및 정규식을 사용하여 수집하는 보고서 수를 제어하는 ​​방법에 대한 자세한 내용은 [configuring billing inputs](http://docs.splunk.com/Documentation/AddOns/released/AWS/Billing) 지침을 참조.

Splunk 플랫폼의 보고서 데이터에 액세스하려면 Add-on에 포함된 보고서를 사용하여 최신 스냅샷 참조. 보고서 조정은 지원되지 않음.

### Billing Report 유형

#### Monthly Report

**Monthly Report**에는 계정 및 월별 라인 항목의 IAM 사용자가 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됨. 청구 및 비용 관리 콘솔의 청구서 페이지에서이 보고서를 다운로드 할 수 있음.

파일 이름 형식 : {AWS account number}-aws-billing-csv-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 Add-on이 전체 보고서를 하루에 한 번 가져옴.

#### Monthly cost allocation Report

**Monthly cost allocation Report**에는 Monthly Report와 동일한 데이터가 포함되어 있지만 작성한 비용 할당 태그도 포함됨. 지정한 Amazon S3Bucket에서 이 보고서를 가져와야 함. 표준 AWS 저장 속도가 적용.

파일 이름 형식 : {AWS 계정 번호} -aws-cost-allocation-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 Add-on이 전체 보고서를 하루에 한 번 가져옴.

#### Detailed Billing Report

**Detailed Billing Report**에는 계정 및 IAM 사용자가 시간별 광고 항목에서 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됨. 지정한 Amazon S3Bucket에서이 보고서를 가져와야 함. 표준 AWS 저장 속도가 적용.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-detailed-line-items-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 Add-on은 월이 끝난 후에 만 ​​보고서를 수집. Add-on은 Amazon Billing 서비스에 의해 완료될 때까지 하루에 한 번 보고서를 계속 수집.

#### 리소스 및 태그가 포함된 Detailed Billing Report

리소스 및 태그가 포함된 **Detailed Billing Report**에는 Detailed Billing Report와 동일한 데이터가 포함되어 있지만 계정에서 사용된 AWS 리소스에 대해 생성한 비용 할당 태그 및 ResourceID도 포함됨. 지정한 Amazon S3Bucket에서이 보고서를 가져와야 함. 표준 AWS 저장 속도가 적용.

파일 이름 형식 : {AWS account number}-aws-billing-detailed-line-items-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 Add-on은 월이 끝난 후에만 ​​보고서를 수집. Add-on은 Amazon Billing 서비스에 의해 완료될 때까지 하루에 한 번 보고서를 계속 수집.

### Billing 데이터의 이벤트 유형

Splunk 플랫폼은 소스 유형 `aws:billing` 사용하여 두 가지 유형의 Billing 데이터를 인덱싱함.

- 이벤트 유형이 `aws_billing_monthly_report` 인 Monthly Report
- 이벤트 유형이 `aws_billing_detail_report` 인 세부 보고서

### Add-on의 미리 구성된 보고서에 액세스

Splunk Add-on for Amazon Web Services에는 색인된 Billing Report 데이터를 기반으로하는 여러 보고서가 포함. **Home > Reports**를 클릭하고 접두어가 `AWS Bill-`인 항목을 찾으면 Splunk Web에서 저장된 보고서를 찾을 수 있음. Saved Search 중 일부가 테이블을 반환. 다른 것은 `AWS Bill -` 지금까지의 총비용과 같은 단일 값을 반환.

AWS는 당월의 Billing Report의 여러 스냅샷을 S3Bucket에 저장하기 때문에 Splunk 플랫폼은 일반적으로 여러 Monthly Report 스냅샷을 인덱싱함. 가장 최근의 Monthly Report 스냅샷을 얻으려면 **Home > Reports**를 클릭하고 저장된 보고서 인`AWS Bill - Monthly Latest Snapshot`여십시오. 또는 검색 문자열을 사용하여 검색 : `| savedsearch "AWS Bill - Monthly Latest Snapshot"`

**Home > Reports**를 클릭하고 `AWS Bill - Daily Cost`라는 저장된 보고서를 열면 가장 최근의 상세 보고서를 얻을 수 있음. 또는 검색 문자열`|`을 사용하여 검색. `| savedsearch "AWS Bill - Daily Cost"`. 보고서의 데이터 양이 많아 자세한 보고서를 검색하는 속도가 느려질 수 있음. Splunk은 상세 보고서에 대한 검색을 가속화 할 것을 권장.

#### Report sources

저장된 보고서는 CloudWatch의 결제 통계 데이터 대신 AWS Billing Report를 기반으로 함. 기본적으로 총계 또는 Monthly Report는 AWS Monthly Report (`*-aws-billing-csv-yyyy-mm.csv` or `*-aws-cost-allocation-yyyy-mm.csv`)에서 색인된 데이터를 기반으로 함. Daily Report는 AWS Detailed Report (`*-aws-billing-detailed-line-items-yyyy-mm.csv.zip` or `*-aws-billing-detailed-line-items-with-resources-and-tags-yyyy-mm.csv.zip`).

#### Default index behavior

기본적으로 보고서는 기본 Index인 main에서 데이터를 찾음. 데이터 입력을 구성 할 때 기본 인덱스를 변경한 경우 기본 검색 인덱스 목록에 인덱스를 포함 시키거나 두 개의 보고서를 변경하여 사용자 지정 인덱스로 필터링하지 않으면 보고서가 작동하지 않음.

기본 검색 인덱스 목록에 사용자 정의 색인을 포함하려면 다음을 수행.

1. **Settings > Users and authentication > Access controls > Roles > [Role that uses the saved searches] > Indexes searched by default**을 클릭.
2. 기본 검색 인덱스 목록에 사용자 정의 색인을 포함.
3. Saved Search을 사용하는 각 역할에 대해 이를 반복.

Saved Search을 변경하여 맞춤 색인으로 필터링하려면 다음을 수행.

1. Saved Search `AWS Bill - Monthly Latest Snapshot`.
2. 필터를 추가하여 구성한 색인을 지정. 예를 들어,`index = new_index`.
3. Saved Search 내용을 저장.
4. 다른 Saved Search 인 `AWS Bill - Detailed Cost`에 대해 이 단계를 반복.

## Splunk Add-on for AWS Lookup

Splunk Add-on for AWS에는 8개의 Lookup 포함. Lookup 파일은 AWC 서비스의 필드를 Splunk 플랫폼의 CIM 호환 또는 사람이 읽을 수 있는 값에 매핑함. 검색 파일은 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/lookups`에 있음.

<table>
<tr><td>Filename</td><td>Purpose</td></tr>
<tr><td>aws_config_action_lookup.csv</td><td>상태 필드를 작업 필드에 대한 CIM 호환 값으로 매핑함.</td></tr>
<tr><td>aws_config_object_category_lookup.csv</td><td>다양한 AWS Config 객체 카테고리를 object_category 필드의 CIM 호환 값으로 정렬함.</td></tr>
<tr><td>aws-cloudtrail-action-status.csv</td><td>eventName 및 errorCode 필드를 동작 및 상태에 대한 CIM 호환 값에 매핑함.</td></tr>
<tr><td>aws-cloudtrail-changetype.csv</td><td>eventSource를 change_type 필드의 CIM 호환 값에 매핑함.</td></tr>
<tr><td>aws-health-error-type.csv</td><td>ErrorCode를 ErrorDetail, ErrorCode, ErrorDetail으로 매핑함.</td></tr>
<tr><td>aws-log-sourcetype-modinput.csv</td><td>소스 유형을 modinput으로 매핑</td></tr>
<tr><td>cloudfront_edge_location_lookup</td><td>x_edge_location 값을 사람이 읽을 수 있는 edge_location_name으로 매핑함.</td></tr>
<tr><td>vendor-product-aws-cloudtrail.csv</td><td>소스 유형에 따라 공급 업체, 제품 및 appfields에 대한 CIM 호환 값을 정의.</td></tr>
<tr><td>vpcflow_action_lookup.csv</td><td>숫자 프로토콜 코드를 CIM 호환 프로토콜 필드와 사람이 읽을 수 있는 protocol_full_name으로 매핑함.</td></tr>
<tr><td>vpcflow_protocol_code_lookup.csv</td><td>vpcflow_action 필드를 CIM 호환 액션 필드에 매핑함.</td></tr>
<tr><td>VmSizeToResources.csv</td><td>instance_type 필드를 CIM 호환 cpu_cores, mem_capacity 필드에 매핑함.</td></tr>
</table>

## Splunk Add-on for AWS 데이터 입력을 위한 성능 참조

많은 요소가 처리량 성능에 영향을 줌. Splunk Add-on for AWS이 입력 데이터를 수집하는 속도는 배포 토폴로지, 버킷의 키 수, 파일 크기, 파일 압축 형식, 파일의 이벤트 수, 이벤트 크기 및 기타 변수의 수에 따라 다름. 물론, 하드웨어 및 네트워킹 조건.

이 절에서는 특정 작동 조건에서 측정된 처리량 데이터를 제공하고 성능 테스트 결과에서 AWS 추가 처리 성능 조정에 대한 대략적인 결론과 지침을 제시함. 자체 생산 환경에서 AWS Add-on 처리량 성능을 평가하고 최적화하기 위한 기초로 여기 정보를 사용함. 성능은 사용자 특성, 응용 프로그램 사용량, 서버 구성 및 기타 요인에 따라 다를 수 있으므로 특정 성능 결과는 보장할 수 없음. 정확한 성능 튜닝 및 사이징에 대해서는 Splunk Support에 문의함.

### 참조 하드웨어 및 소프트웨어 환경

여기에 제공된 처리량 데이터 및 결론은 다음 환경에서 실행되는 Splunk 인스턴스 (전용 Heavy Forwarder 및 인덱서)를 사용한 성능 테스트를 기반으로 함.

<table>
<tr><td>Instance type</td><td>M4Double Extra Large (m4.4xlarge)</td></tr>
<tr><td>Memory</td><td>64GB</td></tr>
<tr><td>Compute Units (ECU)</td><td>53.5</td></tr>
<tr><td>vCPU</td><td>16</td></tr>
<tr><td>Storage (GB)</td><td>0(EBS only)</td></tr>
<tr><td>Arch</td><td>64-bit</td></tr>
<tr><td>EBS Optimized (Max Bandwidth)</td><td>2000Mbps</td></tr>
<tr><td>Network performance</td><td>High</td></tr>
</table>

다음 설정은 heavy forwarder의 `outputs.conf`에 설정되어 있음 :

`useACK = true`
`maxQueueSize = 15MB`

### 측정된 성능 데이터

여기에 제공된 처리량 데이터는 특정 작동 조건에서 성능 테스트에서 달성된 각 단일 입력에 대한 최대 성능이며 하드웨어 및 소프트웨어 변수가 변경되면 변경 될 수 있음. 매우 거친 참조용으로만 이 데이터를 사용함.

#### 단일 입력 최대 처리량

<table>
<tr><td>Data Input</td><td>Sourcetype</td><td>Max Throughput (KB/s)</td><td>Max EPS (event/s)</td><td>Max Throughput (GB/day)</td></tr>
<tr><td>Generic S3</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>17,000</td><td>86,000</td><td>1,470</td></tr>
<tr><td>Generic S3</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>11,000</td><td>35,000</td><td>950</td></tr>
<tr><td>Incremental S3</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>11,000</td><td>43,000</td><td>950</td></tr>
<tr><td>Incremental S3</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>7,000</td><td>10,000</td><td>600</td></tr>
<tr><td>SQS-based S3</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>12,000</td><td>50,000</td><td>1,000</td></tr>
<tr><td>SQS-based S3</td><td>aws:elb:accesslogs<br/>
(gz, syslog, event size 250B, S3key size 2MB)</td><td>24,000</td><td>100,000</td><td>2,000</td></tr>
<tr><td>SQS-based S3</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>13,000</td><td>19,000</td><td>1,100</td></tr>
<tr><td>CloudWatch logs [1]</td><td>aws:cloudwatchlog:vpcflow</td><td>1,000</td><td>6,700</td><td>100</td></tr>
<tr><td>CloudWatch<br/>
(ListMetric, 10,000metrics)</td><td>aws:cloudwatch</td><td>240(Metrics/s)</td><td>NA</td><td>NA</td></tr>
<tr><td>CloudTrail</td><td>aws:cloudtrail<br/>
(gz, json, sqs=1000, 9K events/key)</td><td>5,000</td><td>7,000</td><td>400</td></tr>
<tr><td>Kinesis</td><td>aws:cloudwatchlog:vpcflow<br/>
(json, 10shards)</td><td>15,000</td><td>125,000</td><td>1,200</td></tr>
<tr><td>SQS</td><td>aws:sqs<br/>
(json, event size 2.8K)</td><td>N/A</td><td>160</td><td>N/A</td></tr>
</table>

[1] 입력 스트림이 1k보다 크면 API 조절 오류가 발생.

#### 다중 입력 최대 처리량

다음 처리량 데이터는 인덱서 클러스터 분산 환경에서 Heavy Forwarder에 구성된 여러 입력을 사용하여 측정.

> Note : AWS 계정을 더 많이 구성하면 API 사용 증가로 인해 CPU 사용량이 증가하고 처리량 성능이 저하됨. Splunk Add-on for AWS을 구성 할 때 AWS 계정을 통합하는 것이 좋음.

<table>
<tr><td>Data Input</td><td>Sourcetype</td><td>Max Throughput (KB/s)</td><td>Max EPS (events/s)</td><td>Max Throughput (GB/day)</td></tr>
<tr><td>Generic S3</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>23,000</td><td>108,000</td><td>1,980</td></tr>
<tr><td>Generic S3</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>45,000</td><td>130,000</td><td>3,880</td></tr>
<tr><td>Incremental S3</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>34,000</td><td>140,000</td><td>2,930</td></tr>
<tr><td>Incremental S3</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>45,000</td><td>65,000</td><td>3,880</td></tr>
<tr><td>SQS-based S3[1]</td><td>aws:elb:accesslogs<br/>
(plain text, syslog, event size 250B, S3key size 2MB)</td><td>35,000</td><td>144,000</td><td>3,000</td></tr>
<tr><td>SQS-based S3[1]</td><td>aws:elb:accesslogs<br/>
(gz, syslog, event size 250B, S3key size 2MB)</td><td>42,000</td><td>190,000</td><td>3,600</td></tr>
<tr><td>SQS-based S3[1]</td><td>aws:cloudtrail<br/>
(gz, json, event size 720B, S3key size 2MB)</td><td>45,000</td><td>68,000</td><td>3,900</td></tr>
<tr><td>CloudWatch logs</td><td>aws:cloudwatchlog:vpcflow</td><td>1,000</td><td>6,700</td><td>100</td></tr>
<tr><td>CloudWatch (ListMetric)</td><td>aws:cloudwatch<br/>
(10,000metrics)</td><td>240(metrics/s)</td><td>NA</td><td>NA</td></tr>
<tr><td>CloudTrail</td><td>aws:cloudtrail<br/>
(gz, json, sqs=100, 9K events/key)</td><td>20,000</td><td>15,000</td><td>1,700</td></tr>
<tr><td>Kinesis</td><td>aws:cloudwatchlog:vpcflow<br/>
(json, 10shards)</td><td>18,000</td><td>154,000</td><td>1,500</td></tr>
<tr><td>SQS</td><td>aws:sqs<br/>
(json, event size 2.8K)</td><td>N/A</td><td>670</td><td>N/A</td></tr>
</table>

[1] SQS-Based S3입력의 성능 테스트는 하나의 Heavy Forwarder 인스턴스에서 4개의 입력을 실행할 때 최적의 성능 처리량에 도달함을 나타냄. 이러한 병목 현상을 넘어 높은 처리 성능을 달성하기 위해 최대 4개의 SQS-Based S3입력으로 구성된 다수의 Heavy Forwarder 인스턴스를 만들어 동일한 SQS 대기열에서 메시지를 소비하여 데이터를 동시에 수집함으로써 데이터 수집을 더욱 확장 할 수 있음.

#### Heavy Forwarder 당 최대 입력 벤치마크

다음 입력 번호 한도는 CPU 및 메모리 리소스를 최대한 활용하는 인덱서 클러스터 분산 환경에서 Heavy Forwarder에 구성된 여러 입력을 사용하여 측정.

이벤트 크기가 작고 버킷 당 키 수가 적거나 사용 가능한 CPU 및 메모리 리소스가 많을 경우 테이블에 표시된 최대 입력 수보다 많은 입력을 구성 할 수 있음.

<table>
<tr><td>Data Input</td><td>Sourcetype</td><td>Format</td><td>Number of Keys/Bucket</td><td>Event Size</td><td>Max Inputs</td></tr>
<tr><td>S3</td><td>aws:s3</td><td>zip, syslog</td><td>100K</td><td>100B</td><td>300</td></tr>
<tr><td>S3</td><td>aws:cloudtrail</td><td>gz, json</td><td>1,300K</td><td>1KB</td><td>30</td></tr>
<tr><td>Incremental S3</td><td>aws:cloudtrail</td><td>gz, json</td><td>1,300K</td><td>1KB</td><td>20</td></tr>
<tr><td>SQS-based S3</td><td>aws:cloudtrail, aws:config</td><td>gz, json</td><td>1,000K</td><td>1KB</td><td>50</td></tr>
</table>

#### Generic S3입력에 대한 메모리 사용 벤치마크

<table>
<tr><td>Event Size</td><td>Number of Events per Key</td><td>Total Number of Keys</td><td>Archive Type</td><td>Number of Inputs</td><td>Memory Used</td></tr>
<tr><td>1K</td><td>1,000</td><td>10,000</td><td>zip</td><td>20</td><td>20G</td></tr>
<tr><td>1K</td><td>1,000</td><td>1,000</td><td>zip</td><td>20</td><td>12G</td></tr>
<tr><td>1K</td><td>1,000</td><td>10,000</td><td>zip</td><td>10</td><td>18G</td></tr>
<tr><td>100B</td><td>1,000</td><td>10,000</td><td>zip</td><td>10</td><td>15G</td></tr>
</table>

### 성능 튜닝 및 사이징 가이드 라인

예상 AWS 데이터 처리량을 달성하지 못하면 다음 단계에 따라 처리량 성능을 조정.

1. 높은 수준의 처리량 성능을 달성하지 못하도록 하는 시스템의 병목 현상을 식별함. AWS 데이터 처리의 병목 현상은 다음 구성 요소 중 하나에 있을 수 있음.
    - Splunk Add-on for AWS : API 호출을 통해 AWS 데이터를 가져올 수 있는 용량
    - Heavy Forwarder : 데이터를 구문 분석하여 인덱서 계층으로 전달하는 기능으로, 구문 분석, 병합 및 입력 파이프 라인의 처리량이 필요함.
    - 인덱서 : 인덱스 파이프 라인 처리량
    Heavy Forwarder 및 인덱서의 인덱싱 성능 문제를 해결하려면 용량 계획 설명서에서 [Troubleshooting indexing performance](http://docs.splunk.com/Documentation/Splunk/7.1.1/Troubleshooting/Troubleshootindexingperformance) 참조.
    체인은 가장 약한 링크만큼 강력함. 병목 현상의 용량은 전체 시스템 전체의 용량임. 병목 구성 요소의 성능을 식별하고 조정하여 전체 시스템 성능을 향상시킬 수 있음.
2. 병목 요소의 성능을 조정.
    부하가 많은 전달자 또는 인덱서에 병목 현상이있는 경우 용량 계획 안내서의 [Summary of performance recommendations](http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/Summaryofperformancerecommendations) 참조.
    병목 현상이 Splunk Add-on for AWS에있는 경우 일반적으로 AWS 데이터 입력 처리량에 영향을 미치는 다음 주요 요소를 조정.
    - 병렬화 설정
        최적의 쓰루풋 성능을 얻으려면, 리소스 용량이 허락한다면 `server.conf`에 `parallelIngestionPipelines` 값을 2로 설정할 수 있음. `parallelIngestionPipelines`에 대한 자세한 내용은 Splunk Enterprise Capacity Planning Manual의 [Parallelization settings](http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/Parallelization) 참조.

    - AWS 데이터 입력
        리소스 부족이 없는 경우 Add-on에 입력을 추가하면 처리량이 증가하지만 메모리와 CPU를 더 많이 소모함. 메모리 또는 CPU가 부족할 때까지 처리량을 향상시키기 위해 입력 수를 늘림.
        SQS-Based S3입력을 사용하는 경우 동일한 SQS 대기열에서 메시지를 소비하도록 여러 Heavy Forwarder에서 더 많은 입력을 구성하여 데이터 수집을 수평 확장 할 수 있음.
    - 버킷의 키 수
        Generic S3및 Incremental S3입력의 경우 버킷의 키 (또는 객체) 수는 초기 데이터 수집 성능에 영향을 미치는 요소임. Generic 또는 Incremental S3입력이 처음으로 버킷에서 데이터를 수집하면 버킷에 포함된 키가 많을수록 목록 작업을 완료하는데 더 많은 시간이 소요되고 더 많은 메모리가 소비됨. 버킷의 많은 수의 키는 초기 데이터 수집에서 S3입력을 위해 엄청난 양의 메모리가 필요하며 Add-on에서 구성 할 수 있는 입력 수를 제한함.
        해당되는 경우 로그 파일 접두어를 사용하여 버킷의 하위 키를 작은 그룹으로 분할하고 다른 입력을 구성하여 개별적으로 처리 할 수 ​​있음. 로그 파일 접두어를 사용하도록 입력을 구성하는 방법에 대한 자세한 내용은 [Add an S3input for Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/S3) 참조.
        SQS-Based S3입력의 경우 동일한 SQS 대기열에서 소비 된 메시지를 기반으로 데이터 수집을 수평 확장 할 수 있기 때문에 버킷의 키 수는 주요 요인이 아님.
    - 파일 형식
        압축 된 파일은 일반 텍스트 파일보다 훨씬 많은 메모리를 사용함.
1. 병목 현상을 해결했으면 개선 된 성능이 요구 사항을 충족시키는지 확인. 그렇지 않은 경우 이전 단계를 계속 진행하여 시스템에서 다음 병목 현상을 식별하고 예상되는 전체 처리량 성능이 달성 될 때까지 처리함.

## Splunk Add-on for AWS의 Kinesis 입력 성능 참조

이 페이지는 Splunk Add-on for AWS의 Kinesis 입력에 대한 Splunk의 성능 테스트에 대한 참조 정보를 제공함. 이 테스트는 Kinesis 입력이 처음 도입되었을 때 버전 4.0.0에서 수행됨. 이 정보를 사용하여 Kinesis 데이터 수집 작업의 성능을 향상시킬 수 있음.

> Note : 파일 크기, 파일 압축, 이벤트 크기, 배포 아키텍처 및 하드웨어를 비롯한 많은 요인이 성능 결과에 영향을 줌. 이 결과는 참조 정보를 나타내며 모든 환경에서 성능을 나타내지는 않음.

### 요약

다른 환경에서의 결과는 다양하지만, Splines의 Kinesis 입력에 대한 성능 테스트 결과는 다음과 같음.

- 각각의 Kinesis 입력은 최대 6MB/s의 데이터를 처리 할 수 ​​있으며 일일 섭취량은 500GB임.
- 파편이 많을수록 성능이 약간 향상 될 수 있음. 큰 물줄기에는 세 조각이 좋음.

### 테스트 아키텍처

Splunk는 m4.4xlarge AWS EC2인스턴스에서 단일 인스턴스 Splunk Enterprise 6.4.0을 사용하여 Kinesis 입력의 성능을 테스트하여 CPU, 메모리, 저장소 및 네트워크에 병목 현상이 발생하지 않도록 보장함. 인스턴스 사양 :

<table>
<tr><td>Instance type</td><td>M4Quadruple Extra Large (m4.4xlarge)</td></tr>
<tr><td>Memory</td><td>64GB</td></tr>
<tr><td>ECU</td><td>53.5</td></tr>
<tr><td>Cores</td><td>16</td></tr>
<tr><td>Storage</td><td>0GB (EBS only)</td></tr>
<tr><td>Architecture</td><td>64-bit</td></tr>
<tr><td>Network performance</td><td>High</td></tr>
<tr><td>EBS Optimized: Max Bandwidth</td><td>250MB/s</td></tr>
</table>

### Test scenario

Splines은 다음 매개 변수를 테스트하여 Kinesis 스트림을 통해 수집된 대용량 VPC 흐름 로그의 사용 사례를 타겟팅함.

- Shard numbers: 3, 5, and 10shards
- Event size: 120bytes per event
- Number of events: 20,000,000
- Compression: gzip
- Initial stream position: TRIM_HORIZON

AWS는 각 샤드가 초당 5회의 읽기 트랜잭션, 초당 최대 2MB의 읽기 속도로 제한되어 있다고 보고함. 따라서 10개의 샤드로 이론 상한선은 초당 20MB임.

### Test results

스플 렁크 (Splunk)는 분당 최대 600만 이벤트의 데이터 처리 속도 (초당 100,000이벤트)를 관찰. 각 이벤트는 120바이트이므로 최대 처리량은 10MB/s임.

Splunk는 단일 Kinesis 모듈 형 입력에 대해 평균 6MB/s의 처리량을 보거나 약 500GB의 일일 처리량을 관찰.

샤드 수를 10개 샤드에서 3개 샤드로 줄인 후에 스 프렁크는 약 10%의 처리량 다운 그레이드를 관찰.

테스트 중에 Splunk는 인스턴스에서 다음과 같은 리소스 사용을 관찰.

- 약 30%의 표준화 된 CPU 사용
- 약 700MB의 파이썬 메모리 사용

인덱서는 CPU 소비량이 가장 크며 모듈 식 입력은 최대 메모리 소비임.

> Note : 호출이 10MB의 데이터를 반환하고 다음 5초 내에 후속 호출이 이루어지면 AWS는 ProvisionedThroughputExceededException을 발생시킴. Splunk는 1~5분마다 3개의 샤드로 테스트하는 동안이 오류를 관찰.

## Splunk Add-on for AWS에 SNS Alert 사용

> Note : 사용자 지정 검색 명령 및 사용자 지정 Alert Action을 사용하려면 Splunk 관리자이거나 적절한 기능이있는 사용자 여야함.

- Splunk 플랫폼 6.5.0이상을 사용하는 경우 `list_storage_passwords`
- 이전 버전의 Splunk 플랫폼을 사용하고 있다면 `admin_all_objects`

### 사용자 정의 검색 명령 사용

Splunk Add-on for AWS에는 AWS SNS에 경고를 보내는 사용자 정의 검색 명령이 포함.

```sql
...| eval message="My Message" | eval entity="My Entity" | eval correlation_id="1234567890" | awssnsalert account=real region="ap-southeast-1" topic_name="ta-aws-sns-ingestion" publish_all=1
```

<table>
<tr><td>속성</td><td>설명</td></tr>
<tr><td>account</td><td>필수 항목임. Add-on에 구성된 AWS 계정 이름</td></tr>
<tr><td>region</td><td>필수 항목임. AWS 지역 이름</td></tr>
<tr><td>topic_name</td><td>필수 항목임. 경고 메시지가이 AWS SNS 주제 이름으로 전송됨.</td></tr>
<tr><td>message</td><td>필수 항목임. Splunk Add-on for AWS이 AWS SNS로 보낸 메시지임.</td></tr>
<tr><td>publish_all</td><td>publish_all을 0또는 1로 설정할 수 있음. publish_all = 1로 설정하면이 Add-on이이 검색에서 모든 레코드를 보낼 것임을 의미함. publish_all = 0으로 설정하면이 Add-on이 첫 번째 결과 만이 검색에 전송됨을 의미함. 이 필드의 기본값은 0임.</td></tr>
</table>

### Alert Action 사용

Splunk Add-on for AWS은 맞춤형 알림 작업에서 자동 사건 및 이벤트 생성 및 사건 업데이트를 지원. 맞춤 알림 작업은 Splunk 플랫폼 버전 6.3.0이상에서 사용할 수 있음.

사용자 정의 알림 작업에서 새 인시던트 또는 이벤트를 생성하려면 다음과 같이함.

1. AWS SNS에서 사건 또는 이벤트 생성을 트리거하는데 사용할 검색 문자열을 작성함.
2. **Save As > Alert**을 클릭.
3. 경고 양식을 작성함. 경고에 고유 한 이름을 지정하고 경고가 실시간 경고인지 또는 예정된 경고인지 나타내십시오. 자세한 내용은 Splunk Enterprise 설명서의 Alerting Manual에서 [Getting started with Alerts](http://docs.splunk.com/Documentation/Splunk/7.1.1/Alert/Aboutalerts) 참조.
4. 트리거 동작에서 **Add Actions**를 클릭.
5. 경고에서 AWS SNS에 이벤트를 만들려면 목록에서 **AWS SNS Alert** 선택.
6. 표시된 모든 필수 필드의 값을 입력함.

<table>
<tr><td>필드</td><td>설명값</td></tr>
<tr><td>Account</td><td>필수 항목임. Splunk Add-on for AWS에 구성된 계정 이름임.</td></tr>
<tr><td>Region</td><td>필수 항목임. 이벤트가 전송 될 AWS SNS 영역임. 지역이 AWS SNS와 일치하는지 확인해야함.</td></tr>
<tr><td>Topic Name</td><td>필수 항목임. 이벤트가 전송 될 주제의 이름. 주제 이름이 AWS SNS에 있는지 확인해야함.</td></tr>
<tr><td>Correlation ID</td><td>선택 사항. 이 경고를 다른 이벤트와 연관시키는 ID임. 이 필드를 비워두면 기본적으로 $result.correlation_id$가 사용됨.</td></tr>
<tr><td>Entity</td><td>선택 사항. 이벤트, 경고와 관련된 객체 (예 : 호스트, 데이터베이스, EC2인스턴스)임. 이 필드를 비워두면 Splunk는 기본적으로 $result.entity$를 사용함.</td></tr>
<tr><td>Source</td><td>선택 사항. 이벤트 또는 경고의 출처. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result.source $를 사용함.</td></tr>
<tr><td>Timestamp</td><td>선택 사항. 이벤트 시간이 발생. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._time $을 사용함.</td></tr>
<tr><td>Event</td><td>선택 사항. 이벤트의 세부 사항. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._raw $를 사용함.</td></tr>
<tr><td>Message</td><td>필수 항목임. Splunk Add-on for AWS이 AWS SNS로 보낸 메시지임.</td></tr>
</table>