# 문제 해결

## AWS 용 Splunk 애드온 문제 해결

### 일반적인 문제 해결

모든 추가 기능에 적용 할 수있는 유용한 문제 해결 정보는 [추가 기능 문제 해결] (http://docs.splunk.com/Documentation/AddOns/released/Overview/Troubleshootadd-ons)을 참조하십시오. 이 [지원 및 리소스 링크] (http://docs.splunk.com/Documentation/AddOns/latest/Overview/Learnmoreandgethelp)에 액세스 할 수도 있습니다.

### 건강 체크 대시 보드

** Health Check ** 메뉴에서 대시 보드를 선택하여 데이터 수집 오류 및 성능 문제를 해결할 수 있습니다.

** 상태 개요 ** 대시 보드는 모든 입력 유형에 대한 데이터 수집 오류 및 성능 측정 항목을 한눈에 볼 수 있습니다.

- 오류 카테고리 별 오류 수
- 입력 유형, 호스트, 데이터 입력 및 오류 범주에 따른 시간별 오류 카운트
- 호스트, 입력 유형 및 데이터 입력에 따른 시간 경과에 따른 처리량

** S3 Health Details ** 대시 보드는 일반, 증분 및 SQS 기반 S3 입력 유형에 중점을두고 인덱싱 시간 지연 및 이러한 다목적 입력에 대한 자세한 오류 정보를 제공합니다.

건강 대시 보드를 사용자 정의 할 수 있습니다. [대시 보드 및 시각화] (http://docs.splunk.com)의 [대시 보드 편집기 정보] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Viz/CreateandeditdashboardsviatheUI) 항목을 참조하십시오. /Documentation/Splunk/7.1.1/Viz/Aboutthismanual) 매뉴얼을 참조하십시오.

### 내부 로그

문제 해결을 위해 내부 로그 데이터에 직접 액세스 할 수 있습니다. 이러한 원본 유형으로 수집 된 데이터는 상태 검사 대시 보드에서 사용됩니다.

<table>

<tr> <td> 데이터 소스 </td> </td> </td>
<tr> <td> splunk_ta_aws_cloudtrail_cloudtrail_ {input_name} .log의 로그입니다. </td> <td> aws : cloudtrail : log </td> </tr>
<tr> <td> splunk_ta_aws_cloudwatch.log의 로그입니다. </td> <td> aws : cloudwatch : log </td> </tr>
<tr> <td> splunk_ta_aws_cloudwatch_logs.log의 로그입니다. </td> <td> aws : cloudwatchlogs : log </td> </tr>
<tr> <td> splunk_ta_aws_config_ {input_name} .log에서 로그합니다. </td> <td> aws : config : log </td> </tr>
<tr> <td> splunk_ta_aws_config_rule.log에서 로그. </td> <td> aws : configrule : log </td> </tr>
</td> <td> aws : inspector : log </td> </tr> <tr> <td> <tr> <td>
<tr> <td> splunk_ta_aws_description.log에서 로그. </td> <td> aws : description : log </td> </tr>
<tr> <td> splunk_ta_aws_billing_ {input_name} .log에서 로그합니다. </td> <td> aws : billing : log </td> </tr>
<tr> <td> splunk_ta_aws_generic_s3_ {input_name}의 로그입니다. </td> <td> aws : s3 : log </td> </tr>
<tr> <td> splunk_ta_aws_logs_ {input_name} .log의 로그에서 각 증분 S3 입력에는 로그 파일에 입력 이름이있는 로그 파일이 하나 있습니다. </td> <td> aws : logs : log </td> tr>
<tr> <td> splunk_ta_aws_kinesis.log에서 로그. </td> <td> aws : kinesis : log </td> </tr>
<tr> <td> splunk_ta_aws_ sqs_based_s3_ {input_name}의 로그입니다. </td> <td> aws : sqsbaseds3 : log </td> </tr>
<tr> <td> splunk_ta_aws_sns_alert_modular.log 및 splunk_ta_aws_sns_alert_search.log의 로그입니다. </td> <td> aws : sns : alert : log </td> </tr>
<tr> <td> 부가 기능 또는 데이터 입력을 설정할 때 호출되는 REST API 핸들러로 채워진 splunk_ta_aws_rest.log의 로그 </td> <td> aws : resthandler : log </td> </tr>
<tr> <td> 모든 AWS 데이터 입력에 사용 된 프록시 처리기 인 splunk_ta_aws_proxy_conf.log의 로그 <awd : proxy-conf : log </td> </tr>
<tr> <td> S3, CloudWatch 및 SQS 커넥터로 채워진 splunk_ta_aws_s3util.log의 로그입니다. </td> <td> aws : resthandler : log </td> </tr>
<tr> <td> 공유 유틸리티 라이브러리 인 splunk_ta_aws_util.log에서 로그합니다. </td> <td> aws : util : log </td> </tr>
</table>

### 로그 수준 구성

1. Splunk Web의 홈 페이지 왼쪽 탐색 모음에서 ** Splunk 애드온 **을 클릭하십시오.
2. 앱 탐색 바에서 ** 구성 **을 클릭하십시오.
3. ** 로깅 ** 탭을 클릭하십시오.
4. 'INFO'의 기본값을 다른 사용 가능한 옵션 중 하나 인 DEBUG 또는 ERROR로 변경하여 필요에 따라 각 AWS 서비스의 로그 수준을 조정합니다.

> 참고 : 이러한 로그 수준 구성은 런타임 로그에만 적용됩니다. DEBUG의 구성 활동 로그에있는 일부 REST 엔드 포인트 로그 및 일부 유효성 검증 로그는 ERROR에 로그합니다. 이 레벨은 구성 할 수 없습니다.

### 계정 또는 입력 구성 중 문제를 저장하는 중

설정 페이지에서 AWS 계정을 구성하는 동안 오류가 발생하거나 저장하는 데 문제가 있으면`$ SPLUNK_HOME / etc / system / local / web.conf`로 이동하여 아래 표시된대로 시간 초과 설정을 변경하십시오.

```재산
  [설정]
  splunkdConnectionTimeout = 300
```

### 배포 서버로 배포 할 때의 문제

배포 서버를 사용하여 Amazon Web Services 용 Splunk 애드온을 여러 무거운 전달자에 배포하는 경우 배포 서버가 해시 공유를 지원하지 않기 때문에 각 인스턴스에 대한 Splunk Web 설치 UI를 별도로 사용하여 Amazon Web Services 계정을 구성해야합니다 인스턴스간에 암호 저장.

### S3 문제

#### S3 입력 성능 문제

단일 S3 버킷에 대해 여러 개의 S3 입력을 구성하여 성능을 향상시킬 수 있습니다. Splunk 플랫폼은 각 데이터 입력에 대해 하나의 프로세스를 수행하므로 시스템의 처리 능력이 충분하면 여러 입력으로 성능이 향상됩니다. [AWS 용 Splunk 애드온의 S3 입력에 대한 성능 참조] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3PerformanceReference)를 참조하십시오.

> 참고 : 중복 데이터 인덱싱을 방지하려면 동일한 버킷에 대한 여러 입력의 S3 키 이름이 겹치지 않도록하십시오.

#### S3 키 이름 화이트리스트 / 블랙리스트 필터링 문제

화이트리스트와 블랙리스트는 마지막 세그먼트뿐만 아니라 전체 키 이름과 일치합니다.

화이트리스트. * abc /.*는 /a/b/abc/e.gz와 일치합니다.

regex에 대한 추가 도움말 :

-이 블로그 게시물의 비디오보기 : <http://blogs.splunk.com/2008/10/22/all-my-regexs-live-in-texas/>
- Splunk Enterprise 설명서의 일부인 Knowledge Manager 설명서에서 "[Splunk 정규식 정보] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Knowledge/AboutSplunkregularexpressions)"를 읽으십시오.

#### S3 이벤트 행 문제 해결

인덱싱 된 S3 데이터의 줄 바꿈이 잘못된 경우 'props.conf'에 사용자 지정 소스 유형을 구성하여 이벤트에 대한 줄을 끊는 방법을 제어하십시오.

S3 이벤트가 너무 길어서 잘리는 경우`props.conf`에`TRUNCATE = 0`을 설정하여 줄 잘림을 방지하십시오.

자세한 내용은 Splunk Enterprise 설명서의 데이터 가져 오기 설명서에서 [이벤트 줄 바꿈 구성] (http://docs.splunk.com/Documentation/Splunk/latest/Data/Configureeventlinebreaking)을 참조하십시오.

### CloudWatch 구성 문제

#### 스로틀 링

CloudWatch 데이터가 많은 경우`index = _internal Throttling`을 검색하여 API 조절 문제가 발생하는지 확인하십시오. 그렇다면 AWS 지원 팀에 문의하여 CloudWatch API 속도를 높이십시오. 수집하는 메트릭 수를 줄이거 나 세분화하여 API 호출을 줄입니다.

#### 세분성

인덱싱 된 데이터의 세분성이 예상과 다를 경우 구성된 세분성이 선택한 측정 항목에 대해 AWS에서 지원하는 범위 내에 있는지 확인하십시오. 서로 다른 AWS 메트릭은 AWS에서 해당 메트릭을 허용하는 샘플링 기간을 기준으로 다른 최소 세분성을 지원합니다. 예를 들어 CPUUtilization은 5 분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4 시간의 샘플링 기간을가집니다.

선택한 메트릭의 샘플링 기간보다 작은 세분성을 구성한 경우 인덱싱 된 데이터의보고 된 세분성이 실제 세분화 된 세분성을 반영하지만 구성된 세분성으로 레이블이 지정됩니다. 문제가있는`local / inputs.conf` 클라우드 워치 스탠자를 지우고 새로 인덱싱 된 데이터가 정확하도록 지원되는 샘플링 세분성과 일치하도록 세분성 구성을 조정하고 데이터를 다시 색인화하십시오.

### CloudTrail 데이터 색인 문제

Splunk 플랫폼에서 CloudTrail 데이터가 표시되지 않는 경우이 문제 해결 프로세스를 따르십시오.

1. 다음을 검색하여 내부 로그를 검토하십시오.`index = _internal source = * cloudtrail *`
2. "Connected to SQS"문자열을 검색하여 Splunk 플랫폼이 SQS에 성공적으로 연결되어 있는지 확인하십시오.
3. Splunk 플랫폼이 메시지를 성공적으로 처리하는지 확인하십시오. "X 완료, Y 통보 일괄 처리 중 실패"패턴을 따르는 문자열을 찾으십시오.
4. Splunk 플랫폼이 메시지를 삭제하는지 확인하십시오. 패턴 "X를 가져 왔고, Y를 쓰고, 버려진 Z"를 따르는 문자열을 찾습니다.
5. Amazon Web Services 구성을 검토하여 SQS 메시지가 대기열에 있는지 확인하십시오. 메시지가 제거되고 로그에 입력 내용이 제거되지 않는다고 표시되지 않으면 큐에서 다른 스크립트 나 입력 메시지를 사용할 수 있습니다. 데이터 입력을 검토하여 동일한 대기열을 사용하도록 구성된 다른 입력이 없는지 확인하십시오.
6. AWS 콘솔로 이동하여 세부 정보가 1 분으로 설정된 CloudWatch 메트릭을 확인하여 추세를 확인합니다. 자세한 내용은 <https://aws.amazon.com/blogs/aws/amazon-cloudwatch-search-and-browse-metrics-in-the-console/>을 참조하십시오. 소비 된 메시지가 표시되지만 Splunk 플랫폼 입력이 메시지를 소비하지 않는 경우 동일한 대기열에 액세스하는 원격 서비스가 있는지 확인하십시오.

### 결제 보고서 문제

#### AWS에서 청구 보고서에 액세스하는 데 문제가 있습니다.

결제 입력을 구성 할 때 선택한 S3 버킷에서 사용할 수있는 결제 보고서가 있는지, 지정한 AWS 계정에 해당 버킷 내부의 파일을 읽을 수있는 권한이 있는지 확인하십시오.

#### 청구 보고서 데이터 이해 문제

Splunk은 추가 기능에 포함 된 [저장된 검색에 액세스] (http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata#Access_saved_searches)를 권장하여 요금 청구 보고서 데이터를 분석합니다.

#### 청구 데이터 간격 구성 문제

> 참고 : 청구 리포트 데이터의 기본 청구 데이터 수집 수집 간격은 라이센스 사용을 최소화하도록 설계되었습니다. 기본 동작을 검토하고 조심해서 조정하십시오.

Splunk Enterprise가 매월 및 세부 청구 보고서를 가져 오는 간격을 구성하려면 다음을 수행하십시오.

1. Splunk Web에서 AWS 입력 용 Splunk 애드온 화면으로 이동하십시오.
2. 새로운 대금 청구 입력을 생성하거나 클릭하여 기존 입력을 편집하십시오.
3. 설정 탭을 클릭하십시오.
4. 간격 필드에서 값을 사용자 정의하십시오.

### SNS 알림 문제

모듈 형 입력 모듈은 비활성 상태이므로 AWS가 AWS SNS에 올 바르고 올바른지 확인할 수 없습니다. AWS SNS 계정으로 메시지를 보낼 수없는 경우 다음 절차를 수행 할 수 있습니다.

- AWS에 SNS 주제 이름이 존재하고 region ID가 올바르게 구성되었는지 확인하십시오.
- AWS의 Splunk 애드온에서 AWS 계정이 올바르게 구성되었는지 확인하십시오.

그래도 문제가 지속되면 다음 검색을 수행하여 AWS SNS 로그를 확인할 수 있습니다

`index = _ 내부 sourcetype = aws : sns : alert : log "`

VPC 엔드 포인트의 프록시 설정

VPC 엔드 포인트와 함께 프록시를 사용하는 경우`$ SPLUNK_HOME / etc / splunk-launch.conf`에 정의 된 프록시 설정을 확인하십시오. 예를 들면 다음과 같습니다.

`no_proxy = 169.254.169.254,127.0.0.1, s3.amazonaws.com, [s3-ap-southeast-2.amazonaws.com | http : //s3-ap-southeast-2.amazonaws.com/]`

각 S3 region 엔드 포인트를 no_proxy 설정에 추가하고 s3 - \ <your_aws_region \>. amazonaws.com의 올바른 호스트 이름을 사용해야합니다. no_proxy 설정은 IP 주소 사이에 공백을 허용하지 않습니다.

## AWS 용 Splunk 애드온에 대한 청구 데이터 액세스

Amazon Web Services 용 Splunk 애드온은 S3 버킷에서 일반 데이터 추출을 지원합니다. S3 버킷에서 추출하려는 데이터의 한 예는 AWS 청구 보고서 데이터입니다. 청구 입력을 사용하여 AWS 청구 리포트를 수집 한 다음이 애드온에 포함 된 사전 작성된 리포트를 사용하여 유용한 정보를 추출하십시오. 추가 기능의 사전 빌드 된 보고서는 AWS 보고서 형식을 기반으로하므로이 데이터에 쉽게 액세스하고 작업 할 수 있습니다. 이 보고서를 Splunk 플랫폼을 사용하여 다른 S3 데이터를 탐색하는 방법의 예로 사용할 수 있습니다.

> 참고 : 결제 입력은 AWS Marketplace 요금에 대한 청구 보고서를 수집하지 않습니다.

### 청구 리포트 수집 행동

Amazon Web Services는 AWS 설명서에서 자세한 내용을 볼 수있는 4 가지 고유 한 청구 보고서를 제공합니다 (<http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/detailed-billing-reports.html#d0e2817>). AWS 용 Splunk 애드온을 사용하여 네 가지 유형의 청구 보고서를 수집 할 수 있습니다.

아마존 청구 서비스는이 월간 마지막 날이 며칠 후에 최종 보고서가 완성 될 때까지이 보고서 4 개 모두를 지속적으로 업데이트합니다. 보고서가 완료 될 때까지 일일 업데이트는 가장 최근 날짜의 활동에 대한 새로운 결제 정보를 추가하고 이전에보고 된 광고 항목을 업데이트합니다. 예를 들어 청구 서비스는 이미 통과 한 이벤트에 대한 가격 할인을 다시 계산할 수 있습니다.

보고서의 모든 데이터가 업데이트 될 수 있기 때문에 추가 기능은 네 가지 보고서 유형 중 하나를 가져올 때마다 전체 청구 보고서를 가져옵니다. 월별 보고서 및 월별 비용 할당 보고서는 매우 작기 때문에 기본적으로 추가 기능이 매일 이러한 정보를 검색하므로 같은 (작은) 보고서가 여러 번 생성됩니다. 그러나 자세한 보고서는 매우 크기 때문에 추가 기능은 당월 이전 달 동안이 보고서 만 수집합니다.

기본적으로 추가 기능은 사용 가능한 모든 달에 대한 수집 기준과 일치하는 사용 가능한 모든 보고서를 수집합니다. 예를 들어 AWS 용 Splunk 애드온을 2016 년 2 월 15 일에 설치하고 월간 비용 할당 보고서와 리소스 및 태그가 포함 된 세부 청구 보고서를 모두 수집하도록 입력을 구성한다고 가정합니다. 첫날 추가 기능은 2016 년 2 월 현재의 월별 보고서를 2015 년 2 월 16 일까지 수집하고 이전 달의 모든 월별 보고서를 계정에 사용할 수있게합니다. 추가 기능은 2016 년 1 월의 상세 보고서와 계정에서 사용할 수있는 이전 달의 모든 세부 보고서도 수집합니다. 이후의 모든 날에는 최신 버전의 월별 보고서가 최신 날짜로 다운로드됩니다. 또한 가장 최근에 완료 한 달 (이 경우에는 1 월)의 etag을 확인합니다. 아마존 청구 서비스에서 제공되는 최신 1 월 세부 보고서에 대한 자세한 보고서를 확인합니다. 동일하면 월이 끝날 때까지 상세 보고서를 다시 다운로드하지 않습니다. 3 월 1 일에 추가 기능은 2 월에 대한 상세 보고서를 매일 보고서의 etag가 변경되지 않을 때까지 다운로드하기 시작합니다.

cron 일정 및 정규식을 사용하여 수집하는 보고서 수를 제어하는 ​​방법에 대한 자세한 내용은 [대금 청구 입력 구성] (http://docs.splunk.com/Documentation/AddOns/released/AWS/Billing) 지침을 참조하십시오.

Splunk 플랫폼의 보고서 데이터에 액세스하려면 추가 기능에 포함 된 보고서를 사용하여 최신 스냅 샷을보십시오. 보고서 조정은 지원되지 않습니다.

### 결제 보고서 유형

#### 월별보고

** 월간 보고서 **에는 계정 및 월별 라인 항목의 IAM 사용자가 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됩니다. 청구 및 비용 관리 콘솔의 청구서 페이지에서이 보고서를 다운로드 할 수 있습니다.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-csv-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 추가 기능이 전체 보고서를 하루에 한 번 가져옵니다.

#### 월간 비용 할당 보고서

** 월간 비용 할당 보고서 **에는 월간 보고서와 동일한 데이터가 포함되어 있지만 작성한 비용 할당 태그도 포함됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야합니다. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-cost-allocation-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 추가 기능이 전체 보고서를 하루에 한 번 가져옵니다.

#### 세부 청구 보고서

** 세부 청구 보고서 **에는 계정 및 IAM 사용자가 시간별 광고 항목에서 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야합니다. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-detailed-line-items-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 추가 기능은 월이 끝난 후에 만 ​​보고서를 수집합니다. 애드온은 Amazon 청구 서비스에 의해 완료 될 때까지 하루에 한 번 보고서를 계속 수집합니다.

#### 리소스 및 태그가 포함 된 세부 청구 보고서

리소스 및 태그가 포함 된 ** 세부 청구 리포트 **에는 세부 청구 리포트와 동일한 데이터가 포함되어 있지만 계정에서 사용 된 AWS 리소스에 대해 생성 한 비용 할당 태그 및 ResourceID도 포함됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야합니다. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-detailed-line-items-with-resources-and-tags-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 추가 기능은 월이 끝난 후에 만 ​​보고서를 수집합니다. 애드온은 Amazon 청구 서비스에 의해 완료 될 때까지 하루에 한 번 보고서를 계속 수집합니다.

### 청구 데이터의 이벤트 유형

Splunk 플랫폼은 소스 유형`aws : billing`을 사용하여 두 가지 유형의 청구 데이터를 인덱싱합니다.

- 이벤트 유형이 'aws_billing_monthly_report` 인 월별 보고서
- 이벤트 유형이 'aws_billing_detail_report` 인 세부 보고서

### 부가 기능의 미리 구성된 보고서에 액세스합니다.

Amazon Web Services 용 Splunk 애드온에는 색인 된 청구 보고서 데이터를 기반으로하는 여러 보고서가 포함되어 있습니다. ** 홈> 보고서 **를 클릭하고 접두어가 'AWS Bill-'인 항목을 찾으면 Splunk Web에서 저장된 보고서를 찾을 수 있습니다. 저장된 검색 중 일부가 테이블을 반환합니다. 다른 것은`AWS Bill - 지금까지의 총비용 '과 같은 단일 값을 반환합니다.

AWS는 당월의 청구 보고서의 여러 스냅 샷을 S3 버킷에 저장하기 때문에 Splunk 플랫폼은 일반적으로 여러 월간 보고서 스냅 샷을 인덱싱합니다. 가장 최근의 월간 보고서 스냅 샷을 얻으려면 ** 홈> 보고서 **를 클릭하고 저장된 보고서 인`AWS Bill - Monthly Latest Snapshot`을여십시오. 또는 검색 문자열을 사용하여 검색하십시오 :`| savedsearch "AWS Bill - 매월 최신 스냅 샷"

** 홈> 보고서 **를 클릭하고 'AWS Bill - Daily Cost`라는 저장된 보고서를 열면 가장 최근의 상세 보고서를 얻을 수 있습니다. 또는 검색 문자열`| '을 사용하여 검색하십시오. savedsearch "AWS Bill - 일일 비용". 보고서의 데이터 양이 많아 자세한 보고서를 검색하는 속도가 느려질 수 있습니다. Splunk은 상세 보고서에 대한 검색을 가속화 할 것을 권장합니다.

#### 소스보고

저장된 보고서는 CloudWatch의 결제 통계 데이터 대신 AWS 결제 보고서를 기반으로합니다. 기본적으로 총계 또는 월간 보고서는 AWS 월별 보고서 (`-aws-billing-csv-yyyy-mm.csv` 또는`* -aws-cost-allocation-yyyy-mm.csv`)에서 색인 된 데이터를 기반으로합니다. 일일 보고서는 AWS 세부 보고서 ( '* -aws-billing-detailed-line-items-yyyy-mm.csv.zip` 또는`* -aws-billing-detailed-line-items- with-resources-and-tags-yyyy-mm.csv.zip`).

#### 기본 색인 비헤이비어

기본적으로 보고서는 기본 색인 인 main에서 데이터를 찾습니다. 데이터 입력을 구성 할 때 기본 인덱스를 변경 한 경우 기본 검색 인덱스 목록에 인덱스를 포함 시키거나 두 개의 보고서를 변경하여 사용자 지정 인덱스로 필터링하지 않으면 보고서가 작동하지 않습니다.

기본 검색 인덱스 목록에 사용자 정의 색인을 포함하려면 다음을 수행하십시오.

1. ** 설정> 사용자 및 인증> 액세스 제어> 역할> [저장된 검색을 사용하는 역할]> 기본적으로 검색되는 색인 **을 클릭하십시오.
2. 기본 검색 인덱스 목록에 사용자 정의 색인을 포함시킵니다.
3. 저장된 검색을 사용하는 각 역할에 대해이를 반복하십시오.

저장된 검색을 변경하여 맞춤 색인으로 필터링하려면 다음을 수행하십시오.

1. 저장된 검색 'AWS 청구서 - 월간 최신 스냅 샷'을 엽니 다.
2. 필터를 추가하여 구성한 색인을 지정하십시오. 예를 들어,`index = new_index`.
3. 저장된 검색 내용을 저장하십시오.
4. 다른 저장된 검색 인 'AWS Bill - Detailed Cost`에 대해이 단계를 반복하십시오.

## AWS 용 Splunk 애드온 조회

AWS 용 Splunk 애드온에는 8 개의 조회가 포함되어 있습니다. 조회 파일은 AWC 서비스의 필드를 Splunk 플랫폼의 CIM 호환 또는 사람이 읽을 수있는 값에 매핑합니다. 검색 파일은`$ SPLUNK_HOME / etc / apps / Splunk_TA_aws / lookups`에 있습니다.

<table>
<tr> <td> 파일 이름 </td> <td> 목적 </td> </tr>
<td> aws_config_action_lookup.csv </td> <td> 상태 필드를 작업 필드에 대한 CIM 호환 값으로 매핑합니다. </td> </tr>
<td> aws_config_object_category_lookup.csv </td> <td> 다양한 AWS Config 객체 카테고리를 object_category 필드의 CIM 호환 값으로 정렬합니다. </td> </tr>
<td> aws-cloudtrail-action-status.csv </td> <td> eventName 및 errorCode 필드를 동작 및 상태에 대한 CIM 호환 값에 매핑합니다. </td> </tr>
<td> aws-cloudtrail-changetype.csv </td> <td> eventSource를 change_type 필드의 CIM 호환 값에 매핑합니다. </td> </tr>
<td> aws-health-error-type.csv </td> <td> ErrorCode를 ErrorDetail, ErrorCode, ErrorDetail으로 매핑합니다. </td> </tr>
<td> aws-log-sourcetype-modinput.csv </td> <td> 소스 유형을 modinput으로 매핑 </td> </tr>
<tr> <td> cloudfront_edge_location_lookup </td> <td> x_edge_location 값을 사람이 읽을 수있는 edge_location_name으로 매핑합니다. </td> </tr>
<td> vendor-product-aws-cloudtrail.csv </td> 소스 유형에 따라 공급 업체, 제품 및 appfields에 대한 CIM 호환 값을 정의합니다. </td> </tr>
<td> vpcflow_action_lookup.csv </td> <td> 숫자 프로토콜 코드를 CIM 호환 프로토콜 필드와 사람이 읽을 수있는 protocol_full_name으로 매핑합니다. </td> </tr>
<td> vpcflow_protocol_code_lookup.csv </td> <td> vpcflow_action 필드를 CIM 호환 액션 필드에 매핑합니다. </td> </tr>
<td> VmSizeToResources.csv </td> <td> instance_type 필드를 CIM 호환 cpu_cores, mem_capacity 필드에 매핑합니다. </td> </tr>
</table>

## AWS 데이터 입력을위한 Splunk 애드온의 성능 참조

많은 요소가 처리량 성능에 영향을줍니다. AWS 용 Splunk 애드온이 입력 데이터를 수집하는 속도는 배포 토폴로지, 버킷의 키 수, 파일 크기, 파일 압축 형식, 파일의 이벤트 수, 이벤트 크기 및 기타 변수의 수에 따라 다릅니다. 물론, 하드웨어 및 네트워킹 조건.

이 절에서는 특정 작동 조건에서 측정 된 처리량 데이터를 제공하고 성능 테스트 결과에서 AWS 추가 처리 성능 조정에 대한 대략적인 결론과 지침을 제시합니다. 자체 생산 환경에서 AWS 애드온 처리량 성능을 평가하고 최적화하기위한 기초로 여기 정보를 사용하십시오. 성능은 사용자 특성, 응용 프로그램 사용량, 서버 구성 및 기타 요인에 따라 다를 수 있으므로 특정 성능 결과는 보장 할 수 없습니다. 정확한 성능 튜닝 및 사이징에 대해서는 Splunk Support에 문의하십시오.

### 참조 하드웨어 및 소프트웨어 환경

여기에 제공된 처리량 데이터 및 결론은 다음 환경에서 실행되는 Splunk 인스턴스 (전용 무거운 전달자 및 인덱서)를 사용한 성능 테스트를 기반으로합니다.

<table>
</td> </td> </tr> </td> </td>
<tt> 메모리 </td> </td> </td> </td>
<td> 계산 단위 (ECU) </td> <td> 53.5 </td> </tr>
<tr> <td> vCPU </td> <td> 16 </td> </tr>
<tr> <td> 저장 용량 (GB) </td> <td> 0 (EBS 전용) </td> </tr>
<tr> <td> Arch </td> <td> 64 비트 </td> </tr>
<tr> <td> EBS 최적화 (최대 대역폭) </td> <td> 2000 Mbps </td> </tr>
<tr> <td> 네트워크 실적 </td> <td> 높음 </td> </tr>
</table>

다음 설정은 heavy forwarder의`outputs.conf`에 설정되어 있습니다 :

`useACK = true`
`maxQueueSize = 15MB`

### 측정 된 성능 데이터

여기에 제공된 처리량 데이터는 특정 작동 조건에서 성능 테스트에서 달성 된 각 단일 입력에 대한 최대 성능이며 하드웨어 및 소프트웨어 변수가 변경되면 변경 될 수 있습니다. 매우 거친 참조 용으로 만이 데이터를 사용하십시오.

#### 단일 입력 최대 처리량

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> <td> 최대 처리량 (KB / s) </td> <td> 최대 EPS (event / s) </td> <td > 최대 처리량 (GB / 일) </td> </tr>
<tr> <td> 일반 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 17,000 </td> <td> 86,000 </td> <td> 1,470 </td>
<tr> <td> 일반 S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 11,000 </td> 35,000 </td> 950 </td> </td>
<tr> <td> 증분 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 11,000 </td> 43,000 </td> 950 </td> </td>
<tr> <td> Incremental S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> <td> 7000 </td> <td> 600 </td>
<tr> <td> SQS 기반 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> <td> 12,000 </td> 50,000 </td> 1,000 </td> </tr>
<tr> <td> SQS 기반 S3 </td> <td> aws : elb : accesslogs <br/>
(gz, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> <td> 24,000 </td> 100,000 </td> 2,000 </td> </tr>
<tr> <td> SQS 기반 S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 13,000 </td> 19,000 </td> 1,100 </td> </tr>
<td> 1,000 </td> <td> 100 </td> <td> CloudWatch 로그 [1] </td> <td> aws : cloudwatchlog : vpcflow </td> > </tr>
<tr> <td> CloudWatch <br/>
(목록 메트릭, 10,000 메트릭) </td> <td> aws : cloudwatch </td> 240 (Metrics / s) </td> / tr>
<tr> <td> CloudTrail </td> <td> aws : cloudtrail <br/>
(gz, json, sqs = 1000, 9K 이벤트 / 키) </td> 5,000 </td> 7000 </td> 400 </td> </tr>
<tr> <td> Kinesis </td> <td> aws : cloudwatchlog : vpcflow <br/>
</td> 1,200 </td> </td> </td> </td> </td>
<tr> <td> SQS </td> <td> aws : sqs <br/>
(json, 이벤트 크기 2.8K) </td> 해당 없음 </td> </td> 160 </td>
</table>

[1] 입력 스트림이 1k보다 크면 API 조절 오류가 발생합니다.

#### 다중 입력 최대 처리량

다음 처리량 데이터는 인덱서 클러스터 분산 환경에서 무거운 전달자에 구성된 여러 입력을 사용하여 측정되었습니다.

> 참고 : AWS 계정을 더 많이 구성하면 API 사용 증가로 인해 CPU 사용량이 증가하고 처리량 성능이 저하됩니다. AWS에 대한 Splunk 애드온을 구성 할 때 AWS 계정을 통합하는 것이 좋습니다.

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> <td> 최대 처리량 (KB / s) </td> <td> 최대 EPS (events / s) </td> <td > 최대 처리량 (GB / 일) </td> </tr>
<tr> <td> 일반 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 23,000 </td> 108,000 </td> 1,980 </td> </td>
<tr> <td> 일반 S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45000 </td> 130,000 </td> 3,880 </td> </td>
<tr> <td> 증분 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 34,000 </td> 140,000 </td> 2,930 </td> </td>
<tr> <td> Incremental S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45,000 </td> 65,000 </td> 3,880 </td> </td>
<tr> <td> SQS 기반 S3 [1] <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 35,000 </td> <td> 144,000 </td> 3,000 </td> </tr>
<tr> <td> SQS 기반 S3 [1] <td> aws : elb : accesslogs <br/>
(gz, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 42,000 </td> 190,000 </td> 3,600 </td> </tr>
<tr> <td> SQS 기반 S3 [1] <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45,000 </td> 68,000 </td> 3,900 </td> </tr>
클라우드 워치 로그 : vpcflow </td> <td> 1,000 </td> 6,700 </td> 100 </td> </td> tr>
<tr> <td> CloudWatch (ListMetric) </td> <td> aws : cloudwatch <br/>
(10,000 메트릭) </td> 240 (메트릭 / s) </td> <td> NA </td> </tr>
<tr> <td> CloudTrail </td> <td> aws : cloudtrail <br/>
(gz, json, sqs = 100, 9K 이벤트 / 키) </td> 20,000 </td> 15,000 </td> 1700 </td> </tr>
<tr> <td> Kinesis </td> <td> aws : cloudwatchlog : vpcflow <br/>
18,000 </td> </td> </td> </td> </td> </td>
<tr> <td> SQS </td> <td> aws : sqs <br/>
(json, 이벤트 크기 2.8K) </td> N / A </td> <td> 670 </td>
</table>

[1] SQS 기반 S3 입력의 성능 테스트는 하나의 무거운 전달자 인스턴스에서 4 개의 입력을 실행할 때 최적의 성능 처리량에 도달 함을 나타냅니다. 이러한 병목 현상을 넘어 높은 처리 성능을 달성하기 위해 최대 4 개의 SQS 기반 S3 입력으로 구성된 다수의 무거운 전달자 인스턴스를 만들어 동일한 SQS 대기열에서 메시지를 소비하여 데이터를 동시에 수집함으로써 데이터 수집을 더욱 확장 할 수 있습니다.

#### 무거운 전달자 당 최대 입력 벤치 마크

다음 입력 번호 한도는 CPU 및 메모리 리소스를 최대한 활용하는 인덱서 클러스터 분산 환경에서 무거운 전달자에 구성된 여러 입력을 사용하여 측정되었습니다.

이벤트 크기가 작고 버킷 당 키 수가 적거나 사용 가능한 CPU 및 메모리 리소스가 많을 경우 테이블에 표시된 최대 입력 수보다 많은 입력을 구성 할 수 있습니다.

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> 형식 </td> <td> 키 수 / 버킷 수 </td> td> 최대 입력 </td> </tr>
100K </td> <td> S3 </td> <td> 100B </td> <td> S3 </td> 300 </td> </tr>
1,300K </td> 1KB </td> <td> S3 </td> <td> 1dws : 클라우드 레일 </td> <td> > 30 </td> </tr>
1,300K </td> 1KB </td> </td> <td> Incremental S3 </td> td> 20 </td> </tr>
<td> SQS 기반 S3 </td> <td> aws : cloudtrail, aws : config </td> <td> gz, json <td> 1,000K </td> <td> 1KB </td> <td> 50 </td> </tr>
</table>


#### 일반 S3 입력에 대한 메모리 사용 벤치 마크

<table>
<td> <td> <td> <td> 이벤트 크기 </td> <td> 키 수에 대한 이벤트 수 </td> <td> 총 키 수 </td> </td> <td> 사용 된 메모리 </td> </tr>
<td> 1K </td> 1,000 </td> 10,000 </td> <td> 20 </td> 20g </td> > </tr>
<td> 1K </td> 1,000 </td> 1,000 </td> <td> <td> 20 </td> 12G </td> > </tr>
<td> 1K </td> 1,000 </td> 10,000 </td> <td> <td> 10 </td> 18G </td> > </tr>
<td> 100B </td> 1,000 </td> 10,000 </td> <td> <td> 10 </td> 15G </ td > </tr>
</table>

### 성능 튜닝 및 사이징 가이드 라인

예상 AWS 데이터 처리량을 달성하지 못하면 다음 단계에 따라 처리량 성능을 조정하십시오.

1. 높은 수준의 처리량 성능을 달성하지 못하도록하는 시스템의 병목 현상을 식별하십시오. AWS 데이터 처리의 병목 현상은 다음 구성 요소 중 하나에있을 수 있습니다.
    - AWS 용 Splunk 애드온 : API 호출을 통해 AWS 데이터를 가져올 수있는 용량
    - 중형 전달자 : 데이터를 구문 분석하여 인덱서 계층으로 전달하는 기능으로, 구문 분석, 병합 및 입력 파이프 라인의 처리량이 필요합니다.
    - 인덱서 : 인덱스 파이프 라인 처리량
    무거운 전달자 및 인덱서의 인덱싱 성능 문제를 해결하려면 용량 계획 설명서에서 [인덱싱 성능 문제 해결] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Troubleshooting/ 문제 해결 색인 실행 참조)을 참조하십시오.
    체인은 가장 약한 링크만큼 강력합니다. 병목 현상의 용량은 전체 시스템 전체의 용량입니다. 병목 구성 요소의 성능을 식별하고 조정하여 전체 시스템 성능을 향상시킬 수 있습니다.
2. 병목 요소의 성능을 조정하십시오.
    부하가 많은 전달자 또는 인덱서에 병목 현상이있는 경우 용량 계획 안내서의 [성능 권장 사항 요약] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/ 성능 요약 참조)을 참조하십시오.
    병목 현상이 AWS 용 Splunk 애드온에있는 경우 일반적으로 AWS 데이터 입력 처리량에 영향을 미치는 다음 주요 요소를 조정하십시오.
    - 병렬화 설정
    최적의 쓰루풋 성능을 얻으려면, 리소스 용량이 허락한다면`server.conf`에`parallelIngestionPipelines` 값을 2로 설정할 수 있습니다. 'parallelIngestionPipelines`에 대한 자세한 내용은 Splunk Enterprise Capacity Planning Manual의 [Parallelization settings] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/Parallelization)을 참조하십시오.
    - AWS 데이터 입력
    리소스 부족이없는 경우 추가 기능에 입력을 추가하면 처리량이 증가하지만 메모리와 CPU를 더 많이 소모합니다. 메모리 또는 CPU가 부족할 때까지 처리량을 향상시키기 위해 입력 수를 늘리십시오.
    SQS 기반 S3 입력을 사용하는 경우 동일한 SQS 대기열에서 메시지를 소비하도록 여러 무거운 전달자에서 더 많은 입력을 구성하여 데이터 수집을 수평 확장 할 수 있습니다.
    - 버킷의 키 수
    일반 S3 및 증분 S3 입력의 경우 버킷의 키 (또는 객체) 수는 초기 데이터 수집 성능에 영향을 미치는 요소입니다. Generic 또는 Incremental S3 입력이 처음으로 버킷에서 데이터를 수집하면 버킷에 포함 된 키가 많을수록 목록 작업을 완료하는 데 더 많은 시간이 소요되고 더 많은 메모리가 소비됩니다. 버킷의 많은 수의 키는 초기 데이터 수집에서 S3 입력을 위해 엄청난 양의 메모리가 필요하며 애드온에서 구성 할 수있는 입력 수를 제한합니다.
    해당되는 경우 로그 파일 접두어를 사용하여 버킷의 하위 키를 작은 그룹으로 분할하고 다른 입력을 구성하여 개별적으로 처리 할 수 ​​있습니다. 로그 파일 접두어를 사용하도록 입력을 구성하는 방법에 대한 자세한 내용은 [AWS 용 Splunk 애드온에 대한 S3 입력 추가] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3)를 참조하십시오.
    SQS 기반 S3 입력의 경우 동일한 SQS 대기열에서 소비 된 메시지를 기반으로 데이터 수집을 수평 확장 할 수 있기 때문에 버킷의 키 수는 주요 요인이 아닙니다.
    - 파일 형식
    압축 된 파일은 일반 텍스트 파일보다 훨씬 많은 메모리를 사용합니다.
3. 병목 현상을 해결했으면 개선 된 성능이 요구 사항을 충족시키는 지 확인하십시오. 그렇지 않은 경우 이전 단계를 계속 진행하여 시스템에서 다음 병목 현상을 식별하고 예상되는 전체 처리량 성능이 달성 될 때까지 처리하십시오.

## AWS 용 Splunk 애드온의 Kinesis 입력 성능 참조

이 페이지는 AWS 용 Splunk 애드온의 키네시스 입력에 대한 Splunk의 성능 테스트에 대한 참조 정보를 제공합니다. 이 테스트는 Kinesis 입력이 처음 도입되었을 때 버전 4.0.0에서 수행되었습니다. 이 정보를 사용하여 Kinesis 데이터 수집 작업의 성능을 향상시킬 수 있습니다.

> 참고 : 파일 크기, 파일 압축, 이벤트 크기, 배포 아키텍처 및 하드웨어를 비롯한 많은 요인이 성능 결과에 영향을줍니다. 이 결과는 참조 정보를 나타내며 모든 환경에서 성능을 나타내지는 않습니다.

### 요약

다른 환경에서의 결과는 다양하지만, Splines의 Kinesis 입력에 대한 성능 테스트 결과는 다음과 같습니다.

- 각각의 Kinesis 입력은 최대 6MB / s의 데이터를 처리 할 수 ​​있으며 일일 섭취량은 500GB입니다.
- 파편이 많을수록 성능이 약간 향상 될 수 있습니다. 큰 물줄기에는 세 조각이 좋습니다.

### 테스트 아키텍처

Splunk는 m4.4xlarge AWS EC2 인스턴스에서 단일 인스턴스 Splunk Enterprise 6.4.0을 사용하여 Kinesis 입력의 성능을 테스트하여 CPU, 메모리, 저장소 및 네트워크에 병목 현상이 발생하지 않도록 보장합니다. 인스턴스 사양 :

<table>
</td> </td> </tr> </td> </tr> </td>
<tt> 메모리 </td> </td> </td> </td>
<tr> <td> ECU </td> <td> 53.5 </td> </tr>
<tr> <td> 코어 </td> <td> 16 </td> </tr>
<tr> <td> 저장 공간 </td> <td> 0 GB (EBS 전용) </td> </tr>
<td> 64 비트 </td> </tr>
<tr> <td> 네트워크 실적 </td> <td> 높음 </td> </tr>
<tr> <td> EBS 최적화 : 최대 대역폭 </td> <td> 250 MB / s </td> </tr>
</table>

### 테스트 시나리오

Splines은 다음 매개 변수를 테스트하여 Kinesis 스트림을 통해 수집 된 대용량 VPC 흐름 로그의 사용 사례를 타겟팅했습니다.

- 샤드 번호 : 3, 5 및 10 샤드
- 이벤트 크기 : 이벤트 당 120 바이트
- 행사 수 : 20,000,000
- 압축 : gzip
- 초기 스트림 위치 : TRIM_HORIZON

AWS는 각 샤드가 초당 5 회의 읽기 트랜잭션, 초당 최대 2MB의 읽기 속도로 제한되어 있다고보고합니다. 따라서 10 개의 샤드로 이론 상한선은 초당 20MB입니다.

### 시험 결과

스플 렁크 (Splunk)는 분당 최대 600 만 이벤트의 데이터 처리 속도 (초당 100,000 이벤트)를 관찰했습니다. 각 이벤트는 120 바이트이므로 최대 처리량은 10MB / s입니다.

Splunk는 단일 Kinesis 모듈 형 입력에 대해 평균 6 MB / s의 처리량을 보거나 약 500 GB의 일일 처리량을 관찰했습니다.

샤드 수를 10 개 샤드에서 3 개 샤드로 줄인 후에 스 프렁크는 약 10 %의 처리량 다운 그레이드를 관찰했습니다.

테스트 중에 Splunk는 인스턴스에서 다음과 같은 리소스 사용을 관찰했습니다.

- 약 30 %의 표준화 된 CPU 사용
- 약 700 MB의 파이썬 메모리 사용

인덱서는 CPU 소비량이 가장 크며 모듈 식 입력은 최대 메모리 소비입니다.

> 참고 : 호출이 10MB의 데이터를 반환하고 다음 5 초 내에 후속 호출이 이루어지면 AWS는 ProvisionedThroughputExceededException을 발생시킵니다. Splunk는 1 ~ 5 분마다 3 개의 샤드로 테스트하는 동안이 오류를 관찰했습니다.

## AWS 용 Splunk 애드온에 SNS Alert 사용

> 참고 : 사용자 지정 검색 명령 및 사용자 지정 경고 동작을 사용하려면 Splunk 관리자이거나 적절한 기능이있는 사용자 여야합니다.

- Splunk 플랫폼 6.5.0 이상을 사용하는 경우`list_storage_passwords`
- 이전 버전의 Splunk 플랫폼을 사용하고 있다면`admin_all_objects`

### 사용자 정의 검색 명령 사용

AWS 용 Splunk 애드온에는 AWS SNS에 경고를 보내는 사용자 정의 검색 명령이 포함되어 있습니다.

```sql
... | eval message = "내 메시지"| eval entity = "My Entity"| eval correlation_id = "1234567890"| awssnsalert account = 실제 지역 = "ap-southeast-1"topic_name = "ta-aws-sns-ingestion"publish_all = 1
```

<table>
<tr> <td> 특성 </td> <td> 설명 </td> </tr>
<tr> <td> account </td> <td> 필수 항목입니다. 부가 기능에 구성된 AWS 계정 이름 </td> </tr>
<tr> <td> region </td> <td> 필수 항목입니다. AWS 지역 이름 </td> </tr>
<tr> <td> topic_name </td> <td> 필수 항목입니다. 경고 메시지가이 AWS SNS 주제 이름으로 전송됩니다. </td> </tr>
<tr> <td> message </td> <td> 필수 항목입니다. AWS 용 Splunk 애드온이 AWS SNS로 보낸 메시지입니다. </td> </tr>
<tr> <td> publish_all </td> <td> publish_all을 0 또는 1로 설정할 수 있습니다. publish_all = 1로 설정하면이 추가 기능이이 검색에서 모든 레코드를 보낼 것임을 의미합니다. publish_all = 0으로 설정하면이 추가 기능이 첫 번째 결과 만이 검색에 전송됨을 의미합니다. 이 필드의 기본값은 0입니다. </td> </tr>
</table>

### 경고 동작 사용

AWS 용 Splunk 애드온은 맞춤형 알림 작업에서 자동 사건 및 이벤트 생성 및 사건 업데이트를 지원합니다. 맞춤 알림 작업은 Splunk 플랫폼 버전 6.3.0 이상에서 사용할 수 있습니다.

사용자 정의 알림 작업에서 새 인시던트 또는 이벤트를 생성하려면 다음과 같이하십시오.

1. AWS SNS에서 사건 또는 이벤트 생성을 트리거하는 데 사용할 검색 문자열을 작성합니다.
2. ** 다른 이름으로 저장> 알림 **을 클릭하십시오.
3. 경고 양식을 작성하십시오. 경고에 고유 한 이름을 지정하고 경고가 실시간 경고인지 또는 예정된 경고인지 나타내십시오. 자세한 내용은 Splunk Enterprise 설명서의 Alerting Manual에서 [Alerts with Getting Started] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Alert/Aboutalerts)를 참조하십시오.
4. 트리거 동작에서 ** 동작 추가 **를 클릭합니다.
5. 경고에서 AWS SNS에 이벤트를 만들려면 목록에서 ** AWS SNS 경고 **를 선택합니다.
6. 표시된 모든 필수 필드의 값을 입력하십시오.

<table>
<tr> <td> 필드 </td> <td> 예제 값 </td> </tr>
<tr> <td> 계정 </td> <td> 필수 항목입니다. AWS 용 Splunk 애드온에 구성된 계정 이름입니다. </td> </tr>
<tr> <td> 지역 </td> <td> 필수 항목입니다. 이벤트가 전송 될 AWS SNS 영역입니다. 지역이 AWS SNS와 일치하는지 확인해야합니다. </td> </tr>
<tr> <td> 주제 이름 </td> <td> 필수 항목입니다. 이벤트가 전송 될 주제의 이름. 주제 이름이 AWS SNS에 있는지 확인해야합니다. </td> </tr>
<tr> <td> 상관 관계 ID </td> <td> 선택 사항. 이 경고를 다른 이벤트와 연관시키는 ID입니다. 이 필드를 비워두면 기본적으로 $ result.correlation_id $가 사용됩니다. </td> </tr>
<tr> <td> 엔티티 </td> <td> 선택 사항. 이벤트, 경고와 관련된 객체 (예 : 호스트, 데이터베이스, EC2 인스턴스)입니다. 이 필드를 비워두면 Splunk는 기본적으로 $ result.entity $를 사용합니다. </td> </tr>
<tr> <td> 출처 </td> <td> 선택 사항. 이벤트 또는 경고의 출처. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result.source $를 사용합니다. </td> </tr>
<tr> <td> Timestamp </td> <td> 선택 사항. 이벤트 시간이 발생합니다. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._time $을 사용합니다. </td> </tr>
<tr> <td> 이벤트 </td> <td> 선택 사항. 이벤트의 세부 사항. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._raw $를 사용합니다. </td> </tr>
<tr> <td> Message </td> <td> 필수 항목입니다. AWS 용 Splunk 애드온이 AWS SNS로 보낸 메시지입니다. </td> </tr>
</table>
