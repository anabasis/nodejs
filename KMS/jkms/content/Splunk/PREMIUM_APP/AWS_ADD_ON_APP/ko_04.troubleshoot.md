# Troubleshooting

## Splunk Add-on for AWS Troubleshooting

### 일반적인 Troubleshooting

모든 Add-on에 적용 할 수있는 유용한 Troubleshooting 정보는 [Troubleshoot add-ons](http://docs.splunk.com/Documentation/AddOns/released/Overview/Troubleshootadd-ons). You can also access these [support and resource links](http://docs.splunk.com/Documentation/AddOns/latest/Overview/Learnmoreandgethelp) 참조

### Health Check 대시보드

**Health Check** 메뉴에서 대시보드를 선택하여 데이터 수집 오류 및 성능 문제를 해결할 수 있음.

** 상태 개요 ** 대시보드는 모든 입력 유형에 대한 데이터 수집 오류 및 성능 측정 항목을 한눈에 볼 수 있음.

- 오류 카테고리별 오류 수
- 입력 유형, 호스트, 데이터 입력 및 오류 범주에 따른 시간별 오류 카운트
- 호스트, 입력 유형 및 데이터 입력에 따른 시간 경과에 따른 처리량

**S3 Health Details** 대시보드는 General, Increametal 및 SQS-Based S3 입력 유형에 중점을 두고 인덱싱 시간 지연 및 이러한 다목적 입력에 대한 자세한 오류 정보를 제공함.

건강 대시보드를 사용자 정의 할 수 있음. [대시보드 및 시각화] (http://docs.splunk.com)의 [대시보드 편집기 정보] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Viz/CreateandeditdashboardsviatheUI) 항목을 참조함. /Documentation/Splunk/7.1.1/Viz/Aboutthismanual) 매뉴얼을 참조함.

### Internal Logs

Troubleshooting을 위해 Internal Logs 데이터에 직접 액세스 할 수 있음. 이러한 원본 유형으로 수집된 데이터는 상태 검사 대시보드에서 사용됩니다.

<table>
<tr><td>Data source</td><td>Source type</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudtrail_cloudtrail_{input_name}.log.</td><td>aws:cloudtrail:log</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudwatch.log.</td><td>aws:cloudwatch:log</td></tr>
<tr><td>Logs from splunk_ta_aws_cloudwatch_logs.log.</td><td>aws:cloudwatchlogs:log</td></tr>
<tr><td>Logs from splunk_ta_aws_config_{input_name}.log.</td><td>aws:config:log</td></tr>
<tr><td>Logs from splunk_ta_aws_config_rule.log.</td><td>aws:configrule:log</td></tr>
<tr><td>Logs from splunk_ta_aws_inspector_main.log, splunk_ta_aws_inspector_app_env.log, splunk_ta_aws_inspector_proxy_conf.log, and splunk_ta_aws_inspector_util.log.</td><td>aws:inspector:log</td></tr>
<tr><td>Logs from splunk_ta_aws_description.log.</td><td>aws:description:log</td></tr>
<tr><td>Logs from splunk_ta_aws_billing_{input_name}.log.</td><td>aws:billing:log</td></tr>
<tr><td>Logs from splunk_ta_aws_generic_s3_{input_name}.</td><td>aws:s3:log</td></tr>
<tr><td>Logs from splunk_ta_aws_logs_{input_name}.log, each incremental S3 input has one log file with the input name in the log file.</td><td>aws:logs:log</td></tr>
<tr><td>Logs from splunk_ta_aws_kinesis.log.</td><td>aws:kinesis:log</td></tr>
<tr><td>Logs from splunk_ta_aws_ sqs_based_s3_{input_name} .</td><td>aws:sqsbaseds3:log</td></tr>
<tr><td>Logs from splunk_ta_aws_sns_alert_modular.log and splunk_ta_aws_sns_alert_search.log.</td><td>aws:sns:alert:log</td></tr>
<tr><td>Logs from splunk_ta_aws_rest.log, populated by REST API handlers called when setting up the add-on or data input.</td><td>aws:resthandler:log</td></tr>
<tr><td>Logs from splunk_ta_aws_proxy_conf.log, the proxy handler used in all AWS data inputs.</td><td>aws:proxy-conf:log</td></tr>
<tr><td>Logs from splunk_ta_aws_s3util.log, populated by the S3, CloudWatch, and SQS connectors.</td><td>aws:resthandler:log</td></tr>
<tr><td>Logs from splunk_ta_aws_util.log, a shared utilities library.</td><td>aws:util:log</td></tr>
</table>

<table>
<tr> <td> 데이터 소스 </td> </td> </td>
<tr> <td> splunk_ta_aws_cloudtrail_cloudtrail_ {input_name} .log의 로그입니다. </td> <td> aws : cloudtrail : log </td> </tr>
<tr> <td> splunk_ta_aws_cloudwatch.log의 로그입니다. </td> <td> aws : cloudwatch : log </td> </tr>
<tr> <td> splunk_ta_aws_cloudwatch_logs.log의 로그입니다. </td> <td> aws : cloudwatchlogs : log </td> </tr>
<tr> <td> splunk_ta_aws_config_ {input_name} .log에서 로그함. </td> <td> aws : config : log </td> </tr>
<tr> <td> splunk_ta_aws_config_rule.log에서 로그. </td> <td> aws : configrule : log </td> </tr>
</td> <td> aws : inspector : log </td> </tr> <tr> <td> <tr> <td>
<tr> <td> splunk_ta_aws_description.log에서 로그. </td> <td> aws : description : log </td> </tr>
<tr> <td> splunk_ta_aws_billing_ {input_name} .log에서 로그함. </td> <td> aws : billing : log </td> </tr>
<tr> <td> splunk_ta_aws_generic_s3_ {input_name}의 로그입니다. </td> <td> aws : s3 : log </td> </tr>
<tr> <td> splunk_ta_aws_logs_ {input_name} .log의 로그에서 각 증분 S3 입력에는 로그 파일에 입력 이름이있는 로그 파일이 하나 있음. </td> <td> aws : logs : log </td> tr>
<tr> <td> splunk_ta_aws_kinesis.log에서 로그. </td> <td> aws : kinesis : log </td> </tr>
<tr> <td> splunk_ta_aws_ sqs_based_s3_ {input_name}의 로그입니다. </td> <td> aws : sqsbaseds3 : log </td> </tr>
<tr> <td> splunk_ta_aws_sns_alert_modular.log 및 splunk_ta_aws_sns_alert_search.log의 로그입니다. </td> <td> aws : sns : alert : log </td> </tr>
<tr> <td> 부가 기능 또는 데이터 입력을 설정할 때 호출되는 REST API 핸들러로 채워진 splunk_ta_aws_rest.log의 로그 </td> <td> aws : resthandler : log </td> </tr>
<tr> <td> 모든 AWS 데이터 입력에 사용 된 프록시 처리기 인 splunk_ta_aws_proxy_conf.log의 로그 <awd : proxy-conf : log </td> </tr>
<tr> <td> S3, CloudWatch 및 SQS 커넥터로 채워진 splunk_ta_aws_s3util.log의 로그입니다. </td> <td> aws : resthandler : log </td> </tr>
<tr> <td> 공유 유틸리티 라이브러리 인 splunk_ta_aws_util.log에서 로그함. </td> <td> aws : util : log </td> </tr>
</table>

### Log Levels 구성

1. Splunk Web의 홈 페이지 왼쪽 탐색 모음에서 **Splunk Add-on for AWS**을 클릭함.
2. 앱 탐색 바에서 **Configuration**을 클릭함.
3. **Logging** 탭을 클릭함.
4. 'INFO'의 기본값을 다른 사용 가능한 옵션 중 하나 인 DEBUG 또는 ERROR로 변경하여 필요에 따라 각 AWS 서비스의 Log Levels을 조정.

> 참고 : 이러한 Log Levels 구성은 런타임 로그에만 적용됩니다. DEBUG의 구성 활동 로그에있는 일부 REST 엔드 포인트 로그 및 일부 유효성 검증 로그는 ERROR에 로그함. 이 레벨은 구성 할 수 없습니다.

### 계정 또는 입력 구성 중 문제를 저장하는 중

설정 페이지에서 AWS 계정을 구성하는 동안 오류가 발생하거나 저장하는 데 문제가 있으면`$ SPLUNK_HOME / etc / system / local / web.conf`로 이동하여 아래 표시된대로 시간 초과 설정을 변경함.

```재산
  [설정]
  splunkdConnectionTimeout = 300
```

### 배포 서버로 배포 할 때의 문제

배포 서버를 사용하여 Amazon Web Services 용 Splunk 애드온을 여러 무거운 전달자에 배포하는 경우 배포 서버가 해시 공유를 지원하지 않기 때문에 각 인스턴스에 대한 Splunk Web 설치 UI를 별도로 사용하여 Amazon Web Services 계정을 구성해야합니다 인스턴스간에 암호 저장.

### S3 문제

#### S3 입력 성능 문제

단일 S3 버킷에 대해 여러 개의 S3 입력을 구성하여 성능을 향상시킬 수 있음. Splunk 플랫폼은 각 데이터 입력에 대해 하나의 프로세스를 수행하므로 시스템의 처리 능력이 충분하면 여러 입력으로 성능이 향상됩니다. [Splunk Add-on for AWS의 S3 입력에 대한 성능 참조] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3PerformanceReference)를 참조함.

> 참고 : 중복 데이터 인덱싱을 방지하려면 동일한 버킷에 대한 여러 입력의 S3 키 이름이 겹치지 않도록함.

#### S3 키 이름 화이트리스트 / 블랙리스트 필터링 문제

화이트리스트와 블랙리스트는 마지막 세그먼트뿐만 아니라 전체 키 이름과 일치함.

화이트리스트. * abc /.*는 /a/b/abc/e.gz와 일치함.

regex에 대한 추가 도움말 :

-이 블로그 게시물의 비디오보기 : <http://blogs.splunk.com/2008/10/22/all-my-regexs-live-in-texas/>
- Splunk Enterprise 설명서의 일부인 Knowledge Manager 설명서에서 "[Splunk 정규식 정보] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Knowledge/AboutSplunkregularexpressions)"를 읽으십시오.

#### S3 이벤트 행 Troubleshooting

인덱싱 된 S3 데이터의 줄 바꿈이 잘못된 경우 'props.conf'에 사용자 지정 소스 유형을 구성하여 이벤트에 대한 줄을 끊는 방법을 제어함.

S3 이벤트가 너무 길어서 잘리는 경우`props.conf`에`TRUNCATE = 0`을 설정하여 줄 잘림을 방지함.

자세한 내용은 Splunk Enterprise 설명서의 데이터 가져 오기 설명서에서 [이벤트 줄 바꿈 구성] (http://docs.splunk.com/Documentation/Splunk/latest/Data/Configureeventlinebreaking)을 참조함.

### CloudWatch 구성 문제

#### 스로틀 링

CloudWatch 데이터가 많은 경우`index = _internal Throttling`을 검색하여 API 조절 문제가 발생하는지 확인함. 그렇다면 AWS 지원 팀에 문의하여 CloudWatch API 속도를 높이십시오. 수집하는 메트릭 수를 줄이거 나 세분화하여 API 호출을 줄입니다.

#### 세분성

인덱싱 된 데이터의 세분성이 예상과 다를 경우 구성된 세분성이 선택한 측정 항목에 대해 AWS에서 지원하는 범위 내에 있는지 확인함. 서로 다른 AWS 메트릭은 AWS에서 해당 메트릭을 허용하는 샘플링 기간을 기준으로 다른 최소 세분성을 지원함. 예를 들어 CPUUtilization은 5 분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4 시간의 샘플링 기간을가집니다.

선택한 메트릭의 샘플링 기간보다 작은 세분성을 구성한 경우 인덱싱 된 데이터의보고 된 세분성이 실제 세분화 된 세분성을 반영하지만 구성된 세분성으로 레이블이 지정됩니다. 문제가있는`local / inputs.conf` 클라우드 워치 스탠자를 지우고 새로 인덱싱 된 데이터가 정확하도록 지원되는 샘플링 세분성과 일치하도록 세분성 구성을 조정하고 데이터를 다시 색인화함.

### CloudTrail 데이터 색인 문제

Splunk 플랫폼에서 CloudTrail 데이터가 표시되지 않는 경우이 Troubleshooting 프로세스를 따르십시오.

1. 다음을 검색하여 Internal Logs를 검토함.`index = _internal source = * cloudtrail *`
2. "Connected to SQS"문자열을 검색하여 Splunk 플랫폼이 SQS에 성공적으로 연결되어 있는지 확인함.
3. Splunk 플랫폼이 메시지를 성공적으로 처리하는지 확인함. "X 완료, Y 통보 일괄 처리 중 실패"패턴을 따르는 문자열을 찾으십시오.
4. Splunk 플랫폼이 메시지를 삭제하는지 확인함. 패턴 "X를 가져 왔고, Y를 쓰고, 버려진 Z"를 따르는 문자열을 찾습니다.
5. Amazon Web Services 구성을 검토하여 SQS 메시지가 대기열에 있는지 확인함. 메시지가 제거되고 로그에 입력 내용이 제거되지 않는다고 표시되지 않으면 큐에서 다른 스크립트 나 입력 메시지를 사용할 수 있음. 데이터 입력을 검토하여 동일한 대기열을 사용하도록 구성된 다른 입력이 없는지 확인함.
6. AWS 콘솔로 이동하여 세부 정보가 1 분으로 설정된 CloudWatch 메트릭을 확인하여 추세를 확인함. 자세한 내용은 <https://aws.amazon.com/blogs/aws/amazon-cloudwatch-search-and-browse-metrics-in-the-console/>을 참조함. 소비 된 메시지가 표시되지만 Splunk 플랫폼 입력이 메시지를 소비하지 않는 경우 동일한 대기열에 액세스하는 원격 서비스가 있는지 확인함.

### 결제 보고서 문제

#### AWS에서 청구 보고서에 액세스하는 데 문제가 있음.

결제 입력을 구성 할 때 선택한 S3 버킷에서 사용할 수있는 결제 보고서가 있는지, 지정한 AWS 계정에 해당 버킷 내부의 파일을 읽을 수있는 권한이 있는지 확인함.

#### 청구 보고서 데이터 이해 문제

Splunk은 Add-on에 포함 된 [저장된 검색에 액세스] (http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata#Access_saved_searches)를 권장하여 요금 청구 보고서 데이터를 분석함.

#### 청구 데이터 간격 구성 문제

> 참고 : 청구 리포트 데이터의 기본 청구 데이터 수집 수집 간격은 라이센스 사용을 최소화하도록 설계되었습니다. 기본 동작을 검토하고 조심해서 조정.

Splunk Enterprise가 매월 및 세부 청구 보고서를 가져 오는 간격을 구성하려면 다음을 수행함.

1. Splunk Web에서 AWS 입력 용 Splunk 애드온 화면으로 이동함.
2. 새로운 대금 청구 입력을 생성하거나 클릭하여 기존 입력을 편집함.
3. 설정 탭을 클릭함.
4. 간격 필드에서 값을 사용자 정의함.

### SNS 알림 문제

모듈 형 입력 모듈은 비활성 상태이므로 AWS가 AWS SNS에 올 바르고 올바른지 확인할 수 없습니다. AWS SNS 계정으로 메시지를 보낼 수없는 경우 다음 절차를 수행 할 수 있음.

- AWS에 SNS 주제 이름이 존재하고 region ID가 올바르게 구성되었는지 확인함.
- AWS의 Splunk 애드온에서 AWS 계정이 올바르게 구성되었는지 확인함.

그래도 문제가 지속되면 다음 검색을 수행하여 AWS SNS 로그를 확인할 수 있습니다

`index = _ 내부 sourcetype = aws : sns : alert : log "`

VPC 엔드 포인트의 프록시 설정

VPC 엔드 포인트와 함께 프록시를 사용하는 경우`$ SPLUNK_HOME / etc / splunk-launch.conf`에 정의 된 프록시 설정을 확인함. 예를 들면 다음과 같습니다.

`no_proxy = 169.254.169.254,127.0.0.1, s3.amazonaws.com, [s3-ap-southeast-2.amazonaws.com | http : //s3-ap-southeast-2.amazonaws.com/]`

각 S3 region 엔드 포인트를 no_proxy 설정에 추가하고 s3 - \ <your_aws_region \>. amazonaws.com의 올바른 호스트 이름을 사용해야함. no_proxy 설정은 IP 주소 사이에 공백을 허용하지 않습니다.

## Splunk Add-on for AWS에 대한 청구 데이터 액세스

Amazon Web Services 용 Splunk 애드온은 S3 버킷에서 일반 데이터 추출을 지원함. S3 버킷에서 추출하려는 데이터의 한 예는 AWS 청구 보고서 데이터입니다. 청구 입력을 사용하여 AWS 청구 리포트를 수집 한 다음이 애드온에 포함 된 사전 작성된 리포트를 사용하여 유용한 정보를 추출함. Add-on의 사전 빌드 된 보고서는 AWS 보고서 형식을 기반으로하므로이 데이터에 쉽게 액세스하고 작업 할 수 있음. 이 보고서를 Splunk 플랫폼을 사용하여 다른 S3 데이터를 탐색하는 방법의 예로 사용할 수 있음.

> 참고 : 결제 입력은 AWS Marketplace 요금에 대한 청구 보고서를 수집하지 않습니다.

### 청구 리포트 수집 행동

Amazon Web Services는 AWS 설명서에서 자세한 내용을 볼 수있는 4 가지 고유 한 청구 보고서를 제공합니다 (<http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/detailed-billing-reports.html#d0e2817>). Splunk Add-on for AWS을 사용하여 네 가지 유형의 청구 보고서를 수집 할 수 있음.

아마존 청구 서비스는이 월간 마지막 날이 며칠 후에 최종 보고서가 완성 될 때까지이 보고서 4 개 모두를 지속적으로 업데이트함. 보고서가 완료 될 때까지 일일 업데이트는 가장 최근 날짜의 활동에 대한 새로운 결제 정보를 추가하고 이전에보고 된 광고 항목을 업데이트함. 예를 들어 청구 서비스는 이미 통과 한 이벤트에 대한 가격 할인을 다시 계산할 수 있음.

보고서의 모든 데이터가 업데이트 될 수 있기 때문에 Add-on은 네 가지 보고서 유형 중 하나를 가져올 때마다 전체 청구 보고서를 가져옵니다. 월별 보고서 및 월별 비용 할당 보고서는 매우 작기 때문에 기본적으로 Add-on이 매일 이러한 정보를 검색하므로 같은 (작은) 보고서가 여러 번 생성됩니다. 그러나 자세한 보고서는 매우 크기 때문에 Add-on은 당월 이전 달 동안이 보고서 만 수집함.

기본적으로 Add-on은 사용 가능한 모든 달에 대한 수집 기준과 일치하는 사용 가능한 모든 보고서를 수집함. 예를 들어 Splunk Add-on for AWS을 2016 년 2 월 15 일에 설치하고 월간 비용 할당 보고서와 리소스 및 태그가 포함 된 세부 청구 보고서를 모두 수집하도록 입력을 구성한다고 가정함. 첫날 Add-on은 2016 년 2 월 현재의 월별 보고서를 2015 년 2 월 16 일까지 수집하고 이전 달의 모든 월별 보고서를 계정에 사용할 수있게함. Add-on은 2016 년 1 월의 상세 보고서와 계정에서 사용할 수있는 이전 달의 모든 세부 보고서도 수집함. 이후의 모든 날에는 최신 버전의 월별 보고서가 최신 날짜로 다운로드됩니다. 또한 가장 최근에 완료 한 달 (이 경우에는 1 월)의 etag을 확인함. 아마존 청구 서비스에서 제공되는 최신 1 월 세부 보고서에 대한 자세한 보고서를 확인함. 동일하면 월이 끝날 때까지 상세 보고서를 다시 다운로드하지 않습니다. 3 월 1 일에 Add-on은 2 월에 대한 상세 보고서를 매일 보고서의 etag가 변경되지 않을 때까지 다운로드하기 시작함.

cron 일정 및 정규식을 사용하여 수집하는 보고서 수를 제어하는 ​​방법에 대한 자세한 내용은 [대금 청구 입력 구성] (http://docs.splunk.com/Documentation/AddOns/released/AWS/Billing) 지침을 참조함.

Splunk 플랫폼의 보고서 데이터에 액세스하려면 Add-on에 포함 된 보고서를 사용하여 최신 스냅 샷을보십시오. 보고서 조정은 지원되지 않습니다.

### 결제 보고서 유형

#### 월별보고

** 월간 보고서 **에는 계정 및 월별 라인 항목의 IAM 사용자가 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됩니다. 청구 및 비용 관리 콘솔의 청구서 페이지에서이 보고서를 다운로드 할 수 있음.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-csv-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 Add-on이 전체 보고서를 하루에 한 번 가져옵니다.

#### 월간 비용 할당 보고서

** 월간 비용 할당 보고서 **에는 월간 보고서와 동일한 데이터가 포함되어 있지만 작성한 비용 할당 태그도 포함됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야함. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-cost-allocation-yyyy-mm.csv

이 보고서는 크기가 작으므로 최신 보고서를 얻으려면 Add-on이 전체 보고서를 하루에 한 번 가져옵니다.

#### 세부 청구 보고서

** 세부 청구 보고서 **에는 계정 및 IAM 사용자가 시간별 광고 항목에서 사용하는 각 제품 측정 기준에 대한 AWS 사용이 나열됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야함. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-detailed-line-items-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 Add-on은 월이 끝난 후에 만 ​​보고서를 수집함. 애드온은 Amazon 청구 서비스에 의해 완료 될 때까지 하루에 한 번 보고서를 계속 수집함.

#### 리소스 및 태그가 포함 된 세부 청구 보고서

리소스 및 태그가 포함 된 ** 세부 청구 리포트 **에는 세부 청구 리포트와 동일한 데이터가 포함되어 있지만 계정에서 사용 된 AWS 리소스에 대해 생성 한 비용 할당 태그 및 ResourceID도 포함됩니다. 지정한 Amazon S3 버킷에서이 보고서를 가져와야함. 표준 AWS 저장 속도가 적용됩니다.

파일 이름 형식 : {AWS 계정 번호} -aws-billing-detailed-line-items-with-resources-and-tags-yyyy-mm.csv.zip

이 보고서는 매우 커질 수 있으므로 Add-on은 월이 끝난 후에 만 ​​보고서를 수집함. 애드온은 Amazon 청구 서비스에 의해 완료 될 때까지 하루에 한 번 보고서를 계속 수집함.

### 청구 데이터의 이벤트 유형

Splunk 플랫폼은 소스 유형`aws : billing`을 사용하여 두 가지 유형의 청구 데이터를 인덱싱함.

- 이벤트 유형이 'aws_billing_monthly_report` 인 월별 보고서
- 이벤트 유형이 'aws_billing_detail_report` 인 세부 보고서

### 부가 기능의 미리 구성된 보고서에 액세스함.

Amazon Web Services 용 Splunk 애드온에는 색인 된 청구 보고서 데이터를 기반으로하는 여러 보고서가 포함되어 있음. ** 홈> 보고서 **를 클릭하고 접두어가 'AWS Bill-'인 항목을 찾으면 Splunk Web에서 저장된 보고서를 찾을 수 있음. 저장된 검색 중 일부가 테이블을 반환함. 다른 것은`AWS Bill - 지금까지의 총비용 '과 같은 단일 값을 반환함.

AWS는 당월의 청구 보고서의 여러 스냅 샷을 S3 버킷에 저장하기 때문에 Splunk 플랫폼은 일반적으로 여러 월간 보고서 스냅 샷을 인덱싱함. 가장 최근의 월간 보고서 스냅 샷을 얻으려면 ** 홈> 보고서 **를 클릭하고 저장된 보고서 인`AWS Bill - Monthly Latest Snapshot`을여십시오. 또는 검색 문자열을 사용하여 검색하십시오 :`| savedsearch "AWS Bill - 매월 최신 스냅 샷"

** 홈> 보고서 **를 클릭하고 'AWS Bill - Daily Cost`라는 저장된 보고서를 열면 가장 최근의 상세 보고서를 얻을 수 있음. 또는 검색 문자열`| '을 사용하여 검색함. savedsearch "AWS Bill - 일일 비용". 보고서의 데이터 양이 많아 자세한 보고서를 검색하는 속도가 느려질 수 있음. Splunk은 상세 보고서에 대한 검색을 가속화 할 것을 권장함.

#### 소스보고

저장된 보고서는 CloudWatch의 결제 통계 데이터 대신 AWS 결제 보고서를 기반으로함. 기본적으로 총계 또는 월간 보고서는 AWS 월별 보고서 (`-aws-billing-csv-yyyy-mm.csv` 또는`* -aws-cost-allocation-yyyy-mm.csv`)에서 색인 된 데이터를 기반으로함. 일일 보고서는 AWS 세부 보고서 ( '* -aws-billing-detailed-line-items-yyyy-mm.csv.zip` 또는`* -aws-billing-detailed-line-items- with-resources-and-tags-yyyy-mm.csv.zip`).

#### 기본 색인 비헤이비어

기본적으로 보고서는 기본 색인 인 main에서 데이터를 찾습니다. 데이터 입력을 구성 할 때 기본 인덱스를 변경 한 경우 기본 검색 인덱스 목록에 인덱스를 포함 시키거나 두 개의 보고서를 변경하여 사용자 지정 인덱스로 필터링하지 않으면 보고서가 작동하지 않습니다.

기본 검색 인덱스 목록에 사용자 정의 색인을 포함하려면 다음을 수행함.

1. ** 설정> 사용자 및 인증> 액세스 제어> 역할> [저장된 검색을 사용하는 역할]> 기본적으로 검색되는 색인 **을 클릭함.
2. 기본 검색 인덱스 목록에 사용자 정의 색인을 포함시킵니다.
3. 저장된 검색을 사용하는 각 역할에 대해이를 반복함.

저장된 검색을 변경하여 맞춤 색인으로 필터링하려면 다음을 수행함.

1. 저장된 검색 'AWS 청구서 - 월간 최신 스냅 샷'을 엽니 다.
2. 필터를 추가하여 구성한 색인을 지정함. 예를 들어,`index = new_index`.
3. 저장된 검색 내용을 저장함.
4. 다른 저장된 검색 인 'AWS Bill - Detailed Cost`에 대해이 단계를 반복함.

## Splunk Add-on for AWS 조회

Splunk Add-on for AWS에는 8 개의 조회가 포함되어 있음. 조회 파일은 AWC 서비스의 필드를 Splunk 플랫폼의 CIM 호환 또는 사람이 읽을 수있는 값에 매핑함. 검색 파일은`$ SPLUNK_HOME / etc / apps / Splunk_TA_aws / lookups`에 있음.

<table>
<tr> <td> 파일 이름 </td> <td> 목적 </td> </tr>
<td> aws_config_action_lookup.csv </td> <td> 상태 필드를 작업 필드에 대한 CIM 호환 값으로 매핑함. </td> </tr>
<td> aws_config_object_category_lookup.csv </td> <td> 다양한 AWS Config 객체 카테고리를 object_category 필드의 CIM 호환 값으로 정렬함. </td> </tr>
<td> aws-cloudtrail-action-status.csv </td> <td> eventName 및 errorCode 필드를 동작 및 상태에 대한 CIM 호환 값에 매핑함. </td> </tr>
<td> aws-cloudtrail-changetype.csv </td> <td> eventSource를 change_type 필드의 CIM 호환 값에 매핑함. </td> </tr>
<td> aws-health-error-type.csv </td> <td> ErrorCode를 ErrorDetail, ErrorCode, ErrorDetail으로 매핑함. </td> </tr>
<td> aws-log-sourcetype-modinput.csv </td> <td> 소스 유형을 modinput으로 매핑 </td> </tr>
<tr> <td> cloudfront_edge_location_lookup </td> <td> x_edge_location 값을 사람이 읽을 수있는 edge_location_name으로 매핑함. </td> </tr>
<td> vendor-product-aws-cloudtrail.csv </td> 소스 유형에 따라 공급 업체, 제품 및 appfields에 대한 CIM 호환 값을 정의함. </td> </tr>
<td> vpcflow_action_lookup.csv </td> <td> 숫자 프로토콜 코드를 CIM 호환 프로토콜 필드와 사람이 읽을 수있는 protocol_full_name으로 매핑함. </td> </tr>
<td> vpcflow_protocol_code_lookup.csv </td> <td> vpcflow_action 필드를 CIM 호환 액션 필드에 매핑함. </td> </tr>
<td> VmSizeToResources.csv </td> <td> instance_type 필드를 CIM 호환 cpu_cores, mem_capacity 필드에 매핑함. </td> </tr>
</table>

## AWS 데이터 입력을위한 Splunk 애드온의 성능 참조

많은 요소가 처리량 성능에 영향을줍니다. Splunk Add-on for AWS이 입력 데이터를 수집하는 속도는 배포 토폴로지, 버킷의 키 수, 파일 크기, 파일 압축 형식, 파일의 이벤트 수, 이벤트 크기 및 기타 변수의 수에 따라 다릅니다. 물론, 하드웨어 및 네트워킹 조건.

이 절에서는 특정 작동 조건에서 측정 된 처리량 데이터를 제공하고 성능 테스트 결과에서 AWS 추가 처리 성능 조정에 대한 대략적인 결론과 지침을 제시함. 자체 생산 환경에서 AWS 애드온 처리량 성능을 평가하고 최적화하기위한 기초로 여기 정보를 사용함. 성능은 사용자 특성, 응용 프로그램 사용량, 서버 구성 및 기타 요인에 따라 다를 수 있으므로 특정 성능 결과는 보장 할 수 없습니다. 정확한 성능 튜닝 및 사이징에 대해서는 Splunk Support에 문의함.

### 참조 하드웨어 및 소프트웨어 환경

여기에 제공된 처리량 데이터 및 결론은 다음 환경에서 실행되는 Splunk 인스턴스 (전용 무거운 전달자 및 인덱서)를 사용한 성능 테스트를 기반으로함.

<table>
</td> </td> </tr> </td> </td>
<tt> 메모리 </td> </td> </td> </td>
<td> 계산 단위 (ECU) </td> <td> 53.5 </td> </tr>
<tr> <td> vCPU </td> <td> 16 </td> </tr>
<tr> <td> 저장 용량 (GB) </td> <td> 0 (EBS 전용) </td> </tr>
<tr> <td> Arch </td> <td> 64 비트 </td> </tr>
<tr> <td> EBS 최적화 (최대 대역폭) </td> <td> 2000 Mbps </td> </tr>
<tr> <td> 네트워크 실적 </td> <td> 높음 </td> </tr>
</table>

다음 설정은 heavy forwarder의`outputs.conf`에 설정되어 있습니다 :

`useACK = true`
`maxQueueSize = 15MB`

### 측정 된 성능 데이터

여기에 제공된 처리량 데이터는 특정 작동 조건에서 성능 테스트에서 달성 된 각 단일 입력에 대한 최대 성능이며 하드웨어 및 소프트웨어 변수가 변경되면 변경 될 수 있음. 매우 거친 참조 용으로 만이 데이터를 사용함.

#### 단일 입력 최대 처리량

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> <td> 최대 처리량 (KB / s) </td> <td> 최대 EPS (event / s) </td> <td > 최대 처리량 (GB / 일) </td> </tr>
<tr> <td> 일반 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 17,000 </td> <td> 86,000 </td> <td> 1,470 </td>
<tr> <td> 일반 S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 11,000 </td> 35,000 </td> 950 </td> </td>
<tr> <td> 증분 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 11,000 </td> 43,000 </td> 950 </td> </td>
<tr> <td> Incremental S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> <td> 7000 </td> <td> 600 </td>
<tr> <td> SQS-Based S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> <td> 12,000 </td> 50,000 </td> 1,000 </td> </tr>
<tr> <td> SQS-Based S3 </td> <td> aws : elb : accesslogs <br/>
(gz, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> <td> 24,000 </td> 100,000 </td> 2,000 </td> </tr>
<tr> <td> SQS-Based S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 13,000 </td> 19,000 </td> 1,100 </td> </tr>
<td> 1,000 </td> <td> 100 </td> <td> CloudWatch 로그 [1] </td> <td> aws : cloudwatchlog : vpcflow </td> > </tr>
<tr> <td> CloudWatch <br/>
(목록 메트릭, 10,000 메트릭) </td> <td> aws : cloudwatch </td> 240 (Metrics / s) </td> / tr>
<tr> <td> CloudTrail </td> <td> aws : cloudtrail <br/>
(gz, json, sqs = 1000, 9K 이벤트 / 키) </td> 5,000 </td> 7000 </td> 400 </td> </tr>
<tr> <td> Kinesis </td> <td> aws : cloudwatchlog : vpcflow <br/>
</td> 1,200 </td> </td> </td> </td> </td>
<tr> <td> SQS </td> <td> aws : sqs <br/>
(json, 이벤트 크기 2.8K) </td> 해당 없음 </td> </td> 160 </td>
</table>

[1] 입력 스트림이 1k보다 크면 API 조절 오류가 발생함.

#### 다중 입력 최대 처리량

다음 처리량 데이터는 인덱서 클러스터 분산 환경에서 무거운 전달자에 구성된 여러 입력을 사용하여 측정되었습니다.

> 참고 : AWS 계정을 더 많이 구성하면 API 사용 증가로 인해 CPU 사용량이 증가하고 처리량 성능이 저하됩니다. AWS에 대한 Splunk 애드온을 구성 할 때 AWS 계정을 통합하는 것이 좋습니다.

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> <td> 최대 처리량 (KB / s) </td> <td> 최대 EPS (events / s) </td> <td > 최대 처리량 (GB / 일) </td> </tr>
<tr> <td> 일반 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 23,000 </td> 108,000 </td> 1,980 </td> </td>
<tr> <td> 일반 S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45000 </td> 130,000 </td> 3,880 </td> </td>
<tr> <td> 증분 S3 </td> <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 34,000 </td> 140,000 </td> 2,930 </td> </td>
<tr> <td> Incremental S3 </td> <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45,000 </td> 65,000 </td> 3,880 </td> </td>
<tr> <td> SQS-Based S3 [1] <td> aws : elb : accesslogs <br/>
(일반 텍스트, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 35,000 </td> <td> 144,000 </td> 3,000 </td> </tr>
<tr> <td> SQS-Based S3 [1] <td> aws : elb : accesslogs <br/>
(gz, syslog, 이벤트 크기 250B, S3 키 크기 2MB) </td> 42,000 </td> 190,000 </td> 3,600 </td> </tr>
<tr> <td> SQS-Based S3 [1] <td> aws : cloudtrail <br/>
(gz, json, 이벤트 크기 720B, S3 키 크기 2MB) </td> 45,000 </td> 68,000 </td> 3,900 </td> </tr>
클라우드 워치 로그 : vpcflow </td> <td> 1,000 </td> 6,700 </td> 100 </td> </td> tr>
<tr> <td> CloudWatch (ListMetric) </td> <td> aws : cloudwatch <br/>
(10,000 메트릭) </td> 240 (메트릭 / s) </td> <td> NA </td> </tr>
<tr> <td> CloudTrail </td> <td> aws : cloudtrail <br/>
(gz, json, sqs = 100, 9K 이벤트 / 키) </td> 20,000 </td> 15,000 </td> 1700 </td> </tr>
<tr> <td> Kinesis </td> <td> aws : cloudwatchlog : vpcflow <br/>
18,000 </td> </td> </td> </td> </td> </td>
<tr> <td> SQS </td> <td> aws : sqs <br/>
(json, 이벤트 크기 2.8K) </td> N / A </td> <td> 670 </td>
</table>

[1] SQS-Based S3 입력의 성능 테스트는 하나의 무거운 전달자 인스턴스에서 4 개의 입력을 실행할 때 최적의 성능 처리량에 도달 함을 나타냅니다. 이러한 병목 현상을 넘어 높은 처리 성능을 달성하기 위해 최대 4 개의 SQS-Based S3 입력으로 구성된 다수의 무거운 전달자 인스턴스를 만들어 동일한 SQS 대기열에서 메시지를 소비하여 데이터를 동시에 수집함으로써 데이터 수집을 더욱 확장 할 수 있음.

#### 무거운 전달자 당 최대 입력 벤치 마크

다음 입력 번호 한도는 CPU 및 메모리 리소스를 최대한 활용하는 인덱서 클러스터 분산 환경에서 무거운 전달자에 구성된 여러 입력을 사용하여 측정되었습니다.

이벤트 크기가 작고 버킷 당 키 수가 적거나 사용 가능한 CPU 및 메모리 리소스가 많을 경우 테이블에 표시된 최대 입력 수보다 많은 입력을 구성 할 수 있음.

<table>
<td> 데이터 입력 </td> <td> Sourcetype </td> 형식 </td> <td> 키 수 / 버킷 수 </td> td> 최대 입력 </td> </tr>
100K </td> <td> S3 </td> <td> 100B </td> <td> S3 </td> 300 </td> </tr>
1,300K </td> 1KB </td> <td> S3 </td> <td> 1dws : 클라우드 레일 </td> <td> > 30 </td> </tr>
1,300K </td> 1KB </td> </td> <td> Incremental S3 </td> td> 20 </td> </tr>
<td> SQS-Based S3 </td> <td> aws : cloudtrail, aws : config </td> <td> gz, json <td> 1,000K </td> <td> 1KB </td> <td> 50 </td> </tr>
</table>


#### 일반 S3 입력에 대한 메모리 사용 벤치 마크

<table>
<td> <td> <td> <td> 이벤트 크기 </td> <td> 키 수에 대한 이벤트 수 </td> <td> 총 키 수 </td> </td> <td> 사용 된 메모리 </td> </tr>
<td> 1K </td> 1,000 </td> 10,000 </td> <td> 20 </td> 20g </td> > </tr>
<td> 1K </td> 1,000 </td> 1,000 </td> <td> <td> 20 </td> 12G </td> > </tr>
<td> 1K </td> 1,000 </td> 10,000 </td> <td> <td> 10 </td> 18G </td> > </tr>
<td> 100B </td> 1,000 </td> 10,000 </td> <td> <td> 10 </td> 15G </ td > </tr>
</table>

### 성능 튜닝 및 사이징 가이드 라인

예상 AWS 데이터 처리량을 달성하지 못하면 다음 단계에 따라 처리량 성능을 조정.

1. 높은 수준의 처리량 성능을 달성하지 못하도록하는 시스템의 병목 현상을 식별함. AWS 데이터 처리의 병목 현상은 다음 구성 요소 중 하나에있을 수 있음.
    - Splunk Add-on for AWS : API 호출을 통해 AWS 데이터를 가져올 수있는 용량
    - 중형 전달자 : 데이터를 구문 분석하여 인덱서 계층으로 전달하는 기능으로, 구문 분석, 병합 및 입력 파이프 라인의 처리량이 필요함.
    - 인덱서 : 인덱스 파이프 라인 처리량
    무거운 전달자 및 인덱서의 인덱싱 성능 문제를 해결하려면 용량 계획 설명서에서 [인덱싱 성능 Troubleshooting] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Troubleshooting/ Troubleshooting 색인 실행 참조)을 참조함.
    체인은 가장 약한 링크만큼 강력함. 병목 현상의 용량은 전체 시스템 전체의 용량입니다. 병목 구성 요소의 성능을 식별하고 조정하여 전체 시스템 성능을 향상시킬 수 있음.
2. 병목 요소의 성능을 조정.
    부하가 많은 전달자 또는 인덱서에 병목 현상이있는 경우 용량 계획 안내서의 [성능 권장 사항 요약] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/ 성능 요약 참조)을 참조함.
    병목 현상이 Splunk Add-on for AWS에있는 경우 일반적으로 AWS 데이터 입력 처리량에 영향을 미치는 다음 주요 요소를 조정.
    - 병렬화 설정
    최적의 쓰루풋 성능을 얻으려면, 리소스 용량이 허락한다면`server.conf`에`parallelIngestionPipelines` 값을 2로 설정할 수 있음. 'parallelIngestionPipelines`에 대한 자세한 내용은 Splunk Enterprise Capacity Planning Manual의 [Parallelization settings] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Capacity/Parallelization)을 참조함.
    - AWS 데이터 입력
    리소스 부족이없는 경우 Add-on에 입력을 추가하면 처리량이 증가하지만 메모리와 CPU를 더 많이 소모함. 메모리 또는 CPU가 부족할 때까지 처리량을 향상시키기 위해 입력 수를 늘리십시오.
    SQS-Based S3 입력을 사용하는 경우 동일한 SQS 대기열에서 메시지를 소비하도록 여러 무거운 전달자에서 더 많은 입력을 구성하여 데이터 수집을 수평 확장 할 수 있음.
    - 버킷의 키 수
    일반 S3 및 증분 S3 입력의 경우 버킷의 키 (또는 객체) 수는 초기 데이터 수집 성능에 영향을 미치는 요소입니다. Generic 또는 Incremental S3 입력이 처음으로 버킷에서 데이터를 수집하면 버킷에 포함 된 키가 많을수록 목록 작업을 완료하는 데 더 많은 시간이 소요되고 더 많은 메모리가 소비됩니다. 버킷의 많은 수의 키는 초기 데이터 수집에서 S3 입력을 위해 엄청난 양의 메모리가 필요하며 애드온에서 구성 할 수있는 입력 수를 제한함.
    해당되는 경우 로그 파일 접두어를 사용하여 버킷의 하위 키를 작은 그룹으로 분할하고 다른 입력을 구성하여 개별적으로 처리 할 수 ​​있음. 로그 파일 접두어를 사용하도록 입력을 구성하는 방법에 대한 자세한 내용은 [Splunk Add-on for AWS에 대한 S3 입력 추가] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3)를 참조함.
    SQS-Based S3 입력의 경우 동일한 SQS 대기열에서 소비 된 메시지를 기반으로 데이터 수집을 수평 확장 할 수 있기 때문에 버킷의 키 수는 주요 요인이 아닙니다.
    - 파일 형식
    압축 된 파일은 일반 텍스트 파일보다 훨씬 많은 메모리를 사용함.
3. 병목 현상을 해결했으면 개선 된 성능이 요구 사항을 충족시키는 지 확인함. 그렇지 않은 경우 이전 단계를 계속 진행하여 시스템에서 다음 병목 현상을 식별하고 예상되는 전체 처리량 성능이 달성 될 때까지 처리함.

## Splunk Add-on for AWS의 Kinesis 입력 성능 참조

이 페이지는 Splunk Add-on for AWS의 키네시스 입력에 대한 Splunk의 성능 테스트에 대한 참조 정보를 제공함. 이 테스트는 Kinesis 입력이 처음 도입되었을 때 버전 4.0.0에서 수행되었습니다. 이 정보를 사용하여 Kinesis 데이터 수집 작업의 성능을 향상시킬 수 있음.

> 참고 : 파일 크기, 파일 압축, 이벤트 크기, 배포 아키텍처 및 하드웨어를 비롯한 많은 요인이 성능 결과에 영향을줍니다. 이 결과는 참조 정보를 나타내며 모든 환경에서 성능을 나타내지는 않습니다.

### 요약

다른 환경에서의 결과는 다양하지만, Splines의 Kinesis 입력에 대한 성능 테스트 결과는 다음과 같습니다.

- 각각의 Kinesis 입력은 최대 6MB / s의 데이터를 처리 할 수 ​​있으며 일일 섭취량은 500GB입니다.
- 파편이 많을수록 성능이 약간 향상 될 수 있음. 큰 물줄기에는 세 조각이 좋습니다.

### 테스트 아키텍처

Splunk는 m4.4xlarge AWS EC2 인스턴스에서 단일 인스턴스 Splunk Enterprise 6.4.0을 사용하여 Kinesis 입력의 성능을 테스트하여 CPU, 메모리, 저장소 및 네트워크에 병목 현상이 발생하지 않도록 보장함. 인스턴스 사양 :

<table>
</td> </td> </tr> </td> </tr> </td>
<tt> 메모리 </td> </td> </td> </td>
<tr> <td> ECU </td> <td> 53.5 </td> </tr>
<tr> <td> 코어 </td> <td> 16 </td> </tr>
<tr> <td> 저장 공간 </td> <td> 0 GB (EBS 전용) </td> </tr>
<td> 64 비트 </td> </tr>
<tr> <td> 네트워크 실적 </td> <td> 높음 </td> </tr>
<tr> <td> EBS 최적화 : 최대 대역폭 </td> <td> 250 MB / s </td> </tr>
</table>

### 테스트 시나리오

Splines은 다음 매개 변수를 테스트하여 Kinesis 스트림을 통해 수집된 대용량 VPC 흐름 로그의 사용 사례를 타겟팅했습니다.

- 샤드 번호 : 3, 5 및 10 샤드
- 이벤트 크기 : 이벤트 당 120 바이트
- 행사 수 : 20,000,000
- 압축 : gzip
- 초기 스트림 위치 : TRIM_HORIZON

AWS는 각 샤드가 초당 5 회의 읽기 트랜잭션, 초당 최대 2MB의 읽기 속도로 제한되어 있다고보고함. 따라서 10 개의 샤드로 이론 상한선은 초당 20MB입니다.

### 시험 결과

스플 렁크 (Splunk)는 분당 최대 600 만 이벤트의 데이터 처리 속도 (초당 100,000 이벤트)를 관찰했습니다. 각 이벤트는 120 바이트이므로 최대 처리량은 10MB / s입니다.

Splunk는 단일 Kinesis 모듈 형 입력에 대해 평균 6 MB / s의 처리량을 보거나 약 500 GB의 일일 처리량을 관찰했습니다.

샤드 수를 10 개 샤드에서 3 개 샤드로 줄인 후에 스 프렁크는 약 10 %의 처리량 다운 그레이드를 관찰했습니다.

테스트 중에 Splunk는 인스턴스에서 다음과 같은 리소스 사용을 관찰했습니다.

- 약 30 %의 표준화 된 CPU 사용
- 약 700 MB의 파이썬 메모리 사용

인덱서는 CPU 소비량이 가장 크며 모듈 식 입력은 최대 메모리 소비입니다.

> 참고 : 호출이 10MB의 데이터를 반환하고 다음 5 초 내에 후속 호출이 이루어지면 AWS는 ProvisionedThroughputExceededException을 발생시킵니다. Splunk는 1 ~ 5 분마다 3 개의 샤드로 테스트하는 동안이 오류를 관찰했습니다.

## Splunk Add-on for AWS에 SNS Alert 사용

> 참고 : 사용자 지정 검색 명령 및 사용자 지정 경고 동작을 사용하려면 Splunk 관리자이거나 적절한 기능이있는 사용자 여야함.

- Splunk 플랫폼 6.5.0 이상을 사용하는 경우`list_storage_passwords`
- 이전 버전의 Splunk 플랫폼을 사용하고 있다면`admin_all_objects`

### 사용자 정의 검색 명령 사용

Splunk Add-on for AWS에는 AWS SNS에 경고를 보내는 사용자 정의 검색 명령이 포함되어 있음.

```sql
... | eval message = "내 메시지"| eval entity = "My Entity"| eval correlation_id = "1234567890"| awssnsalert account = 실제 지역 = "ap-southeast-1"topic_name = "ta-aws-sns-ingestion"publish_all = 1
```

<table>
<tr> <td> 특성 </td> <td> 설명 </td> </tr>
<tr> <td> account </td> <td> 필수 항목입니다. 부가 기능에 구성된 AWS 계정 이름 </td> </tr>
<tr> <td> region </td> <td> 필수 항목입니다. AWS 지역 이름 </td> </tr>
<tr> <td> topic_name </td> <td> 필수 항목입니다. 경고 메시지가이 AWS SNS 주제 이름으로 전송됩니다. </td> </tr>
<tr> <td> message </td> <td> 필수 항목입니다. Splunk Add-on for AWS이 AWS SNS로 보낸 메시지입니다. </td> </tr>
<tr> <td> publish_all </td> <td> publish_all을 0 또는 1로 설정할 수 있음. publish_all = 1로 설정하면이 Add-on이이 검색에서 모든 레코드를 보낼 것임을 의미함. publish_all = 0으로 설정하면이 Add-on이 첫 번째 결과 만이 검색에 전송됨을 의미함. 이 필드의 기본값은 0입니다. </td> </tr>
</table>

### 경고 동작 사용

Splunk Add-on for AWS은 맞춤형 알림 작업에서 자동 사건 및 이벤트 생성 및 사건 업데이트를 지원함. 맞춤 알림 작업은 Splunk 플랫폼 버전 6.3.0 이상에서 사용할 수 있음.

사용자 정의 알림 작업에서 새 인시던트 또는 이벤트를 생성하려면 다음과 같이함.

1. AWS SNS에서 사건 또는 이벤트 생성을 트리거하는 데 사용할 검색 문자열을 작성함.
2. ** 다른 이름으로 저장> 알림 **을 클릭함.
3. 경고 양식을 작성함. 경고에 고유 한 이름을 지정하고 경고가 실시간 경고인지 또는 예정된 경고인지 나타내십시오. 자세한 내용은 Splunk Enterprise 설명서의 Alerting Manual에서 [Alerts with Getting Started] (http://docs.splunk.com/Documentation/Splunk/7.1.1/Alert/Aboutalerts)를 참조함.
4. 트리거 동작에서 ** 동작 추가 **를 클릭함.
5. 경고에서 AWS SNS에 이벤트를 만들려면 목록에서 ** AWS SNS 경고 **를 선택함.
6. 표시된 모든 필수 필드의 값을 입력함.

<table>
<tr> <td> 필드 </td> <td> 예제 값 </td> </tr>
<tr> <td> 계정 </td> <td> 필수 항목입니다. Splunk Add-on for AWS에 구성된 계정 이름입니다. </td> </tr>
<tr> <td> 지역 </td> <td> 필수 항목입니다. 이벤트가 전송 될 AWS SNS 영역입니다. 지역이 AWS SNS와 일치하는지 확인해야함. </td> </tr>
<tr> <td> 주제 이름 </td> <td> 필수 항목입니다. 이벤트가 전송 될 주제의 이름. 주제 이름이 AWS SNS에 있는지 확인해야함. </td> </tr>
<tr> <td> 상관 관계 ID </td> <td> 선택 사항. 이 경고를 다른 이벤트와 연관시키는 ID입니다. 이 필드를 비워두면 기본적으로 $ result.correlation_id $가 사용됩니다. </td> </tr>
<tr> <td> 엔티티 </td> <td> 선택 사항. 이벤트, 경고와 관련된 객체 (예 : 호스트, 데이터베이스, EC2 인스턴스)입니다. 이 필드를 비워두면 Splunk는 기본적으로 $ result.entity $를 사용함. </td> </tr>
<tr> <td> 출처 </td> <td> 선택 사항. 이벤트 또는 경고의 출처. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result.source $를 사용함. </td> </tr>
<tr> <td> Timestamp </td> <td> 선택 사항. 이벤트 시간이 발생함. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._time $을 사용함. </td> </tr>
<tr> <td> 이벤트 </td> <td> 선택 사항. 이벤트의 세부 사항. 이 필드를 비워두면 Splunk 플랫폼은 기본적으로 $ result._raw $를 사용함. </td> </tr>
<tr> <td> Message </td> <td> 필수 항목입니다. Splunk Add-on for AWS이 AWS SNS로 보낸 메시지입니다. </td> </tr>
</table>
