# Input Configuration 세부 정보

## Splunk Add-on for AWS의 Config input Configuration

> Config input type은 Config 데이터의 콜렉션 (source type : `aws:config, aws:config:notification`)을 지원. 이러한 유형의 데이터를 수집하려면 SQS-Based S3 입력을 구성하는 것이 좋음.

Splunk Web을 통해 데이터 수집 노드의 Splunk Add-on for Amazon Web Services(권장) 또는 `local/inputs.conf`에 AWS Config input을 구성
이 데이터 소스는 현재 중국 또는 GovCloud가 포함되지 않은 AWS 지역의 하위 집합에서만 사용.
지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#awsconfig_region> AWS 설명서를 참조.

고유한 SQS마다 하나의 활성화된 Config modular input만 있어야 함.
다른 modular input이 액세스 및 구문 분석을 시도하는 SQS 메시지 또는 S3 레코드를 삭제하려고 할 때 여러 개의 활성화된 modular input이 충돌 가능성
운영환경으로 이동하기 전에 테스트 구성을 비활성화하거나 삭제.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Config input을 구성.

- [Configure a Config input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Config#Configure_a_Config_input_using_Splunk_Web) (recommended)
- [Configure a Config input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Config#Configure_a_Config_input_using_configuration_file)

### Splunk Web을 사용하여 Config input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Config > Config**.을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 Config 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_region</td><td>AWS Region</td><td>로그 알림 SQS Queue을 포함하는 AWS 지역. inputs.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>sqs_queue</td><td>SQS queue name</td><td>AWS가 새 Config 알림을 보내는 대기열의 이름. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력. 큐 이름은 전체 큐 URL의 마지막 세그먼트. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:config의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 업데이트해야 함.
Splunk 플랫폼은 다음과 같이이 sourcetype의 3 가지 변형을 사용하여 AWS Config 이벤트를 인덱싱함.

- Configuration 스냅 샷은 sourcetype = aws:config로 인덱싱됨.
- Configuration 변경 알림은 sourcetype = aws:config:notification으로 색인됨.
- aws_config.log의 로그는 sourcetype = aws:config:log로 인덱싱됨.

aws:config의 기본값을 수정하면 &lt;yourcustomsourcetype&gt;:notification 및 &lt;yourcustomsourcetype&gt;:log가 표시됨. </td></tr>

<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Config 데이터를 저장하는 인덱스 이름. 기본값은 main임.</td></tr>
<tr><td>Polling interval</td><td>Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 30초임.</td></tr>
</table>

### 구성 파일을 사용하여 Config input Configuration

`inputs.conf`에서 입력을 수동으로 설정하려면, 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_config://<name>]
aws_account = <value>
aws_region = <value>
sqs_queue = <value>
interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는 $SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf에서 찾을 수 있는 기본값을 가짐.

```properties
[aws_config]
aws_account =
sourcetype = aws:config
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스탠자를`/ local`에 복사하고 이를 수동으로`inputs.conf`를 구성하기 위한 시작점으로 사용할 경우, 스탠자 제목을`aws_config`에서`aws_config://<name>`으로 변경하고 필요한 추가 매개 변수 추가

### Config input에서 SQS-Based S3 입력으로 전환

SQS-Based S3 입력은 CloudTrail 데이터를 수집하기 위한 Config input에 대한 내결함성이 뛰어나고 성능이 뛰어난 대안임. Config input을 사용하여 Config 데이터를 이미 수집하고 있다면 SQS-Based S3 입력을 구성하고 Config 데이터 수집을 위한 새로운 입력으로 쉽게 전환 할 수 있음.

1. Config 데이터를 수집하는 데 사용중인 Config input을 비활성화함.
2. 구성 데이터를 수집하는 SQS Queue에 dead-letter queue 및 SQS 가시성 timeout 설정을 설정함. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS)를 참조.
3. 마지막 단계에서 구성한 SQS Queue을 가리키는 SQS-Based S3 입력을 생성. 자세한 내용은 [Configure SQS-based S3 inputs for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_SQS-based_S3_inputs_for_the_Splunk_Add-on_for_AWS)을 참조.

구성 단계.
일단 구성되면 새로운 SQS-Based S3 입력이 이전 Config input을 대체하여 동일한 SQS Queue에서 Config 데이터를 수집.

## Splunk Add-on for AWS에 대한 Config Rules Input Configuration

Config Rules 입력을 구성하여 Config Rules 데이터 (sourcetype : `aws:config:rules`)를 수집.

Splunk Web(권장) 또는 `local/aws_config_rule_tasks.conf`를 통해 데이터 수집 노드의 Splunk Add-on for AWS에 대한 Config Rules 입력을 구성. 이 데이터 소스는 현재 중국 또는 GovCloud가 포함되지 않은 AWS 지역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#awsconfig_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Configure a Config Rules input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigRules#Configure_a_Config_Rules_input_using_Splunk_Web) (recommended)
- [Configure a Config Rules input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigRules#Configure_a_Config_Rules_input_using_configuration_file)

### Splunk Web을 사용하여 Config Rules Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Config Rules**을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 Config Rules 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_config_rule_tasks.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>region</td><td>Region</td><td>Config Rules이 포함 된 AWS 영역임. aws_config_rule_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>rule_names</td><td>Config Rules</td><td>Config Rules 이름은 쉼표로 구분된 목록으로 표시됨. 모든 규칙을 수집하려면 비워 두십시오.</td></tr>
<tr><td>sourcetype</td><td>Source Type</td><td>이벤트의 sourcetype. aws:config:rule의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Config Rules 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>polling_interval</td><td>Polling Interval</td><td>데이터 수집 간격 (초). 기본값은 300 초임.</td></tr>
</table>

다음은 두 개의 규칙에 대한 Config Rules 데이터를 수집하는 예제 스탠자임.

```properties
[splunkapp2:us-east-1]
aws_account = splunkapp2
region = us-east-1
index = aws
polling_interval = 300
sourcetype = aws:config:rule
rule_names=required-tags,restricted-common-ports
```

### 구성 파일을 사용하여 Config Rules Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플릿을 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_config_rule_tasks.conf`를 만듬.

```properties
[<name>]
account = <value>
region = <value>
rule_names = <value>
sourcetype = <value>
polling_interval = <value>
index = <value>
```

## Splunk Add-on for AWS의 Inspector Input Configuration

Inspector 입력을 구성하여 Inspector 데이터를 수집합니다 (sourcetype :`aws:inspector`).

Splunk Web(권장) 또는 `local/aws_inspector_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS에 대한 Inspector 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#inspector_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Configure an Inspector input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Inspector#Configure_an_Inspector_input_using_Splunk_Web) (recommended)
- [Configure an Inspector input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Inspector#Configure_an_Inspector_input_using_configuration_file)

### Splunk Web을 사용하여 Inspector Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Inspector**.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>account</td><td>AWS Account</td><td>Splunk 플랫폼이 Inspector 결과에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_inspector_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나의 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>regions</td><td>AWS Region</td><td>데이터가 포함 된 AWS 지역임. aws_inspector_tasks.conf에서 지역 ID를 쉼표로 구분된 목록에 입력.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:inspector의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Inspector 결과를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>polling_interval</td><td>Pooling interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 300초임.
구성 파일을 사용하여 Inspector 입력 구성</td></tr>
</table>

설정 파일을 사용하여 입력을 설정하려면, 다음 템플릿을 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_inspector_tasks.conf`를 생성.

```properties
[<name>]
account = <value>
regions = <value>
index = <value>
polling_interval = <value>
sourcetype = <value>
```

다음은 Inspector 결과를 수집하는 예제 절임.

```properties
[splunkapp2:us-west-2]
account = splunkapp2
index = default
interval = 300
region = us-west-2
sourcetype = aws:inspector
```

## Splunk Add-on for AWS에 대한 CloudTrail Input Configuration

> CloudTrail 입력 유형은 CloudTrail 데이터 (sourcetype : `aws:cloudtrail`)의 수집을 지원. 그러나 이러한 유형의 데이터를 수집하려면 SQS-Based S3 입력을 구성하는 것이 좋음.

CloudTrail Input Configuration을 시작하기 전에 다음 동작을 고려.

1. 고유한 각 SQS > SNS > S3 버킷 경로에 대해 활성화된 CloudTrail modular input 만 하나만 가져야함. 다른 modular input이 액세스 및 구문 분석을 시도하는 SQS 메시지 또는 S3 레코드를 삭제하려고 할 때 여러 개의 활성화된 modular input이 충돌을 일으킬 수 있음. 프로덕션 환경으로 이동하기 전에 테스트 구성을 비활성화하거나 삭제.

2. CloudTrail 데이터를 수집하려는 AWS 영역이 여러 개 있는 경우 Amazon Web Services는 작업중인 AWS 파티션의 모든 영역에 적용되는 트레일을 구성 할 것을 권장. 하나의 CloudTrail 입력을 설정하여 모든 지역의 로그 파일이 저장되는 중앙 집중화 된 S3 버킷에서 데이터를 수집.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 CloudTrail 입력을 구성.

- [Configure a CloudTrail input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudTrail#Configure_a_CloudTrail_input_using_Splunk_Web) (recommended)
- [Configure a CloudTrail input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudTrail#Configure_a_CloudTrail_input_using_configuration_file)

### Splunk Web을 사용하여 CloudTrail Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > CloudTrail**을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudTrail 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_region</td><td>AWS Region</td><td>로그 알림 SQS Queue을 포함하는 AWS 지역. inputs.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>sqs_queue</td><td>SQS queue name</td><td>AWS가 새로운 CloudTrail 로그 알림을 보내는 대기열의 이름임. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력할 수 있음. 큐 이름은 전체 큐 URL의 마지막 세그먼트임. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue임.
<tr><td>remove_files_when_done</td><td>Remove logs when done</td><td>인덱싱이 완료된 후 Splunk 플랫폼이 S3 버킷에서 로그 파일을 삭제해야하는지 여부를 나타내는 부울 값임. 기본값은 false임.</td></tr>
<tr><td>exclude_describe_events</td><td>Exclude events</td><td>대량의 데이터를 생성 할 수 있는 읽기 전용 이벤트와 같은 특정 이벤트를 제외할지 여부를 나타내는 부울 값임. 기본값은 true임.</td></tr>
<tr><td>blacklist</td><td>Blacklist for exclusion</td><td>&lt;exclude_describe_events&gt;가 true로 설정된 경우 이벤트 이름을 지정하는 PCRE 정규식임.
공백으로두면 기본 정규식 ^(?:Describe|List|Get).을 사용할 수 있음.</td></tr>
<tr><td>excluded_events_index</td><td>Excluded events index</td><td>Splunk 플랫폼이 제외 된 이벤트를 넣어야하는 인덱스의 이름임. 기본값은 비어 있으며 이벤트를 삭제.</td></tr>
<tr><td>interval</td><td>Interval</td><td>이벤트의 sourcetype. aws:cloudtrail의 기본값을 덮어 쓰려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:cloudtrail의 기본값을 덮어 쓰려는 경우에만 값을 입력. 이벤트 추출은 소스 유형의 기본값에 의존. 기본값을 변경하면 props.conf도 업데이트.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudTrail 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 CloudTrail Input Configuration

`inputs.conf`에서 입력을 수동으로 설정하려면, 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_cloudtrail://<name>]
aws_account = <value>
aws_region = <value>
sqs_queue = <value>
exclude_describe_events = <value>
remove_files_when_done = <value>
blacklist = <value>
excluded_events_index = <value>
interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_cloudtrail]
aws_account =
sourcetype = aws:cloudtrail
exclude_describe_events = true
remove_files_when_done = false
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스텐자를 `/ local`에 복사하고 이를 수동으로`inputs.conf`를 구성하기 위한 시작점으로 사용하려면 스탠자 제목을 aws_cloudtrail에서 `aws_cloudtrail://<name>`으로 변경.

### CloudTrail 입력에서 SQS-Based S3 입력으로 전환

SQS-Based S3 입력은 CloudTail 데이터 수집을 위한 CloudTrail 입력에 대한 내결함성이 뛰어나고 성능이 뛰어난 대안임. CloudTrail 입력을 사용하여 CloudTrail 데이터를 수집중인 경우 SQS-Based S3 입력을 구성하고 CloudTrail 데이터 수집을 위한 새로운 입력으로 원활하게 전환 할 수 있음.

1. CloudTrail 데이터를 수집하는 데 사용중인 CloudTrail 입력을 사용 불가능하게 함.
2. CloudTrail 데이터를 수집하는 SQS queue에 대한 dead-letter queue 및 SQS 가시성 timeout 설정을 설정함. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 참조.
3. 마지막 단계에서 구성한 SQS Queue을 가리키는 SQS-Based S3 입력을 생성. 자세한 구성 단계는 [Configure SQS-based S3 inputs for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3) 참조.

일단 구성되면 새로운 SQS-Based S3 입력이 이전 CloudTrail 입력을 대체하여 동일한 SQS Queue에서 CloudTrail 데이터를 수집.

## Splunk Add-on for AWS에 대한 CloudWatch Logs 입력 추가

> Splunk는 CloudWatch Logs 입력을 사용하여 VPC Flow Logs 데이터 (sourcetype : `aws:cloudwatchlogs :vpcflow`)를 수집하는 것을 강력하게 권장. 왜냐하면 입력 유형은 다음 릴리스에서 더 이상 사용되지 않을 것이기 때문임. Kinesis 입력을 구성하여 대신 VPC 플로우 로그를 수집. 추가 기능에는 Kinesis 입력을 통해 이러한 이벤트에 대한 정확한 지식 추출을 수행하기 위한 색인 시간 논리가 포함.

Splunk Web(권장) 또는 `local/aws_cloudwatch_logs_tasks.conf`를 통해 데이터 수집 노드에 Splunk Add-on for Amazon Web Services에 대한 CloudWatch Logs 입력을 구성.

- [Configure a CloudWatch Logs input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatchLogs#Configure_a_CloudWatch_Logs_input_using_Splunk_Web) (recommended)
- [Configure a CloudWatch Logs input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatchLogs#Configure_a_CloudWatch_Logs_input_using_configuration_file)

### Splunk Web을 사용하여 CloudWatch Logs Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > VPC Flow Logs > CloudWatch Logs**.
- **Create New Input > Others > CloudWatch Logs**.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudWatch Logs 데이터에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. aws_cloudwatch_logs_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 친숙한 이름으로 입력.</td></tr>
<tr><td>region</td><td>AWS Region</td><td>데이터가 포함 된 AWS 지역임. aws_cloudwatch_logs_tasks.conf에서 지역 ID를 입력.</td></tr>
<tr><td>groups</td><td>Log group</td><td>로그 그룹 이름의 쉼표로 구분된 목록.
Note : 현재 릴리스에서는 로그 그룹 이름을 구성 할 때 와일드 카드를 지원하지 않음.
</td></tr>
<tr><td>only_after</td><td>Only After</td><td>
'%Y-%m-%dT%H:%M:%S' 형식의 GMT 시간 문자열. 설정된 경우이 시간 이후의 이벤트 만 쿼리되고 인덱싱됩니다. 기본값은 1970-01-01T00:00:00.
</td></tr>
<tr><td>stream_matcher</td><td>Stream Matching Regex</td><td>Stream 이름을 엄격하게 일치시키는 REGEX. . * 기본값임.</td></tr>
<tr><td>interval</td><td>Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초).</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. VPC Flow Log 데이터를 인덱싱하는 경우 aws:cloudwatchlogs:vpcflow를 입력. 다른 CloudWatch Logs 데이터를 수집하는 경우 aws:cloudwatchlogs를 입력.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudWatch Logs 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 CloudWatch Logs Input Configuration

설정 파일을 사용하여 입력을 설정하려면, 다음 템플릿을 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_cloudwatch_logs_tasks.conf`를 생성.

```properties
[<name>]
account = <value>
groups = <value>
index = <value>
interval = <value>
only_after = <value>
region = <value>
sourcetype = <value>
stream_matcher = <value>
```

다음은 두 개의 로그 그룹에서 VPC 플로우 로그 데이터를 수집하는 스탠자의 예임.

```properties
[splunkapp2:us-west-2]
account = splunkapp2
groups = SomeName/DefaultLogGroup, SomeOtherName/SomeOtherLogGroup
index = default
interval = 600
only_after = 1970-01-01T00:00:00
region = us-west-2
sourcetype = aws:cloudwatchlogs:vpcflow
stream_matcher = eni.*
```

## Splunk Add-on for AWS에 대한 CloudWatch Input Configuration

CloudWatch 데이터를 수집하도록 CloudWatch 입력을 구성 (sourcetype :`aws:cloudwatch`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 CloudWatch 입력을 구성.

- [Configure a CloudWatch input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatch#Configure_a_CloudWatch_input_using_Splunk_Web) (recommended)
- [Configure a CloudWatch input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatch#Configure_a_CloudWatch_input_using_configuration_file)

> **Note** : AWS에서 해당 측정 항목을 허용하는 샘플링 기간을 기준으로 각 최소 측정 항목이 다른 각 측정 항목 또는 측정 항목 집합에 대해 별도 CloudWatch 입력을 구성하는 것이 가장 좋음. 예를 들어 CPUUtilization은 5분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4시간의 샘플링 기간을 가짐. AWS에서 사용할 수 있는 최소 샘플링 기간보다 작은 입도를 구성하면 입력에 API 호출이 낭비됨. 자세한 내용은 [Sizing, performance, and cost considerations for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/Sizingandcost#CloudWatch) 참조.

### Splunk Web을 사용하여 CloudWatch Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > CloudWatch** 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudWatch 데이터에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리를 참조하십시오.</td></tr>
<tr><td>aws_region</td><td>AWS Regions</td><td>AWS 지역 이름. Splunk Web의 드롭 다운 목록에서 하나 이상의 영역을 선택하십시오. inputs.conf에 하나 이상의 유효한 AWS 지역 ID를 쉼표로 구분하여 입력하십시오. 자세한 내용은 AWS 설명서를 참조하십시오.
고급을 클릭하여 측정 항목 구성을 편집하십시오.</td></tr>
<tr><td>metric_namespace</td><td>Namespace</td><td>메트릭 네임 스페이스입니다. 예 : AWS / EBS. Splunk Web에서 + 네임 스페이스 추가 '및'드롭 다운 목록에서 네임 스페이스 선택 또는 수동 입력. 사용자 정의 네임 스페이스를 수동으로 입력하는 경우 나머지 필드에 대해 모든 JSON을 수동으로 입력해야합니다. inputs.conf에 지정한 지역의 유효한 네임 스페이스를 입력하십시오. 입력마다 하나의 메트릭 네임 스페이스 만 지정할 수 있습니다.</td></tr>
<tr><td>metric_dimensions</td><td>Dimensions</td><td>CloudWatch 메트릭 차원을 JSON 배열 또는 객체로, 문자열을 키로, 정규 표현식을 값으로 사용합니다. Splunk Web은 형식이 지정된 JSON을 자동으로 채워서 선택한 네임 스페이스의 모든 메트릭 차원을 수집합니다. 원하는 경우 JSON을 사용자 정의하여 컬렉션을 원하는 차원으로만 제한 할 수 있습니다. 예를 들어 SQS 네임 스페이스의 경우 [splunk. * _ current \\\\ s]를 입력하여 "splunk"로 시작하고 "_current"로 끝나는 큐 이름에 대한 메트릭 만 수집 할 수 있습니다. \ ""]}].

하나의 데이터 입력에서 여러 차원을 설정할 수 있습니다. JSON 배열을 사용하는 경우 배열의 모든 객체와 일치하는 차원이 일치합니다. JSON 객체는 정규 표현식 또는 정규 표현식 배열 인 키와 값으로 문자열을가집니다. 차원은 다음과 같은 경우에만 개체와 일치합니다.

- 객체에 설정된 키가 동일합니다.
- 각 키의 값에는 JSON 객체의 키에 대한 값의 모든 정규식과 일치하는 요소가 하나 이상 (목록의 경우) 존재합니다.

예를 들어 [{ "key": [ "val. *", ". * lue"]}]는 { "key": "value"}와 { "key": [ "value" { "key": "value", "key2": "value2"}.
예외 : BucketName 차원은 길이가 1보다 큰 와일드 카드 또는 배열을 지원하지 않습니다. 따라서 AWS / S3 네임 스페이스에서 메트릭을 수집 할 때 각 S3 버킷에 대해 별도 CloudWatch 입력을 구성하십시오. 예 : { "StorageType": [ "StandardStorage"], "BucketName": [ "my_favorite_bucket"]}.
</td></tr>
<tr><td>metric_names</td><td>Metrics</td><td>JSON 배열에서 CloudWatch 메트릭 이름. 예 : [ "CPUUtilization", "DiskReadOps", "StatusCheckFailed_System"]. Splunk Web은 사용자가 선택한 네임 스페이스의 모든 메트릭 이름에 대해 올바른 형식의 JSON을 자동으로 채 웁니다. JSON을 편집하여 수집하지 않으려는 측정 항목을 제거하십시오. 필요하지 않은 측정 항목을 수집하면 불필요한 API 호출이 발생합니다.</td></tr>
<tr><td>statistics</td><td>Metric statistics</td><td>요청하려는 메트릭 통계입니다. 기본값은 평균, 합계, SampleCount, 최대, 최소입니다. inputs.conf에서이 목록은 JSON 인코딩되어야합니다. 예 : [ "Average", "Sum", "SampleCount", "Maximum", "Minimum"].</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 소스 유형. aws : cloudwatch의 기본값을 무시하려면 값을 입력하십시오. 이벤트 추출은 소스 유형의 기본값에 의존합니다. 기본값을 변경하면 props.conf도 업데이트해야합니다.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudWatch 데이터를 저장하는 인덱스 이름입니다. 기본값은 main입니다.</td></tr>
<tr><td>polling_interval</td><td>Polling interval</td><td>폴링 간격 (초). 세분화 된 기간의 배수 여야하며 21600 (6 시간)을 넘지 않아야합니다. 이 값의 기본값은 3600입니다.이 값을 세분화 기간 값의 12 배를 초과하지 않도록 설정하는 것이 가장 좋습니다. 추가 기능은 대기 시간을 허용하기 위해 데이터를 수집하기 전에 세분성 기간이 끝난 후 4 분 내에 빌드됩니다.</td></tr>
<tr><td>period</td><td>Period</td><td>반환 된 데이터 요소의 세분성 (초)입니다. 정기적으로 측정되는 메트릭의 경우 기간은 60 초 (1 분)로 짧을 수 있으며 60의 배수 여야합니다. 다른 AWS 메트릭은 AWS에서 해당 메트릭에 허용하는 샘플링 기간을 기준으로 다른 최소 세분성을 지원할 수 있습니다. 예를 들어 CPUUtilization은 5 분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4 시간의 샘플링 기간을가집니다. 선택한 메트릭에 대해 허용 된 샘플링 기간보다 작은 세분성을 구성하지 마십시오. 그렇지 않으면보고 된 세분성이 샘플링 세분성을 반영하지만 구성된 세분성으로 레이블되어 결과가 일치하지 않게됩니다. 세분성이 작을수록 메트릭 데이터가 더 정확 해집니다. 작은 세분성을 구성하는 것은 메트릭을 정확하게 분석하고 데이터 볼륨을 제한하는 데 관심이없는 경우에 유용합니다. 광범위한보기가 수용 가능하거나 AWS에서 수집하는 데이터의 양을 제한하려는 경우 더 세밀한 구성을하십시오.</td></tr>
</table>

### 구성 파일을 사용하여 CloudWatch Input Configuration

inputs.conf에서 입력을 수동으로 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_cloudwatch://<name>]
aws_account = <value>
aws_iam_role=<value>
aws_region = <value>
metric_namespace = <value>
metric_names = <value>
metric_dimensions = <value>
statistics = <value>
period = <value>
polling_interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_cloudwatch]
aws_account =
sourcetype = aws:cloudwatch
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스텐자를 `/local`에 복사하고 이를 수동으로 `inputs.conf`를 구성하는 시작점으로 사용하려면 스탠자 제목을 aws_cloudwatch에서`aws_cloudwatch://<name>`으로 변경.

## Splunk Add-on for AWS에 대한 Description Input Configuration

Description 데이터를 수집하기 위해 Description 입력을 구성 (sourcetype : `aws:description`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Description 입력을 구성.

- [Configure a Description input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/DescriptionInput#Configure_a_Description_input_using_Splunk_Web) (recommended)
- [Configure a Description input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/DescriptionInput#Configure_a_Description_input_using_configuration_file)

> 참고 : Splunk App for AWS을 사용하는 경우이 입력을 앱에서 Metadata라고 함.

### Splunk Web을 사용하여 설명 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Description** 클릭.

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<tr> <td> account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 설명 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_description_tasks.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<tr> <td> regions </td> <td> AWS Regions </td> <td> 설명 데이터를 수집하는 AWS 지역임. Splunk Web의 드롭다운 목록에서 하나 이상의 영역을 선택. aws_description_tasks.conf에 하나 이상의 유효한 AWS 지역 ID를 쉼표로 구분하여 입력. 자세한 내용은 AWS 설명서를 참조. </td> </tr>
&lt;api name&gt; 형식의 데이터를 수집하려는 API 및 간격 (초) </td> <td> apis </td>/&lt;api 간격 (초)&gt;, &lt;api 이름&gt;/&lt;api 간격 (초)&gt; Splunk Web의 기본값은 다음과 같슴.
ec2_resources/3600, ec2_instances/3600, ec2_reserved_instances/3600, ebs_snapshots/3600, elastic_load_balancers/3600, vpcs/3600, vpc_network_acls/3600, cloudfront_distributions/3600, vpc_subnets/3600, rds_instances/3600, ec2_key_pairs/3600, ec2_security_groups/3600
이 API는이 릴리스에서 지원되는 모든 API에서 수집. 속도 제한 오류를 피하기 위해 간격을 3600 초 (1 시간) 이상으로 설정함. </td> </tr>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:description을 입력. </td> </tr>
<td> </td> <td> </td> </td> </td> <td> Splunk 플랫폼이 설명 데이터를 넣는 색인 이름. 기본값은 main임. </td> </tr>
</table>

### 구성 파일을 사용하여 설명 Input Configuration

설정 파일을 사용하여 Description 입력을 설정하려면, 다음 템플릿을 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_description_tasks.conf`를 생성.

```재산
[<이름>]
계정 = <값>
aws_iam_role = <값>
apis = <값>
색인 = <값>
regions = <value>
sourcetype = <값>
```

다음은 지원되는 모든 API에서 설명 데이터를 수집하는 스 D 자의 예임.

```재산
[desc : splunkapp2]
account = splunkapp2
3600, ec2_instances/3600, ec2_instances/3600, ec2_key_pairs/3600, ec2_security_groups/3600, api = ec2_volumes/3600, ec2_instances/3600, ec2_reserved_instances/3600, ebs_snapshots/3600, elastic_load_balancers/3600, vpcs/3600, vpc_network_acls/3600, cloudfront_distributions/3600, vpc_subnets /
색인 = 기본값
regions = us-west-2
sourcetype = aws:설명
```

## Splunk Add-on for AWS을 위한 일반 S3 Input Configuration

> 버전 4.3.0부터 Splunk Add-on for AWS은 SQS-Based S3 입력을 제공함.이 S3 입력은 다양한 유형의 로그 파일을 수집하기 위한 일반 S3 및 증분 형 S3 입력 유형에 비해 확장 성이 뛰어나고 성능이 뛰어난 대안임. S3 버킷. 사전 정의 된 다양한 사용자 정의 데이터 유형을 수집하기 위한 새로운 입력의 경우 SQS-Based S3 입력 사용을 고려함.

일반 S3 입력은 버킷의 모든 개체를 나열하고 수집할 때마다 각 버킷에서 수집되지 않은 데이터를 가져 오기 위해 각 파일의 수정 날짜를 검사함. 버킷에있는 객체 수가 많으면 처리량이 낮고 시간이 오래 걸릴 수 있음.

일반 S3 Input Configuration을 시작하기 전에 다음과 같은 예상 동작을 기록함.

1. S3 입력의 초기 스캔 시간 매개 변수를 작성한 후에 편집 할 수 없슴. S3 입력의 시작 시간을 조정해야하는 경우 삭제하고 다시 작성함.
2. S3 데이터 입력은 자주 수정되는 파일을 읽지 않음. 인덱싱 된 파일이 수정 된 경우 Splunk 플랫폼은 파일을 다시 인덱싱하여 데이터가 중복됨. 키/블랙리스트/화이트리스트 옵션을 사용하여 나중에 수정할 수없는 파일 만 색인화하도록 추가 기능에 지시함.
3. S3 데이터 입력은 압축 파일을 접미어에 따라 처리함. 파일이 해당 형식이거나 데이터 처리 오류가 발생할 경우에만이 접미어를 사용함. 데이터 입력은 다음 압축 유형을 지원.
    - zip, gzip, tar 또는 tar.gz 형식의 단일 파일
    - zip, tar 또는 tar.gz 형식의 폴더가 있거나없는 여러 파일
    > 압축 파일을 확장하려면 상당한 운영 체제 리소스가 필요함.
4. Splunk 플랫폼은 BOM이있는 UTF-8, BOM이있는 UTF-16LE/BE, BOM이있는 UTF-32BE/LE 옵션 중에서 파일에 사용 된 문자 세트를 자동 감지함. S3 키가 다른 문자 세트를 사용하는 경우 character_set 매개 변수를 사용하여 inputs.conf에 지정할 수 있으며이 수집 작업을 자체 입력으로 분리 할 수 ​​있음. 단일 입력에서 비 자동 감지 문자 세트를 혼합하면 오류가 발생함.
5. S3 버킷에 매우 많은 파일이 포함되어 있으면 단일 S3 버킷에 여러 개의 S3 입력을 구성하여 성능을 향상시킬 수 있음. Splunk 플랫폼은 각 데이터 입력에 대해 하나의 프로세스를 수행하므로 시스템의 처리 능력이 충분하면 여러 입력으로 성능이 향상됨. 자세한 내용은 Splunk Add-on for AWS의 S3 입력에 대한 성능 참조를 참조.
    > 중복 데이터 인덱싱을 방지하려면 여러 입력이 동일한 S3 폴더 및 파일 데이터를 수집하지 않는지 확인함.
6. 더 이상 적극적으로 수집하지 않아도 S3 버켓 내용을 보관하는 것이 가장 좋음. AWS는 입력이 새 파일과 변경된 파일에 대해 버킷을 스캔하는 데 사용하는 목록 키 API 호출에 대해 요금을 부과하므로 이전 S3 키를 다른 버킷이나 저장소 유형에 보관하여 비용을 줄이고 성능을 향상시킬 수 있음.
7. S3 입력을 구성한 후 새 이벤트를 처리하기 전에 몇 분 동안 기다렸다가 검색 할 수 있음. 대기 시간은 데이터를 수집하는 S3 버킷의 파일 수에 따라 달라짐. 수량이 클수록 지연 시간이 길어짐. 또한 로깅 수준이 높을수록 데이터 소화 시간이 길어짐. 디버그 모드는 매우 장황하며 프로덕션 시스템에서는 권장되지 않음.


다음 방법 중 하나를 사용하여 데이터 수집 노드에서 일반 S3 입력을 구성.

- [Splunk Web을 사용하여 일반 S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3#Configure_a_Generic_S3_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 일반 S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/S3#Configure_a_Generic_S3_input_using_configuration_file)

### Splunk Web을 사용하여 일반 S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- ** 새 입력 만들기> CloudTrail> 일반 S3 **
- ** 새 입력 만들기> CloudFront 액세스 로그> 일반 S3 **
- ** 새 입력 만들기> ELB 액세스 로그> 일반 S3 **
- ** 새 입력 만들기> S3 액세스 로그> 일반 S3 **
- ** 새 입력 만들기> 기타> 일반 S3 **

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인함. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 S3 버킷의 키에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> bucket_name </td> <td> S3 Bucket </td> <td> AWS 버킷 이름 </td> </tr>
<td> log_file_prefix </td> <td> 로그 파일 접두어 </td> <td> 로그 파일의 접두어를 구성. 이 부가 기능은이 접두사 아래의 로그 파일을 검색함. </td> </tr>
</td> </td> 로그 시작 날짜 </td> </td> </td> </td>
</td> </td> </td> </td> </td> </td>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:s3의 기본값을 무시하려는 경우에만 지정함. 드롭다운에서 sourcetype을 선택하거나 사용자 정의 sourcetype을 직접 입력할 수 있음. 액세스 로그를 색인화하려면 버킷의 로그 유형에 따라 aws:s3 : accesslogs, aws:cloudfront : accesslogs 또는 aws:elb : accesslogs를 입력. S3 버킷에서 Cloudtrack 이벤트를 직접 인덱싱하려면 sourcetype을 aws:cloudtrail로 변경. </td> </tr>
<td> Index </td> <td> Splunk 플랫폼이 S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임. </td> </tr>
<td> ct_blacklist </td> <td> CloudTrail 이벤트 블랙리스트 </td> sourcetype이 aws:cloudtrail로 설정된 경우에만 유효함. 제외 할 이벤트 이름을 지정하는 PCRE 일반 표현식임. 기본 정규식은 대용량 데이터를 생성 할 수 있는 이벤트를 제외하기 위해 ^ $임. 모든 데이터의 색인을 생성하려면 비워 두십시오. </td> </tr>
<td> Blacklist </td> </td> CloudTrail 이벤트 블랙리스트 </td> Splunk 플랫폼이 스캔에서 제외해야하는 S3 경로를 나타내는 일반 표현식임. 정규식은 전체 경로와 일치해야 함. </td> </tr>
<td> polling_interval </td> <td> 폴링 간격 </td> <td> Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 1800 초임. </td> </tr>
</table>

### 구성 파일을 사용하여 일반 S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```재산
[aws_s3://<이름>]
is_secure = <AWS에 보안 연결 사용 여부>
host_name = <S3 서비스의 호스트 이름>
aws_account = <AWS에 연결하는 데 사용되는 AWS 계정>
bucket_name = <S3 버킷 이름>
polling_interval = <통계에 대한 폴링 간격>
key_name = <S3 키 접두사>
recursion_depth = <폴더 키의 경우 -1 == unconstrained>
initial_scan_datetime = <Splunk 상대 시간>
terminal_scan_datetime = <이 날짜 시간 전에 수정 된 S3 키만 고려됨. 날짜 시간 형식 사용 : % Y- % m- % dT % H : % M : % S % z (예 : 2011-07-06T21 : 54 : 23-0700).>
max_items = <최대 추적 가능 항목>
max_retries = <완료되지 않은 항목을 스트리밍하려는 최대 시도 횟수>
화이트리스트 = <폴더 키를 사용할 때 블랙리스트에 대한 정규 표현식을 무시함.>
blacklist = <폴더 키를 사용할 때 무시할 키>
character_set = <S3 파일에 사용 된 인코딩. 기본적으로 'auto'로 설정하면 BOM이없는 UTF-8, UTF-16BE, UTF-16LE, UTF32BE 및 UTF32LE로 파일 인코딩이 자동으로 감지됨. 하나의 지정된 인코딩이 설정되면 데이터 입력은 해당 인코딩 만 처리함.>
ct_blacklist = <클라우드 레일 이벤트를 차단하는 블랙리스트. sourcetype = aws:cloudtrail을 수동으로 설정할 때만 유효함.>
ct_excluded_events_index = <제외 된 이벤트를 넣을 인덱스의 이름. 기본값은 비어 있으며 이벤트를 버립니다>
aws_iam_role = <AWS IAM 역할>
```

> 참고 : 하나의 AWS 계정에서 버킷의 서로 다른 접두사 위치에 로그를 가져 오려면 각 접두어 이름에 하나씩 여러 개의 AWS 데이터 입력을 구성해야 함. 또는,
하나의 데이터 입력을 구성 할 수 있지만 다른 AWS 계정을 사용하여 버킷의 다른 접두사가있는 위치의 로그를 수집할 수 있음.

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```재산
[aws_s3]
aws_account =
sourcetype = aws:s3
initial_scan_datetime = 기본값
max_items = 100000
max_retries = 3
polling_interval =
간격 = 30
재귀 _ 깊이 = -1
character_set = auto
is_secure = True
host_name = s3.amazonaws.com
ct_blacklist = ^ (? : 설명 | 목록 | 가져 오기)
ct_excluded_events_index =
```

## Splunk Add-on for AWS의 증분 S3 Input Configuration

> 버전 4.3.0부터 Splunk Add-on for AWS은 SQS-Based S3 입력을 제공함.이 S3 입력은 다양한 유형의 로그 파일을 수집하기 위한 일반 S3 및 증분 형 S3 입력 유형에 비해 확장 성이 뛰어나고 성능이 뛰어난 대안임. S3 버킷. 사전 정의 된 다양한 사용자 정의 데이터 유형을 수집하기 위한 새로운 입력의 경우 SQS-Based S3 입력 사용을 고려함.

증분 S3 입력은 파일 이름에 포함 된 날짜 시간 정보를 검사 점 레코드와 비교하여 버킷에서 처리되지 않은 개체 만 나열하고 검색하므로 처리 성능이 크게 향상됨.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 증분 S3 입력을 구성.

- [Splunk Web을 사용하여 증분 S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/IncrementalS3#Configure_an_Incremental_S3_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 증분 S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/IncrementalS3#Configure_an_Incremental_S3_input_using_configuration_file)

### Splunk Web을 사용하여 증분 S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- ** 새 입력 만들기> CloudTrail> 증분 S3 **
- ** 새 입력 만들기> CloudFront 액세스 로그> 증 분식 S3 **
- ** 새 입력 만들기> ELB 액세스 로그> 증 분식 S3 **
- ** 새 입력 만들기> S3 액세스 로그> 증분 S3 **

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인함. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 S3 버킷의 키에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> bucket_name </td> <td> S3 Bucket </td> <td> AWS 버킷 이름 </td> </tr>
<td> log_file_prefix </td> <td> 로그 파일 접두어 </td> <td> 다른 경로 요소와 함께 로그 파일의 접두어를 구성하여 추가 기능이 로그를 검색하는 URL을 구성합니다 파일.
로그 파일의 위치는 각 S3 증분 로그 유형마다 다릅니다.

cloudtrail :이 부가 기능은 &lt;bucket_name&gt;/log_file_prefix/AWSLogs/&lt;Account ID&gt;/CloudTrail/&lt;Region ID&gt;/&lt;YYYY/MM/DD&gt;/&lt;file_name&gt; .json.gz.
elb :이 부가 기능은 &lt;bucket_name&gt;/&lt;log_file_prefix&gt;/AWSLogs/&lt;Account ID&gt;/elasticloadbalancing/&lt;Region ID&gt;/&lt;YYYY/MM/DD&gt;/&lt;file_name&gt; .log.gz.
S3 :이 부가 기능은 &lt;bucket_name&gt; &lt;log_file_prefix&gt; <YYYY-mm-DD-HH-MM-SS> &lt;UniqueString&gt;에서 S3 액세스 로그를 검색함.
cloudfront :이 부가 기능은 &lt;bucket_name&gt;/&lt;log_file_prefix&gt; &lt;distributionID&gt; &lt;YYYY/MM/DD&gt;의 클라우드 프런트 액세스 로그를 검색함. &lt;UniqueID&gt; .gz
참고 : 하나의 AWS 계정에서 버킷의 다른 접두어가 붙은 위치에 로그를 가져 오려면 각 접두사 이름에 하나씩 여러 개의 AWS 데이터 입력을 구성해야 함. 또는 하나의 데이터 입력을 구성 할 수 있지만 다른 AWS 계정을 사용하여 버킷의 서로 다른 접두어 위치에 로그를 가져올 수 있음.
</td> </tr>
<tr> <td> log_type </td> <td> 로그 유형 </td> <td> 처리 할 로그 유형임. 이 값은이 구성 페이지에 액세스하기 위해 선택한 메뉴 경로에 따라 자동으로 설정됨. </td> </tr>
로그 시작 날짜 </td> </td> </td> </td> </td>
<tr> <td> distribution_id </td> <td> Distribution ID </td> <td> CloudFront 배포 ID임. 이 필드는 새 입력 작성> CloudFront 액세스 로그> 증 분식 S3 메뉴 경로를 통해 Input Configuration 페이지에 액세스 한 경우에만 표시됨. </td> </tr>
<tr> <td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. 이 값은이 구성 페이지에 액세스하기 위해 선택한 메뉴 경로를 기반으로 수집하려는 로그 유형에 대해 자동으로 설정됨. </td> </tr>
<td> Index </td> <td> Splunk 플랫폼이 S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임. </td> </tr>
<td> interval </td> <td> Interval </td> <td> splunkd가 모듈화 된 입력의 상태를 검사하기 전에 기다리는 시간(초). 입력이 충돌 한 경우 재시작을 트리거 할 수있다. 기본값은 30 초임. </td> </tr>
</table>

### 구성 파일을 사용하여 증분 S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```재산
[splunk_ta_aws_logs://<name>]
log_type =
aws_account =
host_name =
bucket_name =
bucket_region =
log_file_prefix =
log_start_date =
log_name_format =
aws_iam_role = 가정 할 AWS 역할.
max_retries = @integer : [- 1, 1000]. 기본값은 -1임. -1은 성공할 때까지 다시 시도 함을 의미함.
max_fails = @integer : [0, 10000]. 기본값은 10000임. 실패한 파일 수가 max_fails를 초과하면 새 키 검색을 중지함.
max_number_of_process = @ 정수 : [1, 64]. 기본값은 2임.
max_number_of_thread = @ 정수 : [1, 64]. 기본값은 4임.
```

## Splunk Add-on for AWS을 위한 SQS-Based S3 Input Configuration

Splunk Add-on for AWS을 위한 SQS-Based S3 Input Configuration
SQS-Based S3는 CloudFront 액세스 로그, 구성, ELB 액세스 로그, CloudTrail, S3 액세스 로그 및 기타 사용자 정의 데이터 유형과 같이 다양한 사전 정의 된 데이터 유형을 수집하는 데 권장되는 입력 유형임. 가능한 경우 SQS-Based S3 입력을 구성하여 지원하는 데이터 유형을 수집.

SQS-Based S3 Input Configuration을 시작하기 전에 SNS를 통해 SQS에 알림을 전송하도록 S3을 구성하여 새 이벤트가 S3 버킷에 기록되었다고 추가 기능에 알립니다. [Configure SQS] (http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 및 [Configure SNS] (http://docs.splunk.com/Documentation/AddOns/released/)를 참조. AWS/ConfigureAWS # Configure_SNS) 섹션을 참조.

또한 다음과 같은 예상되는 동작에 유의함.

1. SQS-Based S3 입력은 이벤트 알림이 SQS로 전송 된 S3 버킷에 저장된 거의 실시간으로 새로 생성 된 AWS 서비스 로그 만 수집. 과거에 발생한 모든 이벤트 또는 SNS를 통해 SQS로 전송 된 알림이없는 이벤트는 수집되지 않음. 과거에 S3 버킷에 저장된 기록 로그를 수집하려면 대신 S3 입력을 사용함. S3 입력은 초기 스캔 시간 파라미터 (로그 시작 날짜)를 설정하여 과거 지정된 시간 이후에 생성 된 데이터를 수집.
2. 여러 유형의 로그를 같은 지역의 여러 버킷에서 수집하려면 각 버켓에 대해 하나의 SQS-Based S3 입력을 생성하는 대신 보내도록 이러한 버킷을 구성하여 모든 버킷의 데이터를 수집하도록 하나의 입력을 설정할 수 있음 동일한 SQS Queue에 대한 알림. SQS-Based S3 입력 폴링 메시지.
3. S3 버킷에서 데이터를 처리 할 때 높은 처리량을 얻으려면 S3 버킷이 데이터 수집을 수평 확장하도록 여러 개의 SQS-Based S3 입력을 구성 할 수 있음.
4. SQS-Based S3 입력을 구성한 후에는 새로운 이벤트가 수집되어 검색 될 때까지 몇 분간 기다려야함. 또한 로깅 수준이 높을수록 데이터 소화 시간이 길어짐. 디버그 모드는 매우 장황하며 프로덕션 시스템에서는 권장되지 않음.
5. SQS 기반 입력을 사용하면 추가 기능에서 생성 된 API 호출을 최적화하고 SQS/SNS를 사용하여 알림 수신시 이벤트를 수집하여 S3 버킷에서 데이터를 수집할 수 있음.
6. SQS-Based S3 입력은 상태가 없슴. 즉, 여러 입력이 동일한 버킷에서 데이터를 수집할 때 하나의 입력이 다운되면 다른 입력은 계속해서 데이터를 수집하고 실패한 입력에서로드를 인계함. 이렇게하면 여러 입력을 구성하여 동일한 버킷에서 데이터를 수집하여 내결함성을 향상시킬 수 있음.

SQS-Based S3 입력은 다음과 같은 유형의 S3 로그를 지원. ** CloudTrail 로그, Config, S3 액세스 로그, CloudFront 액세스 로그 및 ELB 액세스 로그 **. 로그 파일의 위치는 입력이 SQS에서 검색하는 메시지에서 파생됨.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 SQS-Based S3 입력을 구성.

- [Splunk Web을 사용하여 SQS-Based S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 SQS-Based S3 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input_using_configuration_file)

### Splunk Web을 사용하여 SQS-Based S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- ** 새 입력 만들기> CloudTrail> SQS-Based S3 **
- ** 새 입력 만들기> CloudFront 액세스 로그> SQS-Based S3 **
- ** 새 입력 만들기> 구성> SQS-Based S3 **
- ** 새 입력 만들기> ELB 액세스 로그> SQS-Based S3 **
- ** 새 입력 만들기> S3 액세스 로그> SQS-Based S3 **
- ** 새 입력 만들기> 기타> SQS-Based S3 **

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인함. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr> <td> 인수 </td> </td> </td> </td>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 S3 버킷의 키에 액세스하는 데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> sqs_queue_region </td> <td> AWS 지역 </td> <td> SQS Queue에있는 AWS 지역. us-east-1. </td> </tr>
<td> SQS queue </td> <td> <td> SQL 큐 URL </td> </tr> <tr> <td> sqs_queue_url </td>
<td> sqs_batch_size </td> <td> SQS 배치 크기 </td> <td> 하나의 배치에서 SQS Queue에서 가져올 최대 메시지 수. 1에서 10 사이의 정수를 입력. Splunk은 작은 파일에는 큰 값을, 큰 파일에는 작은 값을 설정하도록 권장. 기본 SQS 일괄 처리 크기는 10임. 대용량 파일을 처리하고 시스템 메모리가 제한되어있는 경우이 값을 더 작은 값으로 설정함. </td> </tr>
<tr> <td> s3_file_decoder </td> <td> S3 파일 디코더 </td> 해당 로그 파일을 구문 분석하는 데 사용할 디코더. 디코더는 선택한 데이터 유형에 따라 설정됨. 사용자 정의 데이터 유형을 선택한 경우 Cloudtrail, 구성, ELB 액세스 로그, S3 액세스 로그, CloudFront 액세스 로그 중 하나를 선택. </td> </tr>
<td> sourcetype </td> <td> 수집할 이벤트의 sourcetype으로 입력에 대해 선택된 디코더에 따라 자동으로 채워짐. </td> </td> tr>
<td> 간격 </td> 간격 </td> <td> 두 데이터 수집 실행 사이의 시간(초). 기본값은 300 초임. </td> </tr>
<td> Index </td> <td> Splunk 플랫폼이 SQS-Based S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임. </td> </tr>
</table>

### 구성 파일을 사용하여 SQS-Based S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

아래의 매개 변수를 구성 할 수 있음.

```재산
[aws_sqs_based_s3://<stanza_name>]
aws_account = <값>
간격 = <값>
s3_file_decoder = <값>
sourcetype = <값>
sqs_batch_size = <값>
sqs_queue_region = <값>
sqs_queue_url = <값>
```

`s3_file_decoder '의 유효한 값은 CloudTrail, Config, S3 액세스 로그, ELB 액세스 로그, CloudFront 액세스 로그 및 CustomLog임.

기본적으로 지원되는 다른 AWS 로그 유형을 사용자 정의 로그로 처리하려면`s3_file_decoder = CustomLogs '를 설정해야 함. 이렇게하면 사용자 정의 로그를 Splunk로 처리 할 수 ​​있지만 데이터는 구문 분석하지 않음. 의미있는 이벤트로 커스텀 로그를 처리하려면`props.conf`와`transforms.conf`에서 추가 설정을 수행하여 수집 된 데이터를 분석하여 특정 요구 사항을 충족시켜야함.

이 설정에 대한 더 자세한 정보는 Add-on 디렉토리 아래의`/ README/inputs.conf.spec`을보십시오.

### 일반 S3 입력에서 SQS-Based S3 입력으로 마이그레이션

SQS-Based S3는 확장 가능하고 다른 S3 입력 유형보다 처리 성능이 뛰어 나기 때문에 S3 버킷의 실시간 데이터 수집에 권장되는 입력 유형임.

이미 데이터를 수집하기 위해 일반 S3 입력을 사용하는 경우 다음 단계를 사용하여 SQS-Based S3 입력으로 전환함.

1. AWS 서비스의 필수 구성을 수행함.
    - dead-letter queue와 적절한 가시성 타임 아웃이 구성된 SQS queue를 설정함. [Configure SQS] (http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS)를 참조.
    - SQS Queue에 알림을 보내기 위해 데이터를 수집하는 S3 버킷 (지정된 경우 S3 키 접두사가있는)을 설정함. [Configure SNS] (http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS)를 참조.
2. 방금 구성한 SQS Queue을 사용하여 SQS-Based S3 입력을 추가. [구성 및 SQS-Based S3 입력] (http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input)을 참조. 설정 후 새 입력이 활성화되어 있는지 확인하고 버킷에서 데이터 수집을 시작함.
3. 기존 일반 S3 입력을 편집하고 ** 종료 날짜/시간 ** 필드를 지금 (현재 시스템 시간)으로 설정하여 단계적으로 제거함.
4. 이전 입력의 모든 태스크 실행이 완료 될 때까지 기다리십시오. 가장 좋은 방법은 폴링 빈도의 두 배 이상을 기다리는 것임.
5. 이전 일반 S3 입력을 비활성화함.
6. 다음 검색을 실행하여 변환 중에 수집 된 중복 이벤트를 삭제.

CloudTrail 이벤트의 경우 :

```sql
색인 = xxx sourcetype = aws:cloudtrail | 소스에 의한 streamstats 수, eventID | 검색 횟수> 1 | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.eventID.indexed_time | 테이블 dup_id | outputcsv dupes.csv
```

```sql
색인 = xxx sourcetype = aws:cloudtrail | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.eventID.indexed_time | 검색 [| inputcsv dupes.csv | 형식 "(" "" "" ""OR "") "] | 지우다
```

S3 액세스 로그 :

```sql
index = xxx sourcetype = aws:s3 : accesslogs | 소스 별 streamstats 수, request_id | 검색 횟수> 1 | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.request_id.indexed_time | 테이블 dup_id | outputcsv dupes.csv
```

```sql
index = xxx sourcetype = aws:s3 : accesslogs | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.request_id.indexed_time | 검색 [| inputcsv dupes.csv | 형식 "(" "" "" ""OR "") "] | 지우다
```

CloudFront 액세스 로그의 경우 :

```sql
색인 = xxx sourcetype = aws:cloudfront : accesslogs | streamstats는 소스 별 카운트, x_edge_request_id | 검색 횟수> 1 | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.x_edge_request_id.indexed_time | 테이블 dup_id | outputcsv dupes.csv
```

```sql
색인 = xxx sourcetype = aws:cloudfront : accesslogs | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.x_edge_request_id.indexed_time | 검색 [| inputcsv dupes.csv | 형식 "(" "" "" ""OR "") "] | 지우다
```

기본로드 밸런서 (elb) 액세스 로그의 경우 :

이벤트에는 고유한 ID가 없기 때문에 해시 기능을 사용하여 중복을 제거함.

```sql
index = xxx sourcetype = aws:elb : accesslogs | 평가 해시 = sha256 (_raw) | 소스, 해시로 Stream 통계 계산 검색 횟수> 1 | eval indexed_time = strftime (_indextime, "% +") | eval dup_id = source.hash.indexed_time | 테이블 dup_id | outputcsv dupes.csv
```

```sql
index = xxx sourcetype = aws:elb : accesslogs
| 평가 해시 = sha256 (_raw)
| eval indexed_time = strftime (_indextime, "% +")
| eval dup_id = source.hash.indexed_time
| 검색 [| inputcsv dupes.csv | 형식 "(" "" "" ""OR "") "] | 지우다
```

선택적으로 기존의 일반 S3 입력을 삭제.

### SQS-Based S3 입력으로 자동 스케일링 데이터 수집

SQS-Based S3 입력 유형을 사용하면 중복 이벤트를 생성하지 않고 동일한 S3 버킷의 로그를 수집하도록 여러 입력을 구성하여 데이터 수집을 확장 할 수 있는 AWS 인프라의 자동 확장 기능을 최대한 활용할 수 있음. 이것은 매우 큰 S3 버킷에서 로그를 수집하고 데이터 수집 입력에서 병목 현상이 발생한 경우 특히 유용함.

1. SQS-Based S3 입력이 실행되는 무거운 전달자 인스턴스에 대한 AWS 자동 확장 그룹을 만듬.
    자동 확장 그룹을 만들려면 실행 구성을 지정하거나 AMI를 만들어 무거운 전달자를 호스팅하는 새 EC2 인스턴스를 제공하고 부트 스트랩 스크립트를 사용하여 AWS 용 Splunk 추가 기능을 설치하고 SQS-Based S3 입력을 구성 할 수 있음. 자동 크기 조정 그룹 및 AWS 생성 방법에 대한 자세한 내용은 AWS 설명서 (<http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html>)를 참조.
2. 다음 Amazon SQS 메트릭 중 하나에 대한 CloudWatch 경보를 설정함.
    - ApproximateNumberOfMessagesVisible (권장) : 큐에서 검색 할 수 있는 메시지 수.
    - ApproximateAgeOfOldestMessage : 큐에있는 가장 오래된 삭제되지 않은 메시지의 대략적인 경과 시간(초).
    Amazon SQS 메트릭에 대한 CloudWatch 경보 설정에 대한 지침은 AWS 설명서 (<http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQS_AlarmMetrics.html>)를 참조.
3. CloudWatch 경보를 트리거로 사용하여 SQS-Based S3 입력이 동일한 SQS Queue의 메시지를 소비하도록 구성된 새 무거운 전달자 인스턴스를 제공하여 처리 성능을 향상시킵니다.

## Splunk Add-on for AWS에 대한 청구 Input Configuration

대금 청구 데이터를 수집하도록 대금 청구 입력을 구성 (sourcetype :`aws:billing`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Billing 입력을 구성.

- [Splunk Web을 사용하여 청구 Input Configuration] (권장)
- [구성 파일을 사용하여 청구 Input Configuration]

> 참고 : 월간 보고서와 상세 보고서를 모두 수집하려는 경우 두 개의 청구 입력을 구성해야 함. 하나는 월간 보고서 용이고 다른 하나는 세부 보고서 용임. 이렇게하면, 두 리포트 유형 모두에 입력 한 값을 적용하지 않고 특정 리포트 유형에 대해`interval`과`report_file_match_regex`를 설정할 수 있음.
> 참고 : 청구 입력을 구성한 후 데이터 수집 동작 및 Add-on에 포함 된 미리 구성된 보고서에 액세스하는 방법에 대한 자세한 내용은 "Splunk Add-on for AWS의 청구 데이터 액세스"를 참조.

### Splunk Web을 사용하여 결제 Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 Create New Input> Billing을 클릭.

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<tr> <td> AWS Input Configuration </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼에서 결제 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> Bucket </td> <td> S3 Bucket </td> <td> 결제 보고서를 보관하도록 구성된 S3 버킷 </td> </tr>
<tr> <td> monthly_report_type </td> <td> 월간 보고서 </td> <td> Splunk 플랫폼이 AWS 계정에서 수집하는 월별 보고서 유형임. 다음 값 중 하나를 입력.

- 없음
- 월별보고
- 월간 비용 할당 보고서

</td> </tr>
<tr> <td> detail_report_type </td> <td> 자세한 보고서 </td> <td> Splunk 플랫폼이 AWS 계정에서 수집하는 자세한 보고서 유형임. 다음 값 중 하나를 입력.

- 없음
- 세부 결제 보고서
- 리소스 및 태그가 포함 된 세부 청구 보고서

</td> </tr>
<tr> <td> Splunk 관련 설정 </td> </tr>
<td> initial_scan_datetime </td> <td> 시작 날짜/시간 (UTC) </td> <td>이 부가 기능은이 시간 이후에 데이터를 수집하기 시작함. 이 필드를 공백으로두면 입력이 구성되기 전의 기본값이 90 일임.

> 참고 : 입력이 생성되면이 값을 변경할 수 없슴. </td> </tr>
sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:billing의 기본값을 무시하려면 값을 지정함. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함. </td> </tr>
<td> </td> <td> </td> <td> </td> <td> Splunk 플랫폼이 청구 데이터를 저장하는 인덱스 이름임. 기본값은 main임.
고급 설정 </td> </tr>
Interval </td> <td> Splunk 플랫폼이 명령을 다시 실행하기 전에 기다리는 시간(초) 또는 유효한 cron 일정을 입력. 기본값은 86400 초 (하루)임. 이 간격은 월별 보고서 유형 및 자세한 보고서 유형에 다르게 적용됨. 월별 보고서 유형의 경우 간격은 현재 월간 월간 보고서의 데이터 수집 빈도 및 변경 전의 월별 보고서의 etag를 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 버전의 월별 보고서와 일치하지 않으면 최신 보고서를 다운로드하여 최신 데이터를 가져옵니다. 자세한 보고서 유형의 경우 간격은 이전 달의 상세 보고서 etag에서 변경 사항이 있는지 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 보고서와 일치하지 않으면 보고서를 다운로드하여 최신 데이터를 얻슴. 현재 월은 월이 끝날 때까지 수집되지 않음.
AWS 청구 보고서는 보통 월 말일 후 며칠까지 최종 확정되지 않으므로 cron 표현식 0 0 8-31 * *을 사용하여 매월 첫 7 일간 데이터 수집을 건너 뛰고 여러 사본을 수집하지 않도록 할 수 있음. 완료되지 않은 달에 대한 아직 완료되지 않은 보고서. </td> </tr>
<td> report_file_match_reg </td> <td> 보고서 선택을 위한 정규 표현식 </td> <td> AWS의 보고서와 일치시키기 위해 Splunk 플랫폼이 사용하는 정규 표현식. 이 표현식은 monthly_report_type 및 detail_report_type 인수의 값을 대체함. 따라서 월 단위 및 상세 청구 보고서를 모두 수집하려고하지만 regex를 사용하여 보고서 수집 기간을 지정하려는 경우 두 개의 별도 청구 입력을 구성해야 여기서 지정한 정규식은 다음과 같은 보고서 유형 중 하나에만 적용됨. 당신은 수집하기를 원함.
이 정규식을 사용하여 필요하지 않은 데이터를 수집하지 않도록 보고서 수집을 특정 기간으로 제한함. 입력을 처음 사용하는 경우 특히 중요함. 기본적으로 추가 기능은 이전 달의 모든 사용 가능한 보고서를 수집. 크기가 큰 상세 보고서를 수집하면 매우 많은 양의 데이터가 수집 될 수 있음. 수집 한 과거 데이터의 개월 수를 제한하고자 할 수 있음. 예를 들어, \ d + -aws-billing-detailed-line-items-201 [56789] - \ d + .csv.zip 표현식을 사용하여 2015 년 1 월 이후의 상세 보고서 만 수집하거나 \ d + -aws 식을 수집할 수 있음. 2015 - ((0 [4-9]) | (10) | (11) | (12) .csv.zip) | (\ d + - 세부 정보 - 2015 년 4 월 및 그 이후에 자원 및 태그가 포함 된 세부 청구 보고서 만 수집하기 위해 aws-billing-detailed-line-items-with-resources-and-tags-201 [6789] - \ d + .csv.zip) > </tr>
<td> temp_folder </td> <td> 임시 폴더 </td> <td> 다운로드 된 세부 청구서 보고서 .zip 파일을 임시로 저장하기에 충분한 공간이있는 기본이 아닌 폴더의 전체 경로. 압축되지 않은 세부 청구서 보고서 파일의 예상 크기를 고려함. 압축 파일의 크기보다 훨씬 클 수 있음. 임시 폴더를 지정하지 않으면 Add-on은 기본적으로 시스템 임시 폴더를 사용함. </td> </tr>
</table>

### 구성 파일을 사용하여 청구 Input Configuration

inputs.conf에 입력을 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```재산
[aws_billing://<이름>]
aws_account = <값>
aws_iam_role = <값>
간격 = <값>
initial_scan_datetime = <값>
bucket_name = <값>
세부 _ 보고서 유형 = <값>
monthly_report_type = <값>
report_file_match_reg = <값>
sourcetype = <값>
색인 = <값>
host_name = s3.amazonaws.com
```

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```재산
[aws_billing]
bucket_name =
aws_account =
monthly_report_type = 월간 비용 할당 보고서
detail_report_type = 리소스 및 태그가 포함 된 세부 청구 보고서
report_file_match_reg =
간격 = 86400
sourcetype = aws:결제
host_name = s3.amazonaws.com
```

위의 값은 Splunk Web의 기본값에 해당함. 이 스텐자를/local에 복사하여 inputs.conf를 수동으로 구성하기 위한 시작점으로 사용하려면 스탠자 제목을 aws_billing에서 aws_billing:// \ <name \>으로 변경하십시오

## Splunk Add-on for AWS에 대한 비용 및 사용 보고서 Config input

비용 및 사용 보고서 데이터를 수집하도록 청구 입력을 구성 (sourcetype :`aws:billing : cur`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 비용 및 사용 보고서 입력을 구성.

- [Splunk Web을 사용하여 비용 및 사용 보고서 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/BillingCostandUsage#Configure_a_Cost_and_Usage_Report_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 비용 및 사용 보고서 Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/BillingCostandUsage#Configure_a_Cost_and_Usage_Report_input_using_configuration_file)

> AWS가 폴더로 보고서를 전달할 수 있도록 표식을 활성화하십시오 (폴더 이름은 접두사의 이름이됨). 타임 스탬프, 모든 보고서를 섭취하지 않으려는 경우 보고서 이름을 사용하여 결과를 필터링 할 수 있음.

비용 및 사용 보고서 입력을 구성한 후 자세한 내용은 [Splunk Add-on for AWS의 청구 데이터 액세스] (http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata)를 참조. 데이터 수집 동작 및 추가 기능에 포함 된 미리 구성된 보고서에 액세스하는 방법에 대해 설명함.

AWS 측면 구성 단계에 대한 자세한 내용은 AWS 설명서의 비용 및 사용 보고서 섹션을 참조.

### Splunk Web을 사용하여 비용 및 사용 보고서 Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 ** 새 입력 만들기> 청구> 청구 (비용 및 사용 보고서) **를 클릭.

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<tr> <td colspan = 3> AWS Input Configuration </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼에서 결제 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> Bucket </td> <td> S3 Bucket </td> <td> 결제 보고서를 보관하도록 구성된 S3 버킷 </td> </tr>
<td> bucket_region </td> <td> S3 Bucket </td> <td> S3 버킷이 청구 보고서를 보관하도록 설정된 지역 위치. </td> </tr>
<td> report_prefix </td> <td> 보고서 접두사 </td> <td> AWS가 보고서를 지정된 폴더로 전달할 수 있도록하는 데 사용되는 접미어임. </td> </tr>
<td> report_names </td> <td> 리포트 이름 패턴 </td> </td> </td> 리포트를 이름별로 필터링하는 데 사용되는 정규 표현식임.
<tr> <td colspan = 3> Splunk 관련 설정 </td> </tr>
<td> start_date </td> <td> 시작일 </td> <td>이 부가 기능은이 시간 이후에 데이터를 수집하기 시작함. 이 필드를 공백으로두면 입력이 구성되기 전의 기본값이 90 일임.
참고 : 입력이 생성되면이 값을 변경할 수 없슴. </td> </tr>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:billing의 기본값을 무시하려면 값을 지정함. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함. </td> </tr>
<td> </td> <td> </td> <td> </td> <td> Splunk 플랫폼이 청구 데이터를 저장하는 인덱스 이름임. 기본값은 main임. </td> </tr>
<tr> <td colspan = 3> 고급 설정 </td> </tr>
Interval </td> <td> Splunk 플랫폼이 명령을 다시 실행하기 전에 기다리는 시간(초) 또는 유효한 cron 일정을 입력. 기본값은 86400 초 (하루)임. 이 간격은 월별 보고서 유형 및 자세한 보고서 유형에 다르게 적용됨. 월별 보고서 유형의 경우 간격은 현재 월간 월간 보고서의 데이터 수집 빈도 및 변경 전의 월별 보고서의 etag를 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 버전의 월별 보고서와 일치하지 않으면 최신 보고서를 다운로드하여 최신 데이터를 가져옵니다. 자세한 보고서 유형의 경우 간격은 이전 달의 상세 보고서 etag에서 변경 사항이 있는지 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 보고서와 일치하지 않으면 보고서를 다운로드하여 최신 데이터를 얻슴. 현재 월은 월이 끝날 때까지 수집되지 않음.
AWS 청구 보고서는 보통 월 말일 후 며칠까지 최종 확정되지 않으므로 cron 표현식 0 0 8-31 * *을 사용하여 매월 첫 7 일간 데이터 수집을 건너 뛰고 여러 사본을 수집하지 않도록 할 수 있음. 완료되지 않은 달에 대한 아직 완료되지 않은 보고서. </td> </tr>
<td> temp_folder </td> <td> 임시 폴더 </td> <td> 다운로드 된 세부 청구서 보고서 .zip 파일을 임시로 저장하기에 충분한 공간이있는 기본이 아닌 폴더의 전체 경로. 압축되지 않은 세부 청구서 보고서 파일의 예상 크기를 고려함. 압축 파일의 크기보다 훨씬 클 수 있음. 임시 폴더를 지정하지 않으면 Add-on은 기본적으로 시스템 임시 폴더를 사용함. </td> </tr>
</table>

### 구성 파일을 사용하여 비용 및 사용 보고서 Input Configuration

inputs.conf에 입력을 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```재산
[aws_billing_cur://<이름>]
start_by_shell = true
aws_account = <값>
aws_iam_role = <값>
bucket_name = <값>
bucket_region = <값>
report_names = <값>
report_prefix = <값>
시작일 = <값>
temp_folder = <값>
host_name = s3.amazonaws.com
```

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```재산
[aws_billing_cur]
start_by_shell = false
aws_account = <값>
aws_iam_role = <값>
bucket_name = <값>
bucket_region = <값>
report_names = <값>
report_prefix = <값>
시작일 = <값>
temp_folder = <값>
```

위의 값은 Splunk Web의 기본값에 해당함. 이 스탠자를`/ local`에 복사하고 이것을 inputs.conf를 수동으로 설정하기 위한 시작점으로 사용하려면 스탠자 제목을`aws_billing : cur`에서`aws_billing : cur:// \ <name \>으로 변경하십시오 `.

## Splunk Add-on for AWS을 위한 Kinesis Input Configuration

Kinesis는 VPC 흐름 로그 (sourcetype :`aws:cloudwatchlogs : vpcflow`)를 수집하기 위해 권장되는 입력 유형임. 또한이 입력 유형은 Kinesis Stream을 통한 사용자 정의 데이터 유형의 수집을 지원.

Splunk Web(권장) 또는`local/aws_kinesis_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS에 대한 Kinesis 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#ak_region> AWS 설명서를 참조.

> 참고 : Kinesis 데이터 입력은 gzip 압축 또는 일반 텍스트 데이터 만 지원. 다른 인코딩으로 데이터를 가져올 수 없으며 동일한 입력에 gzip과 plaintext를 혼합하여 데이터를 가져올 수도 없슴. gzip 데이터와 일반 텍스트 데이터에 대해 별도의 Kinesis 입력을 만듬.

다음 중 한 가지 방법을 사용하여 데이터 수집 노드에 Kinesis 입력을 구성.

- [Splunk Web을 사용하여 Kinesis Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/Kinesis#Configure_a_Kinesis_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 Kinesis Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/Kinesis#Configure_a_Kinesis_input_using_configuration_file)

### Splunk Web을 사용하여 Kinesis Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- ** 새 입력 만들기> VPC 흐름 로그> Kinesis **
- ** 새로운 입력 만들기> 기타> Kinesis **

<table>

<tr> <td> 인수 </td> </td> </td> </td>
<td> AWS 계정 </td> <td> Splines 플랫폼이 Kinesis 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_kinesis_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<tr> <td> region </td> <td> AWS Region </td> <td> Kinesis Stream이 포함 된 AWS 지역임. aws_kinesis_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조. </td> </tr>
<td> stream_names </td> <td> Stream 이름 </td> <td> 쉼표로 구분된 목록의 Stream 이름. 모든 Stream을 수집하려면 비워 두십시오. </td> </tr>
<tr> <td> encoding </td> <td> </td>를 사용한 인코딩 <td> Stream 데이터의 인코딩. gzip으로 설정하거나 공백으로 두십시오. 기본값은 Base64임. 단일 입력으로 수집하는 모든 Stream 데이터는 동일한 인코딩을 가져야함. 이 입력을 통해 VPC Flow Logs 데이터를 수집하는 경우 일반적으로 인코딩은 gzip임. </td> </tr>
<tr> <td> init_stream_position </td> <td> 초기 Stream 위치 </td> <td> LATEST 또는 TRIM_HORIZON. LATEST는 입력이 사용 가능한 지점에서 데이터 수집을 시작함. TRIM_HORIZON은 가장 오래된 데이터 레코드로 수집을 시작함. </td> </tr>
<tr> <td> 형식 </td> <td> 레코드 형식 </td> <td> CloudWatchLogs 또는 없음. CloudWatchLogs를 선택하면이 부가 기능이 CloudWatchLogs 형식의 데이터를 구문 분석함. </td> </tr>
<td> sourcetype </td> <td> 이벤트의 sourcetype임. Kinesis를 통해 VPC 플로우 로그 데이터를 인덱싱하는 경우 aws:cloudwatchlogs : vpcflow를 입력. 다른 Kinesis 데이터를 수집하는 경우 aws:kinesis를 입력. </td> </tr>
<td> Index </td> <td> Splunk 플랫폼이 Kinesis 데이터를 두는 인덱스 이름임. 기본값은 main임. </td> </tr>
</table>

### 구성 파일을 사용하여 Kinesis Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플리트를 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_kinesis_tasks.conf`를 작성함.

```재산
[<이름>]
계정 = <값>
aws_iam_role = <값>
지역 = <값>
stream_names = <값>
인코딩 = <값>
init_stream_position = <값>
형식 = <값>
sourcetype = <값>
색인 = <값>
```

다음은 해당 지역에서 사용 가능한 모든 Stream에 대해 Kinesis 데이터를 수집하는 예제 스탠자임.

```재산
[splunkapp2 : us-east-1]
account = splunkapp2
지역 = 미국 동쪽 -1
인코딩 =
init_stream_position = LATEST
색인 = aws
format = CloudWatchLogs
sourcetype = aws:kinesis
```

## Splunk Add-on for AWS을 위한 SQS Input Configuration

Splunk Web(권장) 또는`local/aws_sqs_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS을 위한 SQS 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#inspector_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Splunk Web을 사용하여 SQS Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS#Configure_an_SQS_input_using_Splunk_Web) (권장)
- [구성 파일을 사용하여 SQS Input Configuration] (http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS#Configure_an_SQS_input_using_configuration_file)

### Splunk Web을 사용하여 SQS Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 ** 새 입력 만들기> Others> SQS **를 클릭.

<table>
<tr> <td> Splunk Web의 입력란 </td> <td> </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 SQS 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_sqs_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_region </td> <td> AWS 지역 </td> <td> 로그 알림 SQS Queue을 포함하는 AWS 지역. aws_sqs_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조. </td> </tr>
<td> sqs_queues </td> <td> SQS Queue </td> <td> AWS가 새 SQS 로그 통지를 보내는 대기열의 이름임. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력할 수 있음. 큐 이름은 전체 큐 URL의 마지막 세그먼트임. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue임.
여러 큐를 쉼표로 구분하여 추가 할 수 있음. </td> </tr>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:sqs의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함. </td> </tr>
<td> </td> <td> </td> <td> Splunk 플랫폼이 SQS 데이터를 저장하는 인덱스 이름. 기본값은 main임. </td> </tr>
Interval </td> <td> Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). <tr> <td> interval </td> 기본값은 30 초임. </td> </tr>
</table>

### 구성 파일을 사용하여 SQS Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플리트를 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_sqs_tasks.conf`를 작성함.

```재산
[<이름>]
aws_account = <값>
aws_region = <값>
sqs_queues = <값>
색인 = <값>
sourcetype = <값>
간격 = <값>
```