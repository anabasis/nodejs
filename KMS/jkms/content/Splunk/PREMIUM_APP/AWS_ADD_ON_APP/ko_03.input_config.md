# Input Configuration 세부 정보

## Splunk Add-on for AWS의 Config input Configuration

> Config input type은 Config 데이터의 콜렉션 (source type : `aws:config, aws:config:notification`)을 지원. 이러한 유형의 데이터를 수집하려면 SQS-Based S3 입력을 구성하는 것이 좋음.

Splunk Web을 통해 데이터 수집 노드의 Splunk Add-on for Amazon Web Services(권장) 또는 `local/inputs.conf`에 AWS Config input을 구성
이 데이터 소스는 현재 중국 또는 GovCloud가 포함되지 않은 AWS 지역의 하위 집합에서만 사용.
지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#awsconfig_region> AWS 설명서를 참조.

고유한 SQS마다 하나의 활성화된 Config modular input만 있어야 함.
다른 modular input이 액세스 및 구문 분석을 시도하는 SQS 메시지 또는 S3 레코드를 삭제하려고 할 때 여러 개의 활성화된 modular input이 충돌 가능성
운영환경으로 이동하기 전에 테스트 구성을 비활성화하거나 삭제.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Config input을 구성.

- [Configure a Config input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Config#Configure_a_Config_input_using_Splunk_Web) (recommended)
- [Configure a Config input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Config#Configure_a_Config_input_using_configuration_file)

### Splunk Web을 사용하여 Config input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Config > Config**.을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 Config 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_region</td><td>AWS Region</td><td>로그 알림 SQS Queue을 포함하는 AWS 지역. inputs.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>sqs_queue</td><td>SQS queue name</td><td>AWS가 새 Config 알림을 보내는 대기열의 이름. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력. 큐 이름은 전체 큐 URL의 마지막 세그먼트. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:config의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 업데이트해야 함.
Splunk 플랫폼은 다음과 같이이 sourcetype의 3 가지 변형을 사용하여 AWS Config 이벤트를 인덱싱함.

- Configuration 스냅 샷은 sourcetype = aws:config로 인덱싱됨.
- Configuration 변경 알림은 sourcetype = aws:config:notification으로 색인됨.
- aws_config.log의 로그는 sourcetype = aws:config:log로 인덱싱됨.

aws:config의 기본값을 수정하면 &lt;yourcustomsourcetype&gt;:notification 및 &lt;yourcustomsourcetype&gt;:log가 표시됨. </td></tr>

<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Config 데이터를 저장하는 인덱스 이름. 기본값은 main임.</td></tr>
<tr><td>Polling interval</td><td>Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 30초임.</td></tr>
</table>

### 구성 파일을 사용하여 Config input Configuration

`inputs.conf`에서 입력을 수동으로 설정하려면, 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_config://<name>]
aws_account = <value>
aws_region = <value>
sqs_queue = <value>
interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는 $SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf에서 찾을 수 있는 기본값을 가짐.

```properties
[aws_config]
aws_account =
sourcetype = aws:config
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스탠자를`/ local`에 복사하고 이를 수동으로`inputs.conf`를 구성하기 위한 시작점으로 사용할 경우, 스탠자 제목을`aws_config`에서`aws_config://<name>`으로 변경하고 필요한 추가 매개 변수 추가

### Config input에서 SQS-Based S3 입력으로 전환

SQS-Based S3 입력은 CloudTrail 데이터를 수집하기 위한 Config input에 대한 내결함성이 뛰어나고 성능이 뛰어난 대안임. Config input을 사용하여 Config 데이터를 이미 수집하고 있다면 SQS-Based S3 입력을 구성하고 Config 데이터 수집을 위한 새로운 입력으로 쉽게 전환 할 수 있음.

1. Config 데이터를 수집하는데 사용중인 Config input을 비활성화함.
2. 구성 데이터를 수집하는 SQS Queue에 dead-letter queue 및 SQS 가시성 timeout 설정을 설정함. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS)를 참조.
3. 마지막 단계에서 구성한 SQS Queue을 가리키는 SQS-Based S3 입력을 생성. 자세한 내용은 [Configure SQS-based S3 inputs for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_SQS-based_S3_inputs_for_the_Splunk_Add-on_for_AWS)을 참조.

구성 단계.
일단 구성되면 새로운 SQS-Based S3 입력이 이전 Config input을 대체하여 동일한 SQS Queue에서 Config 데이터를 수집.

## Splunk Add-on for AWS에 대한 Config Rules Input Configuration

Config Rules 입력을 구성하여 Config Rules 데이터 (sourcetype : `aws:config:rules`)를 수집.

Splunk Web(권장) 또는 `local/aws_config_rule_tasks.conf`를 통해 데이터 수집 노드의 Splunk Add-on for AWS에 대한 Config Rules 입력을 구성. 이 데이터 소스는 현재 중국 또는 GovCloud가 포함되지 않은 AWS 지역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#awsconfig_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Configure a Config Rules input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigRules#Configure_a_Config_Rules_input_using_Splunk_Web) (recommended)
- [Configure a Config Rules input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigRules#Configure_a_Config_Rules_input_using_configuration_file)

### Splunk Web을 사용하여 Config Rules Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Config Rules**을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 Config Rules 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_config_rule_tasks.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>region</td><td>Region</td><td>Config Rules이 포함 된 AWS 영역임. aws_config_rule_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>rule_names</td><td>Config Rules</td><td>Config Rules 이름은 쉼표로 구분된 목록으로 표시됨. 모든 규칙을 수집하려면 비워 두십시오.</td></tr>
<tr><td>sourcetype</td><td>Source Type</td><td>이벤트의 sourcetype. aws:config:rule의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Config Rules 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>polling_interval</td><td>Polling Interval</td><td>데이터 수집 간격 (초). 기본값은 300 초임.</td></tr>
</table>

다음은 두 개의 규칙에 대한 Config Rules 데이터를 수집하는 예제 스탠자임.

```properties
[splunkapp2:us-east-1]
aws_account = splunkapp2
region = us-east-1
index = aws
polling_interval = 300
sourcetype = aws:config:rule
rule_names=required-tags,restricted-common-ports
```

### 구성 파일을 사용하여 Config Rules Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플릿을 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_config_rule_tasks.conf`를 만듬.

```properties
[<name>]
account = <value>
region = <value>
rule_names = <value>
sourcetype = <value>
polling_interval = <value>
index = <value>
```

## Splunk Add-on for AWS의 Inspector Input Configuration

Inspector 입력을 구성하여 Inspector 데이터를 수집합니다 (sourcetype :`aws:inspector`).

Splunk Web(권장) 또는 `local/aws_inspector_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS에 대한 Inspector 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#inspector_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Configure an Inspector input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Inspector#Configure_an_Inspector_input_using_Splunk_Web) (recommended)
- [Configure an Inspector input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Inspector#Configure_an_Inspector_input_using_configuration_file)

### Splunk Web을 사용하여 Inspector Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Inspector**.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>account</td><td>AWS Account</td><td>Splunk 플랫폼이 Inspector 결과에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_inspector_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나의 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>regions</td><td>AWS Region</td><td>데이터가 포함 된 AWS 지역임. aws_inspector_tasks.conf에서 지역 ID를 쉼표로 구분된 목록에 입력.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:inspector의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 Inspector 결과를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>polling_interval</td><td>Pooling interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 300초임.
구성 파일을 사용하여 Inspector 입력 구성</td></tr>
</table>

설정 파일을 사용하여 입력을 설정하려면, 다음 템플릿을 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_inspector_tasks.conf`를 생성.

```properties
[<name>]
account = <value>
regions = <value>
index = <value>
polling_interval = <value>
sourcetype = <value>
```

다음은 Inspector 결과를 수집하는 예제 절임.

```properties
[splunkapp2:us-west-2]
account = splunkapp2
index = default
interval = 300
region = us-west-2
sourcetype = aws:inspector
```

## Splunk Add-on for AWS에 대한 CloudTrail Input Configuration

> CloudTrail 입력 유형은 CloudTrail 데이터 (sourcetype : `aws:cloudtrail`)의 수집을 지원. 그러나 이러한 유형의 데이터를 수집하려면 SQS-Based S3 입력을 구성하는 것이 좋음.

CloudTrail Input Configuration을 시작하기 전에 다음 동작을 고려.

1. 고유한 각 SQS > SNS > S3 Bucket 경로에 대해 활성화된 CloudTrail modular input 만 하나만 가져야함. 다른 modular input이 액세스 및 구문 분석을 시도하는 SQS 메시지 또는 S3 레코드를 삭제하려고 할 때 여러 개의 활성화된 modular input이 충돌을 일으킬 수 있음. 프로덕션 환경으로 이동하기 전에 테스트 구성을 비활성화하거나 삭제.

2. CloudTrail 데이터를 수집하려는 AWS 영역이 여러 개 있는 경우 Amazon Web Services는 작업중인 AWS 파티션의 모든 영역에 적용되는 트레일을 구성 할 것을 권장. 하나의 CloudTrail 입력을 설정하여 모든 지역의 로그 파일이 저장되는 중앙 집중화 된 S3 Bucket에서 데이터를 수집.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 CloudTrail 입력을 구성.

- [Configure a CloudTrail input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudTrail#Configure_a_CloudTrail_input_using_Splunk_Web) (recommended)
- [Configure a CloudTrail input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudTrail#Configure_a_CloudTrail_input_using_configuration_file)

### Splunk Web을 사용하여 CloudTrail Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > CloudTrail**을 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudTrail 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_region</td><td>AWS Region</td><td>로그 알림 SQS Queue을 포함하는 AWS 지역. inputs.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>sqs_queue</td><td>SQS queue name</td><td>AWS가 새로운 CloudTrail 로그 알림을 보내는 대기열의 이름임. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력할 수 있음. 큐 이름은 전체 큐 URL의 마지막 세그먼트임. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue임.
<tr><td>remove_files_when_done</td><td>Remove logs when done</td><td>인덱싱이 완료된 후 Splunk 플랫폼이 S3 Bucket에서 로그 파일을 삭제해야 하는지 여부를 나타내는 부울 값임. 기본값은 false임.</td></tr>
<tr><td>exclude_describe_events</td><td>Exclude events</td><td>대량의 데이터를 생성할 수 있는 읽기 전용 이벤트와 같은 특정 이벤트를 제외할지 여부를 나타내는 부울 값임. 기본값은 true임.</td></tr>
<tr><td>blacklist</td><td>Blacklist for exclusion</td><td>&lt;exclude_describe_events&gt;가 true로 설정된 경우 이벤트 이름을 지정하는 PCRE 정규식임.
공백으로두면 기본 정규식 ^(?:Describe|List|Get).을 사용할 수 있음.</td></tr>
<tr><td>excluded_events_index</td><td>Excluded events index</td><td>Splunk 플랫폼이 제외 된 이벤트를 넣어야하는 인덱스의 이름임. 기본값은 비어 있으며 이벤트를 삭제.</td></tr>
<tr><td>interval</td><td>Interval</td><td>이벤트의 sourcetype. aws:cloudtrail의 기본값을 덮어 쓰려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:cloudtrail의 기본값을 덮어 쓰려는 경우에만 값을 입력. 이벤트 추출은 소스 유형의 기본값에 의존. 기본값을 변경하면 props.conf도 업데이트.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudTrail 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 CloudTrail Input Configuration

`inputs.conf`에서 입력을 수동으로 설정하려면, 다음 템플릿을 사용하여 스탠자를 만들고`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_cloudtrail://<name>]
aws_account = <value>
aws_region = <value>
sqs_queue = <value>
exclude_describe_events = <value>
remove_files_when_done = <value>
blacklist = <value>
excluded_events_index = <value>
interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_cloudtrail]
aws_account =
sourcetype = aws:cloudtrail
exclude_describe_events = true
remove_files_when_done = false
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스텐자를 `/ local`에 복사하고 이를 수동으로`inputs.conf`를 구성하기 위한 시작점으로 사용하려면 스탠자 제목을 aws_cloudtrail에서 `aws_cloudtrail://<name>`으로 변경.

### CloudTrail 입력에서 SQS-Based S3 입력으로 전환

SQS-Based S3 입력은 CloudTail 데이터 수집을 위한 CloudTrail 입력에 대한 내결함성이 뛰어나고 성능이 뛰어난 대안임. CloudTrail 입력을 사용하여 CloudTrail 데이터를 수집중인 경우 SQS-Based S3 입력을 구성하고 CloudTrail 데이터 수집을 위한 새로운 입력으로 원활하게 전환 할 수 있음.

1. CloudTrail 데이터를 수집하는데 사용중인 CloudTrail 입력을 사용 불가능하게 함.
2. CloudTrail 데이터를 수집하는 SQS queue에 대한 dead-letter queue 및 SQS 가시성 timeout 설정을 설정함. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 참조.
3. 마지막 단계에서 구성한 SQS Queue을 가리키는 SQS-Based S3 입력을 생성. 자세한 구성 단계는 [Configure SQS-based S3 inputs for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3) 참조.

일단 구성되면 새로운 SQS-Based S3 입력이 이전 CloudTrail 입력을 대체하여 동일한 SQS Queue에서 CloudTrail 데이터를 수집.

## Splunk Add-on for AWS에 대한 CloudWatch Logs 입력 추가

> Splunk는 CloudWatch Logs 입력을 사용하여 VPC Flow Logs 데이터 (sourcetype : `aws:cloudwatchlogs :vpcflow`)를 수집하는 것을 강력하게 권장. 왜냐하면 입력 유형은 다음 릴리스에서 더 이상 사용되지 않을 것이기 때문임. Kinesis 입력을 구성하여 대신 VPC 플로우 로그를 수집. Add-on에는 Kinesis 입력을 통해 이러한 이벤트에 대한 정확한 지식 추출을 수행하기 위한 색인 시간 논리가 포함.

Splunk Web(권장) 또는 `local/aws_cloudwatch_logs_tasks.conf`를 통해 데이터 수집 노드에 Splunk Add-on for Amazon Web Services에 대한 CloudWatch Logs 입력을 구성.

- [Configure a CloudWatch Logs input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatchLogs#Configure_a_CloudWatch_Logs_input_using_Splunk_Web) (recommended)
- [Configure a CloudWatch Logs input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatchLogs#Configure_a_CloudWatch_Logs_input_using_configuration_file)

### Splunk Web을 사용하여 CloudWatch Logs Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > VPC Flow Logs > CloudWatch Logs**.
- **Create New Input > Others > CloudWatch Logs**.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudWatch Logs 데이터에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. aws_cloudwatch_logs_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 친숙한 이름으로 입력.</td></tr>
<tr><td>region</td><td>AWS Region</td><td>데이터가 포함 된 AWS 지역임. aws_cloudwatch_logs_tasks.conf에서 지역 ID를 입력.</td></tr>
<tr><td>groups</td><td>Log group</td><td>로그 그룹 이름의 쉼표로 구분된 목록.
Note : 현재 릴리스에서는 로그 그룹 이름을 구성 할 때 와일드 카드를 지원하지 않음.
</td></tr>
<tr><td>only_after</td><td>Only After</td><td>
'%Y-%m-%dT%H:%M:%S' 형식의 GMT 시간 문자열. 설정된 경우이 시간 이후의 이벤트 만 쿼리되고 인덱싱됩니다. 기본값은 1970-01-01T00:00:00.
</td></tr>
<tr><td>stream_matcher</td><td>Stream Matching Regex</td><td>Stream 이름을 엄격하게 일치시키는 REGEX. . * 기본값임.</td></tr>
<tr><td>interval</td><td>Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초).</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. VPC Flow Log 데이터를 인덱싱하는 경우 aws:cloudwatchlogs:vpcflow를 입력. 다른 CloudWatch Logs 데이터를 수집하는 경우 aws:cloudwatchlogs를 입력.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudWatch Logs 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 CloudWatch Logs Input Configuration

설정 파일을 사용하여 입력을 설정하려면, 다음 템플릿을 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_cloudwatch_logs_tasks.conf`를 생성.

```properties
[<name>]
account = <value>
groups = <value>
index = <value>
interval = <value>
only_after = <value>
region = <value>
sourcetype = <value>
stream_matcher = <value>
```

다음은 두 개의 로그 그룹에서 VPC 플로우 로그 데이터를 수집하는 스탠자의 예임.

```properties
[splunkapp2:us-west-2]
account = splunkapp2
groups = SomeName/DefaultLogGroup, SomeOtherName/SomeOtherLogGroup
index = default
interval = 600
only_after = 1970-01-01T00:00:00
region = us-west-2
sourcetype = aws:cloudwatchlogs:vpcflow
stream_matcher = eni.*
```

## Splunk Add-on for AWS에 대한 CloudWatch Input Configuration

CloudWatch 데이터를 수집하도록 CloudWatch 입력을 구성 (sourcetype :`aws:cloudwatch`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 CloudWatch 입력을 구성.

- [Configure a CloudWatch input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatch#Configure_a_CloudWatch_input_using_Splunk_Web) (recommended)
- [Configure a CloudWatch input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/CloudWatch#Configure_a_CloudWatch_input_using_configuration_file)

> **Note** : AWS에서 해당 측정 항목을 허용하는 샘플링 기간을 기준으로 각 최소 측정 항목이 다른 각 측정 항목 또는 측정 항목 집합에 대해 별도 CloudWatch 입력을 구성하는 것이 가장 좋음. 예를 들어 CPUUtilization은 5분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4시간의 샘플링 기간을 가짐. AWS에서 사용할 수 있는 최소 샘플링 기간보다 작은 입도를 구성하면 입력에 API 호출이 낭비됨. 자세한 내용은 [Sizing, performance, and cost considerations for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/Sizingandcost#CloudWatch) 참조.

### Splunk Web을 사용하여 CloudWatch Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > CloudWatch** 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 CloudWatch 데이터에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리를 참조하십시오.</td></tr>
<tr><td>aws_region</td><td>AWS Regions</td><td>AWS 지역 이름. Splunk Web의 드롭 다운 목록에서 하나 이상의 영역을 선택하십시오. inputs.conf에 하나 이상의 유효한 AWS Region ID를 쉼표로 구분하여 입력하십시오. 자세한 내용은 AWS 설명서를 참조하십시오.
고급을 클릭하여 측정 항목 구성을 편집하십시오.</td></tr>
<tr><td>metric_namespace</td><td>Namespace</td><td>메트릭 네임 스페이스입니다. 예 : AWS / EBS. Splunk Web에서 + 네임 스페이스 추가 '및'드롭 다운 목록에서 네임 스페이스 선택 또는 수동 입력. 사용자 정의 네임 스페이스를 수동으로 입력하는 경우 나머지 필드에 대해 모든 JSON을 수동으로 입력해야합니다. inputs.conf에 지정한 지역의 유효한 네임 스페이스를 입력하십시오. 입력마다 하나의 메트릭 네임 스페이스 만 지정할 수 있습니다.</td></tr>
<tr><td>metric_dimensions</td><td>Dimensions</td><td>CloudWatch 메트릭 차원을 JSON 배열 또는 객체로, 문자열을 키로, 정규 표현식을 값으로 사용합니다. Splunk Web은 형식이 지정된 JSON을 자동으로 채워서 선택한 네임 스페이스의 모든 메트릭 차원을 수집합니다. 원하는 경우 JSON을 사용자 정의하여 컬렉션을 원하는 차원으로만 제한 할 수 있습니다. 예를 들어 SQS 네임 스페이스의 경우 [splunk. * _ current \\\\ s]를 입력하여 "splunk"로 시작하고 "_current"로 끝나는 큐 이름에 대한 메트릭 만 수집 할 수 있습니다. \ ""]}].

하나의 데이터 입력에서 여러 차원을 설정할 수 있습니다. JSON 배열을 사용하는 경우 배열의 모든 객체와 일치하는 차원이 일치합니다. JSON 객체는 정규 표현식 또는 정규 표현식 배열 인 키와 값으로 문자열을가집니다. 차원은 다음과 같은 경우에만 개체와 일치합니다.

- 객체에 설정된 키가 동일합니다.
- 각 키의 값에는 JSON 객체의 키에 대한 값의 모든 정규식과 일치하는 요소가 하나 이상 (목록의 경우) 존재합니다.

예를 들어 [{ "key": [ "val. *",".* lue"]}]는 { "key": "value"}와 { "key": [ "value" { "key": "value", "key2": "value2"}.
예외 : BucketName 차원은 길이가 1보다 큰 와일드 카드 또는 배열을 지원하지 않습니다. 따라서 AWS / S3 네임 스페이스에서 메트릭을 수집 할 때 각 S3 Bucket에 대해 별도 CloudWatch 입력을 구성하십시오. 예 : { "StorageType": [ "StandardStorage"], "BucketName": [ "my_favorite_bucket"]}.
</td></tr>
<tr><td>metric_names</td><td>Metrics</td><td>JSON 배열에서 CloudWatch 메트릭 이름. 예 : [ "CPUUtilization", "DiskReadOps", "StatusCheckFailed_System"]. Splunk Web은 사용자가 선택한 네임 스페이스의 모든 메트릭 이름에 대해 올바른 형식의 JSON을 자동으로 채 웁니다. JSON을 편집하여 수집하지 않으려는 측정 항목을 제거하십시오. 필요하지 않은 측정 항목을 수집하면 불필요한 API 호출이 발생합니다.</td></tr>
<tr><td>statistics</td><td>Metric statistics</td><td>요청하려는 메트릭 통계입니다. 기본값은 평균, 합계, SampleCount, 최대, 최소입니다. inputs.conf에서이 목록은 JSON 인코딩되어야합니다. 예 : [ "Average", "Sum", "SampleCount", "Maximum", "Minimum"].</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 소스 유형. aws : cloudwatch의 기본값을 무시하려면 값을 입력하십시오. 이벤트 추출은 소스 유형의 기본값에 의존합니다. 기본값을 변경하면 props.conf도 업데이트해야합니다.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 CloudWatch 데이터를 저장하는 인덱스 이름입니다. 기본값은 main입니다.</td></tr>
<tr><td>polling_interval</td><td>Polling interval</td><td>폴링 간격 (초). 세분화 된 기간의 배수 여야하며 21600 (6 시간)을 넘지 않아야합니다. 이 값의 기본값은 3600입니다.이 값을 세분화 기간 값의 12 배를 초과하지 않도록 설정하는 것이 가장 좋습니다. Add-on은 대기 시간을 허용하기 위해 데이터를 수집하기 전에 세분성 기간이 끝난 후 4 분 내에 빌드됩니다.</td></tr>
<tr><td>period</td><td>Period</td><td>반환 된 데이터 요소의 세분성 (초)입니다. 정기적으로 측정되는 메트릭의 경우 기간은 60 초 (1 분)로 짧을 수 있으며 60의 배수 여야합니다. 다른 AWS 메트릭은 AWS에서 해당 메트릭에 허용하는 샘플링 기간을 기준으로 다른 최소 세분성을 지원할 수 있습니다. 예를 들어 CPUUtilization은 5 분의 샘플링 기간을 가지지 만 Billing Estimated Charge는 4 시간의 샘플링 기간을가집니다. 선택한 메트릭에 대해 허용 된 샘플링 기간보다 작은 세분성을 구성하지 마십시오. 그렇지 않으면보고 된 세분성이 샘플링 세분성을 반영하지만 구성된 세분성으로 레이블되어 결과가 일치하지 않게됩니다. 세분성이 작을수록 메트릭 데이터가 더 정확 해집니다. 작은 세분성을 구성하는 것은 메트릭을 정확하게 분석하고 데이터 볼륨을 제한하는데 관심이없는 경우에 유용합니다. 광범위한보기가 수용 가능하거나 AWS에서 수집하는데이터의 양을 제한하려는 경우 더 세밀한 구성을하십시오.</td></tr>
</table>

### 구성 파일을 사용하여 CloudWatch Input Configuration

inputs.conf에서 입력을 수동으로 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_cloudwatch://<name>]
aws_account = <value>
aws_iam_role=<value>
aws_region = <value>
metric_namespace = <value>
metric_names = <value>
metric_dimensions = <value>
statistics = <value>
period = <value>
polling_interval = <value>
sourcetype = <value>
index = <value>
```

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_cloudwatch]
aws_account =
sourcetype = aws:cloudwatch
queueSize = 128KB
persistentQueueSize = 24MB
interval = 30
```

위의 값은 Splunk Web의 기본값뿐만 아니라 구성을 위해 Splunk Web에 노출되지 않은 일부 내부값에 해당함. 이 스텐자를 `/local`에 복사하고 이를 수동으로 `inputs.conf`를 구성하는 시작점으로 사용하려면 스탠자 제목을 aws_cloudwatch에서 `aws_cloudwatch://<name>`으로 변경.

## Splunk Add-on for AWS에 대한 Description Input Configuration

Description 데이터를 수집하기 위해 Description 입력을 구성 (sourcetype : `aws:description`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Description 입력을 구성.

- [Configure a Description input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/DescriptionInput#Configure_a_Description_input_using_Splunk_Web) (recommended)
- [Configure a Description input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/DescriptionInput#Configure_a_Description_input_using_configuration_file)

> 참고 : Splunk App for AWS을 사용하는 경우이 입력을 앱에서 Metadata라고 함.

### Splunk Web을 사용하여 설명 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 줄에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Description** 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>account</td><td>AWS Account</td><td>Splunk 플랫폼이 Description 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. aws_description_tasks.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정할 IAM 역할, IAM 역할 관리</td></tr>
<tr><td>regions</td><td>AWS Regions</td><td>Description 데이터를 수집하는 AWS Region임. Splunk Web의 드롭다운 목록에서 하나 이상의 영역을 선택. aws_description_tasks.conf에 하나 이상의 유효한 AWS Region ID를 쉼표로 구분하여 입력. 자세한 내용은 AWS 설명서를 참조.</td></tr>
<tr><td>apis</td><td>APIs/Interval (seconds)</td><td>APIs you want to collect data from, and intervals for each API, in the format of &lt;api name&gt;/&lt;api interval in seconds&gt;,&lt;api name&gt;/&lt;api interval in seconds&gt;. The default value in Splunk Web is

ec2_volumes/3600,ec2_instances/3600,ec2_reserved_instances/3600,ebs_snapshots/3600,elastic_load_balancers/3600,vpcs/3600,vpc_network_acls/3600,cloudfront_distributions/3600,vpc_subnets/3600,rds_instances/3600,ec2_key_pairs/3600,ec2_security_groups/3600

이 API는이 릴리스에서 지원되는 모든 API에서 수집. 속도 제한 오류를 피하기 위해 간격을 3600 초 (1 시간) 이상으로 설정함.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:description을 입력.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 설명 데이터를 넣는 색인 이름. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 Description Input Configuration

설정 파일을 사용하여 Description 입력을 설정하려면, 다음 템플릿을 사용하여`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_description_tasks.conf`를 생성.

```properties
[<name>]
account = <value>
aws_iam_role=<value>
apis = <value>
index = <value>
regions = <value>
sourcetype = <value>
```

다음은 지원되는 모든 API에서 설명 데이터를 수집하는 스 D 자의 예임.

```properties
[desc:splunkapp2]
account = splunkapp2
apis = ec2_volumes/3600,ec2_instances/3600,ec2_reserved_instances/3600,ebs_snapshots/3600,elastic_load_balancers/3600,vpcs/3600,vpc_network_acls/3600,cloudfront_distributions/3600,vpc_subnets/3600,rds_instances/3600,ec2_key_pairs/3600,ec2_security_groups/3600
index = default
regions = us-west-2
sourcetype = aws:description
```

## Splunk Add-on for AWS을 위한 General S3 Input Configuration

> 버전 4.3.0부터 Splunk Add-on for AWS은 SQS-Based S3 입력을 제공. 이 S3 입력은 다양한 유형의 로그 파일을 수집하기 위한 General S3 및 Incremental S3 입력 유형에 비해 확장성이 뛰어나고 성능이 뛰어난 대안임. S3 Bucket. 사전 정의 된 다양한 사용자 정의 데이터 유형을 수집하기 위한 새로운 입력의 경우 SQS-Based S3 입력 사용을 고려.

General S3 입력은 버킷의 모든 개체를 나열하고 수집할 때마다 각 버킷에서 수집되지 않은 데이터를 가져 오기 위해 각 파일의 수정 날짜를 검사함. 버킷에 있는 객체 수가 많으면 처리량이 낮고 시간이 오래 걸릴 수 있음.

General S3 Input Configuration을 시작하기 전에 다음과 같은 예상 동작을 기록함.

1. S3 입력의 초기 스캔 시간 매개 변수를 작성한 후에 편집 할 수 없음. S3 입력의 시작 시간을 조정해야 하는 경우 삭제하고 다시 작성.
2. S3 데이터 입력은 자주 수정되는 파일을 읽지 않음. 인덱싱된 파일이 수정된 경우 Splunk 플랫폼은 파일을 다시 인덱싱하여 데이터가 중복됨. 키/블랙리스트/화이트리스트 옵션을 사용하여 나중에 수정할 수 없는 파일만 색인화하도록 Add-on에 지시함.
3. S3 데이터 입력은 압축 파일을 접미어에 따라 처리함. 파일이 해당 형식이거나 데이터 처리 오류가 발생할 경우에만 이 접미어를 사용. 데이터 입력은 다음 압축 유형을 지원.
    - zip, gzip, tar 또는 tar.gz 형식의 단일 파일
    - zip, tar 또는 tar.gz 형식의 폴더가 있거나없는 여러 파일
    > 압축 파일을 확장하려면 상당한 운영 체제 리소스가 필요함.
4. Splunk 플랫폼은 UTF-8 with BOM, UTF-16LE/BE with BOM, UTF-32BE/LE with BOM 옵션 중에서 파일에 사용 된 문자 세트를 자동감지. S3 키가 다른 문자 세트를 사용하는 경우 character_set 매개 변수를 사용하여 inputs.conf에 지정할 수 있으며이 수집 작업을 자체 입력으로 분리 할 수 ​​있음. 단일 입력에서 비 자동 감지 문자 세트를 혼합하면 오류가 발생.
5. S3 Bucket에 매우 많은 파일이 포함되어 있으면 단일 S3 Bucket에 여러 개의 S3 입력을 구성하여 성능을 향상시킬 수 있음. Splunk 플랫폼은 각 데이터 입력에 대해 하나의 프로세스를 수행하므로 시스템의 처리 능력이 충분하면 여러 입력으로 성능이 향상됨. 자세한 내용은 Splunk Add-on for AWS의 S3 입력에 대한 성능 참조.
    > 중복 데이터 인덱싱을 방지하려면 여러 입력이 동일한 S3 폴더 및 파일 데이터를 수집하지 않는지 확인.
6. 더 이상 적극적으로 수집하지 않아도 S3 버켓 내용을 보관하는 것이 가장 좋음. AWS는 입력이 새 파일과 변경된 파일에 대해 버킷을 스캔하는데 사용하는 목록 키 API 호출에 대해 요금을 부과하므로 이전 S3 키를 다른 버킷이나 저장소 유형에 보관하여 비용을 줄이고 성능을 향상시킬 수 있음.
7. S3 입력을 구성한 후 새 이벤트를 처리하기 전에 몇 분 동안 기다렸다가 검색 할 수 있음. 대기 시간은 데이터를 수집하는 S3 Bucket의 파일 수에 따라 달라짐. 수량이 클수록 지연 시간이 길어짐. 또한 로깅 수준이 높을수록 데이터 소화 시간이 길어짐. 디버그 모드는 매우 장황하며 프로덕션 시스템에서는 권장되지 않음.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 General S3 입력을 구성.

- [Configure a Generic S3 input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/S3#Configure_a_Generic_S3_input_using_Splunk_Web) (recommended)
- [Configure a Generic S3 input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/S3#Configure_a_Generic_S3_input_using_configuration_file)

### Splunk Web을 사용하여 General S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > CloudTrail > Generic S3**
- **Create New Input > CloudFront Access Log > Generic S3**
- **Create New Input > ELB Access Logs > Generic S3**
- **Create New Input > S3 Access Logs > Generic S3**
- **Create New Input > Others > Generic S3**

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 S3 Bucket의 키에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리</td></tr>
<tr><td>bucket_name</td><td>S3 Bucket</td><td>AWS 버킷 이름</td></tr>
<tr><td>log_file_prefix</td><td>Log File Prefix</td><td>로그 파일의 접두어를 구성. 이 부가 기능은이 접두사 아래의 로그 파일을 검색함.</td></tr>
<tr><td>log_start_date</td><td>Start Date/Time</td><td>The start date of the log.</td></tr>
<tr><td>log_end_date</td><td>End Date/Time</td><td>The end date of the log.</td></tr>
<tr><td>sourcetype</td><td>Source Type</td><td>이벤트의 sourcetype. aws:s3의 기본값을 무시하려는 경우에만 지정함. 드롭다운에서 sourcetype을 선택하거나 사용자 정의 sourcetype을 직접 입력할 수 있음. 액세스 로그를 색인화하려면 버킷의 로그 유형에 따라 aws:s3:accesslogs, aws:cloudfront:accesslogs 또는 aws:elb:accesslogs를 입력. S3 Bucket에서 Cloudtrack 이벤트를 직접 인덱싱하려면 sourcetype을 aws:cloudtrail로 변경.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>ct_blacklist</td><td>CloudTrail Event Blacklist</td><td>sourcetype이 aws:cloudtrail로 설정된 경우에만 유효함. 제외할 이벤트 이름을 지정하는 PCRE 일반 표현식임. 기본 정규식은 대용량 데이터를 생성할 수 있는 이벤트를 제외하기 위해 ^$임. 모든 데이터의 색인을 생성하려면 비워 둠.</td></tr>
<tr><td>blacklist</td><td>CloudTrail Event Blacklist</td><td>Splunk 플랫폼이 스캔에서 제외해야 하는 S3 경로를 나타내는 일반 표현식임. 정규식은 전체 경로와 일치해야 함.</td></tr>
<tr><td>polling_interval</td><td>Polling Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). 기본값은 1800초임.</td></tr>
</table>

### 구성 파일을 사용하여 General S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_s3://<name>]
is_secure = <whether use secure connection to AWS>
host_name = <the host name of the S3 service>
aws_account = <AWS account used to connect to AWS>
bucket_name = <S3 bucket name>
polling_interval = <Polling interval for statistics>
key_name = <S3 key prefix>
recursion_depth = <For folder keys, -1 == unconstrained>
initial_scan_datetime = <Splunk relative time>
terminal_scan_datetime = <Only S3 keys which have been modified before this datetime will be considered. Using datetime format: %Y-%m-%dT%H:%M:%S%z (for example, 2011-07-06T21:54:23-0700).>
max_items = <Max trackable items.>
max_retries = <Max number of retry attempts to stream incomplete items.>
whitelist = <Override regex for blacklist when using a folder key.>
blacklist = <Keys to ignore when using a folder key.>
character_set = <The encoding used in your S3 files. Default to 'auto' meaning that file encoding will be detected automatically amoung UTF-8, UTF8 without BOM, UTF-16BE, UTF-16LE, UTF32BE and UTF32LE. Notice that once one specified encoding is set, data input will only handle that encoding.>
ct_blacklist = <The blacklist to exclude cloudtrail events. Only valid when manually set sourcetype=aws:cloudtrail.>
ct_excluded_events_index = <name of index to put excluded events into. default is empty, which discards the events>
aws_iam_role = <AWS IAM role to be assumed>
```

> Note : 하나의 AWS 계정에서 버킷의 서로 다른 접두사 위치에 로그를 가져 오려면 각 접두어 이름에 하나씩 여러 개의 AWS 데이터 입력을 구성해야 함. 또는, 하나의 데이터 입력을 구성 할 수 있지만 다른 AWS 계정을 사용하여 버킷의 다른 접두사가 있는 위치의 로그를 수집할 수 있음.

이러한 설정 중 일부는 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_s3]
aws_account =
sourcetype = aws:s3
initial_scan_datetime = default
max_items = 100000
max_retries = 3
polling_interval=
interval = 30
recursion_depth = -1
character_set = auto
is_secure = True
host_name = s3.amazonaws.com
ct_blacklist = ^(?:Describe|List|Get)
ct_excluded_events_index =
```

## Splunk Add-on for AWS의 Incremental S3 Input Configuration

> 버전 4.3.0부터 Splunk Add-on for AWS은 SQS-Based S3 입력을 제공. 이 S3 입력은 다양한 유형의 로그 파일을 수집하기 위한 General S3 및 Incremental S3 입력 유형에 비해 확장성이 뛰어나고 성능이 뛰어난 대안임. S3 Bucket. 사전 정의 된 다양한 사용자 정의 데이터 유형을 수집하기 위한 새로운 입력의 경우 SQS-Based S3 입력 사용을 고려.

Incremental S3 입력은 파일 이름에 포함 된 날짜 시간 정보를 검사 점 레코드와 비교하여 버킷에서 처리되지 않은 개체 만 나열하고 검색하므로 처리 성능이 크게 향상됨.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Incremental S3 입력을 구성.

- [Configure an Incremental S3 input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/IncrementalS3#Configure_an_Incremental_S3_input_using_Splunk_Web) (recommended)
- [Configure an Incremental S3 input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/IncrementalS3#Configure_an_Incremental_S3_input_using_configuration_file)

### Splunk Web을 사용하여 Incremental S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > CloudTrail > Incremental S3**
- **Create New Input > CloudFront Access Log > Incremental S3**
- **Create New Input > ELB Access Logs > Incremental S3**
- **Create New Input > S3 Access Logs > Incremental S3**

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 S3 Bucket의 키에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리</td></tr>
<tr><td>bucket_name</td><td>S3 Bucket</td><td>AWS Bucket Name</td></tr>
<tr><td>log_file_prefix</td><td>Log File Prefix</td><td>Configure the prefix of the log file, which along with other path elements, forms the URL under which the addon will search the log files.
The locations of the log files are different for each S3 incremental log type:

cloudtrail: This add-on will search for the cloudtrail logs under &lt;bucket_name&gt;/&lt;log_file_prefix&gt;/AWSLogs/&lt;Account ID&gt;/CloudTrail/&lt;Region ID&gt;/&lt;YYYY/MM/DD&gt;/&lt;file_name&gt;.json.gz.
elb: This add-on will search the elb access logs under &lt;bucket_name&gt;/&lt;log_file_prefix&gt;/AWSLogs/&lt;Account ID&gt;/elasticloadbalancing/&lt;Region ID&gt;/&lt;YYYY/MM/DD&gt;/&lt;file_name&gt;.log.gz.
S3: This add-on will search the S3 access logs under &lt;bucket_name&gt;/&lt;log_file_prefix&gt;&lt;YYYY-mm-DD-HH-MM-SS&gt;&lt;UniqueString&gt;.
cloudfront: This add-on will search the cloudfront access logs under &lt;bucket_name&gt;/&lt;log_file_prefix&gt;&lt;distributionID&gt;&lt;YYYY/MM/DD&gt;.&lt;UniqueID&gt;.gz
참고 : 하나의 AWS 계정에서 버킷의 다른 접두어가 붙은 위치에 로그를 가져 오려면 각 접두사 이름에 하나씩 여러 개의 AWS 데이터 입력을 구성해야 함. 또는 하나의 데이터 입력을 구성 할 수 있지만 다른 AWS 계정을 사용하여 버킷의 서로 다른 접두어 위치에 로그를 가져올 수 있음.
</td></tr>
<tr><td>log_type</td><td>Log Type</td><td>처리 할 로그 유형임. 이 값은이 구성 페이지에 액세스하기 위해 선택한 메뉴 경로에 따라 자동으로 설정됨.</td></tr>
<tr><td>log_start_date</td><td>Log Start Date</td><td>The start date of the log.</td></tr>
<tr><td>distribution_id</td><td>Distribution ID</td><td>CloudFront 배포 ID임. 이 필드는 Create New Input > CloudFront Access Log > Incremental S3 메뉴 경로를 통해 Input Configuration 페이지에 액세스한 경우에만 표시됨.</td></tr>
<tr><td>sourcetype</td><td>Source Type</td><td>이벤트의 sourcetype. 이 값은이 구성 페이지에 액세스하기 위해 선택한 메뉴 경로를 기반으로 수집하려는 로그 유형에 대해 자동으로 설정됨.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td>interval</td><td>Interval</td><td>splunkd가 모듈화 된 입력의 상태를 검사하기 전에 기다리는 시간(초). 입력이 충돌 한 경우 재시작을 트리거 할 수있다. 기본값은 30초임.</td></tr>
</table>

### 구성 파일을 사용하여 Incremental S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[splunk_ta_aws_logs://<name>]
log_type =
aws_account =
host_name =
bucket_name =
bucket_region =
log_file_prefix =
log_start_date =
log_name_format =
aws_iam_role = AWS IAM role that to be assumed.
max_retries = @integer:[-1, 1000]. default is -1. -1 means retry until success.
max_fails = @integer: [0, 10000]. default is 10000. Stop discovering new keys if the number of failed files exceeded the max_fails.
max_number_of_process = @integer:[1, 64]. default is 2.
max_number_of_thread = @integer:[1, 64]. default is 4.
```

## Splunk Add-on for AWS을 위한 SQS-Based S3 Input Configuration

SQS-Based S3는 CloudFront Access Logs, Config, ELB Access Logs, CloudTrail, S3 Access Logs 및 기타 사용자 정의 데이터 유형과 같이 다양한 사전 정의된 데이터 유형을 수집하는데 권장되는 입력 유형임. 가능한 경우 SQS-Based S3 입력을 구성하여 지원하는 데이터 유형을 수집.

SQS-Based S3 Input Configuration을 시작하기 전에 SNS를 통해 SQS에 알림을 전송하도록 S3을 구성하여 새 이벤트가 S3 Bucket에 기록되었다고 Add-on에 알림. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 및 [Configure SNS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SNS)를 참조.

또한 다음과 같은 예상되는 동작에 유의함.

1. SQS-Based S3 입력은 이벤트 알림이 SQS로 전송 된 S3 Bucket에 저장된 거의 실시간으로 새로 생성 된 AWS 서비스 로그 만 수집. 과거에 발생한 모든 이벤트 또는 SNS를 통해 SQS로 전송 된 알림이없는 이벤트는 수집되지 않음. 과거에 S3 Bucket에 저장된 기록 로그를 수집하려면 대신 S3 입력을 사용. S3 입력은 초기 스캔 시간 파라미터 (로그 시작 날짜)를 설정하여 과거 지정된 시간 이후에 생성 된 데이터를 수집.
2. 여러 유형의 로그를 같은 지역의 여러 버킷에서 수집하려면 각 버켓에 대해 하나의 SQS-Based S3 입력을 생성하는 대신 보내도록 이러한 버킷을 구성하여 모든 버킷의 데이터를 수집하도록 하나의 입력을 설정할 수 있음 동일한 SQS Queue에 대한 알림. SQS-Based S3 입력 폴링 메시지.
3. S3 Bucket에서 데이터를 처리 할 때 높은 처리량을 얻으려면 S3 Bucket이 데이터 수집을 수평 확장하도록 여러 개의 SQS-Based S3 입력을 구성 할 수 있음.
4. SQS-Based S3 입력을 구성한 후에는 새로운 이벤트가 수집되어 검색 될 때까지 몇 분간 기다려야함. 또한 로깅 수준이 높을수록 데이터 소화 시간이 길어짐. 디버그 모드는 매우 장황하며 프로덕션 시스템에서는 권장되지 않음.
5. SQS 기반 입력을 사용하면 Add-on에서 생성 된 API 호출을 최적화하고 SQS/SNS를 사용하여 알림 수신시 이벤트를 수집하여 S3 Bucket에서 데이터를 수집할 수 있음.
6. SQS-Based S3 입력은 상태가 없음. 즉, 여러 입력이 동일한 버킷에서 데이터를 수집할 때 하나의 입력이 다운되면 다른 입력은 계속해서 데이터를 수집하고 실패한 입력에서로드를 인계함. 이렇게하면 여러 입력을 구성하여 동일한 버킷에서 데이터를 수집하여 내결함성을 향상시킬 수 있음.

SQS-Based S3 입력은 다음과 같은 유형의 S3 로그를 지원. **CloudTrail Logs, Config, S3 Access Logs, CloudFront Access Logs and ELB Access Logs**. 로그 파일의 위치는 입력이 SQS에서 검색하는 메시지에서 파생됨.

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 SQS-Based S3 입력을 구성.

- [Configure an SQS-based S3 input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input_using_Splunk_Web) (recommended)
- [Configure an SQS-based S3 input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input_using_configuration_file)

### Splunk Web을 사용하여 SQS-Based S3 Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > CloudTrail > SQS-based S3**
- **Create New Input > CloudFront Access Log > SQS-based S3**
- **Create New Input > Config > SQS-based S3**
- **Create New Input > ELB Access Logs > SQS-based S3**
- **Create New Input > S3 Access Logs > SQS-based S3**
- **Create New Input > Others > SQS-based S3**

수집할 데이터 유형에 해당하는 올바른 메뉴 경로를 선택했는지 확인. 시스템은 자동으로 적절한 sourcetype을 설정하며 메뉴 경로를 기반으로 후속 구성 페이지에 약간 다른 필드 설정을 표시 할 수 있음.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>Splunk 플랫폼이 S3 Bucket의 키에 액세스하는데 사용하는 AWS 계정 또는 EC2 IAM 역할을 Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나의 친숙한 이름이나 자동 검색된 EC2 IAM 역할의 이름을 입력.
참고 : 선택한 AWS 계정의 지역이 GovCloud 인 경우 S3 Bucket에 대한 옵션로드 실패와 같은 오류가 발생할 수 있음. S3 호스트 이름 필드에 AWS GovCloud Endpoint를 수동으로 추가해야 함. 자세한 내용은 http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html을 참조.
</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리</td></tr>
<tr><td>sqs_queue_region</td><td>AWS Region</td><td>SQS Queue에있는 AWS 지역. us-east-1.</td></tr>
<tr><td>sqs_queue_url</td><td>SQS Queue</td><td>The SQL queue URL.</td></tr>
<tr><td>sqs_batch_size</td><td>SQS Batch Size</td><td>하나의 배치에서 SQS Queue에서 가져올 최대 메시지 수. 1에서 10 사이의 정수를 입력. Splunk은 작은 파일에는 큰 값을, 큰 파일에는 작은 값을 설정하도록 권장. 기본 SQS 일괄 처리 크기는 10임. 대용량 파일을 처리하고 시스템 메모리가 제한되어있는 경우이 값을 더 작은 값으로 설정함.</td></tr>
<tr><td>s3_file_decoder</td><td>S3 File Decoder</td><td>해당 로그 파일을 구문 분석하는데 사용할 디코더. 디코더는 선택한 데이터 유형에 따라 설정됨. 사용자 정의 데이터 유형을 선택한 경우 Cloudtrail, Config, ELB Access Logs, S3 Access Logs, CloudFront Access Logs 중 하나를 선택.</td></tr>
<tr><td>sourcetype</td><td>Source Type</td><td>수집할 이벤트의 sourcetype으로 입력에 대해 선택된 디코더에 따라 자동으로 채워짐.</td></tr>
<tr><td>interval</td><td>Interval</td><td>두 데이터 수집 실행 사이의 시간(초). 기본값은 300 초임.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 SQS-Based S3 데이터를 넣어야하는 인덱스 이름임. 기본값은 main임.</td></tr>
</table>

### 구성 파일을 사용하여 SQS-Based S3 Input Configuration

inputs.conf에서 수동으로 입력을 구성 할 때 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

아래의 매개 변수를 구성 할 수 있음.

```properties
[aws_sqs_based_s3://<stanza_name>]
aws_account = <value>
interval = <value>
s3_file_decoder = <value>
sourcetype = <value>
sqs_batch_size = <value>
sqs_queue_region = <value>
sqs_queue_url = <value>
```

`s3_file_decoder '의 유효한 값은 CloudTrail, Config, S3 Access Logs, ELB Access Logs, CloudFront Access Logs 및 CustomLog임.

기본적으로 지원되는 다른 AWS 로그 유형을 사용자 정의 로그로 처리하려면 `s3_file_decoder = CustomLogs`를 설정해야 함. 이렇게하면 사용자 정의 로그를 Splunk로 처리 할 수 ​​있지만 데이터는 구문 분석하지 않음. 의미있는 이벤트로 커스텀 로그를 처리하려면 `props.conf`와 `transforms.conf`에서 추가 설정을 수행하여 수집 된 데이터를 분석하여 특정 요구 사항을 충족시켜야함.

이 설정에 대한 더 자세한 정보는 Add-on 디렉토리 아래의 `/ README/inputs.conf.spec`을보십시오.

### General S3 입력에서 SQS-Based S3 입력으로 마이그레이션

SQS-Based S3는 확장 가능하고 다른 S3 입력 유형보다 처리 성능이 뛰어 나기 때문에 S3 Bucket의 실시간 데이터 수집에 권장되는 입력 유형임.

이미 데이터를 수집하기 위해 General S3 입력을 사용하는 경우 다음 단계를 사용하여 SQS-Based S3 입력으로 전환함.

1. AWS 서비스의 필수 구성을 수행함.
    - dead-letter queue와 적절한 가시성 타임 아웃이 구성된 SQS queue를 설정함. [Configure SQS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 참조.
    - SQS Queue에 알림을 보내기 위해 데이터를 수집하는 S3 Bucket (지정된 경우 S3 키 접두사가있는)을 설정함. [Configure SNS](http://docs.splunk.com/Documentation/AddOns/released/AWS/ConfigureAWS#Configure_SQS) 참조.
2. 방금 구성한 SQS Queue을 사용하여 SQS-Based S3 입력을 추가. [Configure and SQS-based S3 input](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS-basedS3#Configure_an_SQS-based_S3_input) 참조. 설정 후 새 입력이 활성화되어 있는지 확인하고 버킷에서 데이터 수집을 시작함.
3. 기존 General S3 입력을 편집하고 **End Date/Time** 필드를 지금 (현재 시스템 시간)으로 설정하여 단계적으로 제거함.
4. 이전 입력의 모든 태스크 실행이 완료 될 때까지 기다리십시오. 가장 좋은 방법은 폴링 빈도의 두 배 이상을 기다리는 것임.
5. 이전 General S3 입력을 비활성화함.
6. 다음 검색을 실행하여 변환 중에 수집 된 중복 이벤트를 삭제.

CloudTrail 이벤트의 경우 :

```sql
index=xxx sourcetype=aws:cloudtrail | streamstats count by source, eventID | search count > 1 | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.eventID.indexed_time | table dup_id | outputcsv dupes.csv
```

```sql
index=xxx sourcetype=aws:cloudtrail | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.eventID.indexed_time | search [|inputcsv dupes.csv | format "(" "" "" "" "OR" ")"] | delete
```

S3 Access Logs :

```sql
index=xxx sourcetype=aws:s3:accesslogs | streamstats count by source, request_id | search count > 1 | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.request_id.indexed_time | table dup_id | outputcsv dupes.csv
```

```sql
index=xxx sourcetype=aws:s3:accesslogs | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.request_id.indexed_time | search [|inputcsv dupes.csv | format "(" "" "" "" "OR" ")"] | delete
```

CloudFront Access Logs의 경우 :

```sql
index=xxx sourcetype=aws:cloudfront:accesslogs | streamstats count by source, x_edge_request_id | search count > 1 | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.x_edge_request_id.indexed_time | table dup_id | outputcsv dupes.csv
```

```sql
index=xxx sourcetype=aws:cloudfront:accesslogs | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.x_edge_request_id.indexed_time | search [|inputcsv dupes.csv | format "(" "" "" "" "OR" ")"] | delete
```

classic load balancer (elb) access logs의 경우 :

이벤트에는 고유한 ID가 없기 때문에 해시 기능을 사용하여 중복을 제거함.

```sql
index=xxx sourcetype=aws:elb:accesslogs | eval hash=sha256(_raw) | streamstats count by source, hash | search count > 1 | eval indexed_time=strftime(_indextime, "%+") | eval dup_id=source.hash.indexed_time | table dup_id | outputcsv dupes.csv
```

```sql
index=xxx sourcetype=aws:elb:accesslogs
| eval hash=sha256(_raw)
| eval indexed_time=strftime(_indextime, "%+")
| eval dup_id=source.hash.indexed_time
| search [|inputcsv dupes.csv | format "(" "" "" "" "OR" ")"] | delete
```

선택적으로 기존의 General S3 입력을 삭제.

### SQS-Based S3 입력으로 Auto Scale 데이터 수집

SQS-Based S3 입력 유형을 사용하면 중복 이벤트를 생성하지 않고 동일한 S3 Bucket의 로그를 수집하도록 여러 입력을 구성하여 데이터 수집을 확장 할 수 있는 AWS 인프라의 자동 확장 기능을 최대한 활용할 수 있음. 이것은 매우 큰 S3 Bucket에서 로그를 수집하고 데이터 수집 입력에서 병목 현상이 발생한 경우 특히 유용함.

1. SQS-Based S3 입력이 실행되는 Heavy Forwarder 인스턴스에 대한 AWS 자동 확장 그룹을 만듬.
    자동 확장 그룹을 만들려면 실행 구성을 지정하거나 AMI를 만들어 Heavy Forwarder를 호스팅하는 새 EC2 인스턴스를 제공하고 부트 스트랩 스크립트를 사용하여 AWS 용 Splunk Add-on을 설치하고 SQS-Based S3 입력을 구성 할 수 있음. 자동 크기 조정 그룹 및 AWS 생성 방법에 대한 자세한 내용은 AWS 설명서 (<http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html>)를 참조.
2. 다음 Amazon SQS 메트릭 중 하나에 대한 CloudWatch 경보를 설정함.
    - ApproximateNumberOfMessagesVisible (권장) : 큐에서 검색 할 수 있는 메시지 수.
    - ApproximateAgeOfOldestMessage : 큐에 있는 가장 오래된 삭제되지 않은 메시지의 대략적인 경과 시간(초).
    Amazon SQS 메트릭에 대한 CloudWatch 경보 설정에 대한 지침은 AWS 설명서 (<http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQS_AlarmMetrics.html>)를 참조.
3. CloudWatch 경보를 트리거로 사용하여 SQS-Based S3 입력이 동일한 SQS Queue의 메시지를 소비하도록 구성된 새 Heavy Forwarder 인스턴스를 제공하여 처리 성능을 향상.

## Splunk Add-on for AWS에 대한 Billing Input Configuration

대금 청구 데이터를 수집하도록 대금 청구 입력을 구성 (sourcetype : `aws:billing`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 Billing 입력을 구성.

- [Configure a Billing input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Billing#Configure_a_Billing_input_using_Splunk_Web) (recommended)
- [Configure a Billing input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Billing#Configure_a_Billing_input_using_configuration_file)

> Note : Monthly 보고서와 Detailed 보고서를 모두 수집하려는 경우 두 개의 Billing 입력을 구성해야 함. 하나는 Monthly 보고서 용이고 다른 하나는 Detailed 보고서 용임. 이렇게하면, 두 리포트 유형 모두에 입력 한 값을 적용하지 않고 특정 리포트 유형에 대해 `interval`과`report_file_match_regex`를 설정할 수 있음.
> Note : Billing 입력을 구성한 후 데이터 수집 동작 및 Add-on에 포함 된 미리 구성된 보고서에 액세스하는 방법에 대한 자세한 내용은 [""Access billing data for the Splunk Add-on for AWS""](http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata) 참조.

### Splunk Web을 사용하여 Billing Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Billing** 클릭.

<table>
<tr><td>구성 파일의 인수</td><td>Splunk Web의 필드</td><td>설명</td></tr>
<tr><td colspan=3>AWS Input Configuration</td></tr>
<tr><td>aws_account</td><td>AWS account</td><td>Splunk 플랫폼에서 결제 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>가정 할 IAM 역할, IAM 역할 관리</td></tr>
<tr><td>bucket_name</td><td>S3 Bucket</td><td>The S3 bucket that is configured to hold billing reports.</td></tr>
<tr><td>monthly_report_type</td><td>Monthly report</td><td>Splunk 플랫폼이 AWS 계정에서 수집하는 Monthly 보고서 유형. 다음 값 중 하나를 입력.

- None
- Monthly report
- Monthly cost allocation report

</td></tr>
<tr><td>detail_report_type</td><td>Detailed report</td><td>Splunk 플랫폼이 AWS 계정에서 수집하는 Detailed 보고서 유형입니다. 다음 값 중 하나를 입력.

- None
- Detailed billing report
- Detailed billing report with resource and tags

</td></tr>
<tr><td colspan=3>Splunk-Related Configuration</td></tr>
<tr><td>initial_scan_datetime</td><td>Start Date/Time (UTC)</td><td>이 부가 기능은 이 시간 이후에 데이터를 수집하기 시작함. 이 필드를 공백으로두면 입력이 구성되기 전의 기본값이 90 일임.

> 참고 : 입력이 생성되면이 값을 변경할 수 없음.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>이벤트의 sourcetype. aws:billing의 기본값을 무시하려면 값을 지정함. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함.</td></tr>
<tr><td>index</td><td>Index</td><td>Splunk 플랫폼이 청구 데이터를 저장하는 인덱스 이름임. 기본값은 main임.</td></tr>
<tr><td colspan=3>Advanced Settings</td></tr>
<tr><td>interval</td><td>Interval</td><td>Splunk 플랫폼이 명령을 다시 실행하기 전에 기다리는 시간(초) 또는 유효한 cron 일정을 입력. 기본값은 86400 초 (하루)임. 이 간격은 Monthly 보고서 유형 및 Detailed 보고서 유형에 다르게 적용됨. Monthly 보고서 유형의 경우 간격은 현재 월간 월간 보고서의 데이터 수집 빈도 및 변경 전의 Monthly 보고서의 etag를 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 버전의 Monthly 보고서와 일치하지 않으면 최신 보고서를 다운로드하여 최신 데이터를 가져옵니다. Detailed 보고서 유형의 경우 간격은 이전 달의 상세 보고서 etag에서 변경 사항이 있는지 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 보고서와 일치하지 않으면 보고서를 다운로드하여 최신 데이터를 얻슴. 현재 월은 월이 끝날 때까지 수집되지 않음.
AWS 청구 보고서는 보통 월 말일 후 며칠까지 최종 확정되지 않으므로 cron 표현식 0 0 8-31 * *을 사용하여 매월 첫 7 일간 데이터 수집을 건너 뛰고 여러 사본을 수집하지 않도록 할 수 있음. 완료되지 않은 달에 대한 아직 완료되지 않은 보고서.</td></tr>
<tr><td>report_file_match_reg</td><td>Regex for report selection</td><td>
AWS의 보고서와 일치시키기 위해 Splunk 플랫폼이 사용하는 정규 표현식. 이 표현식은 monthly_report_type 및 detail_report_type 인수의 값을 대체함. 따라서 월 단위 및 상세 청구 보고서를 모두 수집하려고하지만 regex를 사용하여 보고서 수집 기간을 지정하려는 경우 두 개의 별도 청구 입력을 구성해야 여기서 지정한 정규식은 다음과 같은 보고서 유형 중 하나에만 적용됨. 당신은 수집하기를 원함.
이 정규식을 사용하여 필요하지 않은 데이터를 수집하지 않도록 보고서 수집을 특정 기간으로 제한함. 입력을 처음 사용하는 경우 특히 중요함. 기본적으로 Add-on은 이전 달의 모든 사용 가능한 보고서를 수집. 크기가 큰 상세 보고서를 수집하면 매우 많은 양의 데이터가 수집 될 수 있음. 수집 한 과거 데이터의 개월 수를 제한하고자 할 수 있음.
For example, you can use the expression \d+-aws-billing-detailed-line-items-201[56789]-\d+.csv.zip to collect only Detailed reports from January 2015 and later, or the expression \d+-aws-billing-detailed-line-items-with-resources-and-tags-2015-((0[4-9])|(10)|(11)|(12).csv.zip)|(\d+-aws-billing-detailed-line-items-with-resources-and-tags-201[6789]-\d+.csv.zip) to collect only the Detailed billing reports with resources and tags for April 2015 and later.
</td></tr>
<tr><td>temp_folder</td><td>Temp Folder</td><td>다운로드 된 세부 청구서 보고서 .zip 파일을 임시로 저장하기에 충분한 공간이있는 기본이 아닌 폴더의 전체 경로. 압축되지 않은 세부 청구서 보고서 파일의 예상 크기를 고려. 압축 파일의 크기보다 훨씬 클 수 있음. 임시 폴더를 지정하지 않으면 Add-on은 기본적으로 시스템 임시 폴더를 사용.</td></tr>
</table>

### 구성 파일을 사용하여 Billing Input Configuration

inputs.conf에 입력을 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf`에 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_billing://<name>]
aws_account = <value>
aws_iam_role=<value>
interval = <value>
initial_scan_datetime = <value>
bucket_name = <value>
detail_report_type = <value>
monthly_report_type = <value>
report_file_match_reg = <value>
sourcetype = <value>
index = <value>
host_name = s3.amazonaws.com
```

이러한 설정 중 일부는`$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_billing]
bucket_name =
aws_account =
monthly_report_type = Monthly cost allocation report
detail_report_type = Detailed billing report with resources and tags
report_file_match_reg =
interval = 86400
sourcetype = aws:billing
host_name = s3.amazonaws.com
```

위의 값은 Splunk Web의 기본값에 해당함. 이 스텐자를/local에 복사하여 inputs.conf를 수동으로 구성하기 위한 시작점으로 사용하려면 스탠자 제목을 aws_billing에서 `aws_billing://<name>`으로 변경

## Splunk Add-on for AWS에 대한 Cost and Usage Report Config input

Cost and Usage Report 데이터를 수집하도록 Billing 입력을 구성 (sourcetype :`aws:billing : cur`).

다음 방법 중 하나를 사용하여 데이터 수집 노드에서 비용 및 사용 보고서 입력을 구성.

- [Configure a Cost and Usage Report input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/BillingCostandUsage#Configure_a_Cost_and_Usage_Report_input_using_Splunk_Web) (recommended)
- [Configure a Cost and Usage Report input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/BillingCostandUsage#Configure_a_Cost_and_Usage_Report_input_using_configuration_file)

> AWS가 폴더로 보고서를 전달할 수 있도록 표식을 활성화 (폴더 이름은 접두사의 이름). 타임스탬프, 모든 보고서를 섭취하지 않으려는 경우 보고서 이름을 사용하여 결과를 필터링 할 수 있음.

비용 및 사용 보고서 입력을 구성한 후 자세한 내용은 [Access billing data for the Splunk Add-on for AWS](http://docs.splunk.com/Documentation/AddOns/released/AWS/AccessBillingReportdata) 참조. 데이터 수집 동작 및 Add-on에 포함 된 미리 구성된 보고서에 액세스하는 방법에 대해 설명함.

AWS 측면 구성 단계에 대한 자세한 내용은 AWS 설명서의 Cost and Usage Report 섹션을 참조.

### Splunk Web을 사용하여 Cost and Usage Report Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Billing > Billing (Cost and Usage Report)** 클릭.

<table>
<tr><td>Argument in configuration file</td><td>Field in Splunk Web</td><td>Description</td></tr>
<tr><td colspan=3>AWS Input Configuration</td></tr>
<tr><td>aws_account</td><td>AWS account</td><td>The AWS account or EC2 IAM role the Splunk platform uses to access your Billing data. In Splunk Web, select an account from the drop-down list. In inputs.conf, enter the friendly name of one of the AWS accounts that you configured on the Configuration page or the name of the autodiscovered EC2 IAM role.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>The IAM role to assume, see Manage IAM roles</td></tr>
<tr><td>bucket_name</td><td>S3 Bucket</td><td>The S3 bucket that is configured to hold billing reports.</td></tr>
<tr><td>bucket_region</td><td>S3 Bucket</td><td>The region location where the S3 bucket the is configured to hold billing reports.</td></tr>
<tr><td>report_prefix</td><td>Report Prefix</td><td>Prefices used to allow AWS to deliver the reports into a specified folder.</td></tr>
<tr><td>report_names</td><td>Report Name Pattern</td><td>A regular expression used to filter reports by name</td></tr>
<tr><td colspan=3>Splunk-Related Configuration</td></tr>
<tr><td>start_date</td><td>Start Date</td><td>This add-on starts to collect data later than this time. If you leave this field empty, the default value is 90 days before the input is configured.
Note: Once the input is created, this value cannot be changed.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>A source type for the events. Specify a value if you want to override the default of aws:billing. Event extraction relies on the default value of source type. If you change the default value, you must update props.conf as well.</td></tr>
<tr><td>index</td><td>Index</td><td>The index name where the Splunk platform puts the billing data. The default is main.</td></tr>
<tr><td colspan=3>Advanced Settings</td></tr>
<tr><td>interval</td><td>Interval</td><td>Enter the number of seconds to wait before the Splunk platform runs the command again, or a valid cron schedule. Default is 86400 seconds (one day). Note that this interval applies differently for monthly report types and detailed report types. For monthly report types, the interval indicates how often to run the data collection for the current month's monthly report AND how often to check the previous month's monthly report's etag to determine if changes were made. If the etag does not match an already-downloaded version of the monthly report, it will download that report to get the latest data. For detailed report types, the interval indicates how often to check the previous month's detailed report etag to determine if changes were made. If the etag does not match a report already downloaded, it will download that report to get the latest data -- the present month is never collected until the month has ended.
Because AWS billing reports are usually not finalized until several days after the last day of the month, you can use the cron expression 0 0 8-31 * * to skip data collection for the first seven days of every month to avoid collecting multiple copies of not-yet-finalized reports for the just-finished month.</td></tr>
<tr><td>temp_folder</td><td>Temp Folder</td><td>Full path to a non-default folder with sufficient space for temporarily storing downloaded detailed billing report .zip files. Take into account the estimated size of uncompressed detailed billing report files, which can be much larger than that of zipped files. If you do not specify a temp folder, the add-on will use the system temp folder by default.</td></tr>
</table>

<table>
<tr> <td> 구성 파일의 인수 </td> <td> Splunk Web의 필드 </td> </td> </tr>
<tr> <td colspan = 3> AWS Input Configuration </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼에서 결제 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. inputs.conf에 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<td> Bucket </td> <td> S3 Bucket </td> <td> 결제 보고서를 보관하도록 구성된 S3 Bucket </td> </tr>
<td> bucket_region </td> <td> S3 Bucket </td> <td> S3 Bucket이 청구 보고서를 보관하도록 설정된 지역 위치. </td> </tr>
<td> report_prefix </td> <td> 보고서 접두사 </td> <td> AWS가 보고서를 지정된 폴더로 전달할 수 있도록하는데 사용되는 접미어임. </td> </tr>
<td> report_names </td> <td> 리포트 이름 패턴 </td> </td> </td> 리포트를 이름별로 필터링하는데 사용되는 정규 표현식임.
<tr> <td colspan = 3> Splunk 관련 설정 </td> </tr>
<td> start_date </td> <td> 시작일 </td> <td>이 부가 기능은이 시간 이후에 데이터를 수집하기 시작함. 이 필드를 공백으로두면 입력이 구성되기 전의 기본값이 90 일임.
참고 : 입력이 생성되면이 값을 변경할 수 없음. </td> </tr>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:billing의 기본값을 무시하려면 값을 지정함. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함. </td> </tr>
<td> </td> <td> </td> <td> </td> <td> Splunk 플랫폼이 청구 데이터를 저장하는 인덱스 이름임. 기본값은 main임. </td> </tr>
<tr> <td colspan = 3> 고급 설정 </td> </tr>
Interval </td> <td> Splunk 플랫폼이 명령을 다시 실행하기 전에 기다리는 시간(초) 또는 유효한 cron 일정을 입력. 기본값은 86400 초 (하루)임. 이 간격은 Monthly 보고서 유형 및 Detailed 보고서 유형에 다르게 적용됨. Monthly 보고서 유형의 경우 간격은 현재 월간 월간 보고서의 데이터 수집 빈도 및 변경 전의 Monthly 보고서의 etag를 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 버전의 Monthly 보고서와 일치하지 않으면 최신 보고서를 다운로드하여 최신 데이터를 가져옵니다. Detailed 보고서 유형의 경우 간격은 이전 달의 상세 보고서 etag에서 변경 사항이 있는지 확인하는 빈도를 나타냅니다. etag가 이미 다운로드 한 보고서와 일치하지 않으면 보고서를 다운로드하여 최신 데이터를 얻슴. 현재 월은 월이 끝날 때까지 수집되지 않음.
AWS 청구 보고서는 보통 월 말일 후 며칠까지 최종 확정되지 않으므로 cron 표현식 0 0 8-31 * *을 사용하여 매월 첫 7 일간 데이터 수집을 건너 뛰고 여러 사본을 수집하지 않도록 할 수 있음. 완료되지 않은 달에 대한 아직 완료되지 않은 보고서. </td> </tr>
<td> temp_folder </td> <td> 임시 폴더 </td> <td> 다운로드 된 세부 청구서 보고서 .zip 파일을 임시로 저장하기에 충분한 공간이있는 기본이 아닌 폴더의 전체 경로. 압축되지 않은 세부 청구서 보고서 파일의 예상 크기를 고려. 압축 파일의 크기보다 훨씬 클 수 있음. 임시 폴더를 지정하지 않으면 Add-on은 기본적으로 시스템 임시 폴더를 사용. </td> </tr>
</table>

### 구성 파일을 사용하여 Cost and Usage Report Input Configuration

inputs.conf에 입력을 설정하려면 다음 템플릿을 사용하여 스탠자를 만들고 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/inputs.conf` 추가. 파일이나 경로가 없으면 만듬.

```properties
[aws_billing_cur://<name>]
start_by_shell = true
aws_account = <value>
aws_iam_role = <value>
bucket_name = <value>
bucket_region = <value>
report_names = <value>
report_prefix = <value>
start_date = <value>
temp_folder = <value>
host_name = s3.amazonaws.com
```

이러한 설정 중 일부는 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/default/inputs.conf`에서 찾을 수 있는 기본값을 가지고 있음 :

```properties
[aws_billing_cur]
start_by_shell = false
aws_account = <value>
aws_iam_role = <value>
bucket_name = <value>
bucket_region = <value>
report_names = <value>
report_prefix = <value>
start_date = <value>
temp_folder = <value>
```

위의 값은 Splunk Web의 기본값에 해당함. 이 스탠자를 `/local`에 복사하고 이것을 inputs.conf를 수동으로 설정하기 위한 시작점으로 사용하려면 스탠자 제목을 `aws_billing:cur`에서 `aws_billing:cur://<name>`으로 변경.

## Splunk Add-on for AWS을 위한 Kinesis Input Configuration

Kinesis는 VPC Flow Logs (sourcetype : `aws:cloudwatchlogs:vpcflow`)를 수집하기 위해 권장되는 입력 유형임. 또한이 입력 유형은 Kinesis Stream을 통한 사용자 정의 데이터 유형의 수집을 지원.

Splunk Web(권장) 또는 `local/aws_kinesis_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS에 대한 Kinesis 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#ak_region> AWS 설명서를 참조.

> 참고 : Kinesis 데이터 입력은 gzip 압축 또는 일반 텍스트 데이터 만 지원. 다른 인코딩으로 데이터를 가져올 수 없으며 동일한 입력에 gzip과 plaintext를 혼합하여 데이터를 가져올 수도 없음. gzip 데이터와 일반 텍스트 데이터에 대해 별도의 Kinesis 입력을 만듬.

다음 중 한 가지 방법을 사용하여 데이터 수집 노드에 Kinesis 입력을 구성.

- [Configure a Kinesis input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/Kinesis#Configure_a_Kinesis_input_using_Splunk_Web) (recommended)
- [Configure a Kinesis input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/Kinesis#Configure_a_Kinesis_input_using_configuration_file)

### Splunk Web을 사용하여 Kinesis Input Configuration

Splunk Web에서 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 수집할 데이터 유형에 따라 다음 메뉴 경로 중 하나를 선택.

- **Create New Input > VPC Flow Logs > Kinesis**
- **Create New Input > Others > Kinesis**

<table>
<tr><td>Argument</td><td>Corresponding Field in Splunk Web</td><td>Description</td></tr>
<tr><td>account</td><td>AWS Account</td><td>The AWS account or EC2 IAM role the Splunk platform uses to access your Kinesis data. In Splunk Web, select an account from the drop-down list. In aws_kinesis_tasks.conf, enter the friendly name of one of the AWS accounts that you configured on the Configuration page or the name of the autodiscovered EC2 IAM role.</td></tr>
<tr><td>aws_iam_role</td><td>Assume Role</td><td>The IAM role to assume, see Manage IAM roles</td></tr>
<tr><td>region</td><td>AWS Region</td><td>The AWS region that contains the Kinesis streams. In aws_kinesis_tasks.conf, enter the region ID. See the AWS documentation for more information.</td></tr>
<tr><td>stream_names</td><td>Stream Names</td><td>Stream names in a comma-separated list. Leave blank to collect all streams.</td></tr>
<tr><td>encoding</td><td>Encoding with</td><td>The encoding of the stream data. Set to gzip or leave blank, which defaults to Base64. All stream data that you collect in a single input must have the same encoding. If you are collecting VPC Flow Logs data through this input, encoding is typically gzip.</td></tr>
<tr><td>init_stream_position</td><td>Initial Stream Position</td><td>LATEST or TRIM_HORIZON. LATEST starts data collection from the point the input is enabled. TRIM_HORIZON starts collecting with the oldest data record.</td></tr>
<tr><td>format</td><td>Record Format</td><td>CloudWatchLogs or none. If you choose CloudWatchLogs, this add-on will parse the data in CloudWatchLogs format.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>A source type for the events.Enter aws:cloudwatchlogs:vpcflow if you are indexing VPC Flow Log data through Kinesis. Enter aws:kinesis if you are collecting any other Kinesis data.</td></tr>
<tr><td>index</td><td>Index</td><td>The index name where the Splunk platform puts the Kinesis data. The default is main.</td></tr>
</table>

<table>
<tr> <td> 인수 </td> </td> </td> </td>
<td> AWS 계정 </td> <td> Splines 플랫폼이 Kinesis 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_kinesis_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_iam_role </td> <td> 역할 가정 </td> <td> 가정 할 IAM 역할, IAM 역할 관리 </td> </tr>를 참조.
<tr> <td> region </td> <td> AWS Region </td> <td> Kinesis Stream이 포함 된 AWS 지역임. aws_kinesis_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조. </td> </tr>
<td> stream_names </td> <td> Stream 이름 </td> <td> 쉼표로 구분된 목록의 Stream 이름. 모든 Stream을 수집하려면 비워 두십시오. </td> </tr>
<tr> <td> encoding </td> <td> </td>를 사용한 인코딩 <td> Stream 데이터의 인코딩. gzip으로 설정하거나 공백으로 두십시오. 기본값은 Base64임. 단일 입력으로 수집하는 모든 Stream 데이터는 동일한 인코딩을 가져야함. 이 입력을 통해 VPC Flow Logs 데이터를 수집하는 경우 일반적으로 인코딩은 gzip임. </td> </tr>
<tr> <td> init_stream_position </td> <td> 초기 Stream 위치 </td> <td> LATEST 또는 TRIM_HORIZON. LATEST는 입력이 사용 가능한 지점에서 데이터 수집을 시작함. TRIM_HORIZON은 가장 오래된 데이터 레코드로 수집을 시작함. </td> </tr>
<tr> <td> 형식 </td> <td> 레코드 형식 </td> <td> CloudWatchLogs 또는 없음. CloudWatchLogs를 선택하면이 부가 기능이 CloudWatchLogs 형식의 데이터를 구문 분석함. </td> </tr>
<td> sourcetype </td> <td> 이벤트의 sourcetype임. Kinesis를 통해 VPC 플로우 로그 데이터를 인덱싱하는 경우 aws:cloudwatchlogs : vpcflow를 입력. 다른 Kinesis 데이터를 수집하는 경우 aws:kinesis를 입력. </td> </tr>
<td> Index </td> <td> Splunk 플랫폼이 Kinesis 데이터를 두는 인덱스 이름임. 기본값은 main임. </td> </tr>
</table>

### 구성 파일을 사용하여 Kinesis Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플리트를 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_kinesis_tasks.conf`를 작성.

```properties
[<name>]
account = <value>
aws_iam_role=<value>
region = <value>
stream_names = <value>
encoding = <value>
init_stream_position = <value>
format = <value>
sourcetype = <value>
index = <value>
```

다음은 해당 지역에서 사용 가능한 모든 Stream에 대해 Kinesis 데이터를 수집하는 예제 스탠자임.

```properties
[splunkapp2:us-east-1]
account = splunkapp2
region = us-east-1
encoding =
init_stream_position = LATEST
index = aws
format = CloudWatchLogs
sourcetype = aws:kinesis
```

## Splunk Add-on for AWS을 위한 SQS Input Configuration

Splunk Web(권장) 또는`local/aws_sqs_tasks.conf`를 통해 데이터 수집 노드에서 Splunk Add-on for AWS을 위한 SQS 입력을 구성. 이 데이터 소스는 AWS 영역의 하위 집합에서만 사용할 수 있음. 지원되는 전체 영역 목록은 <http://docs.aws.amazon.com/general/latest/gr/rande.html#inspector_region> AWS 설명서를 참조.

구성 옵션을 선택.

- [Configure an SQS input using Splunk Web](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS#Configure_an_SQS_input_using_Splunk_Web) (recommended)
- [Configure an SQS input using configuration file](http://docs.splunk.com/Documentation/AddOns/released/AWS/SQS#Configure_an_SQS_input_using_configuration_file)

### Splunk Web을 사용하여 SQS Input Configuration

Splunk Web을 사용하여 입력을 구성하려면 Splunk Web 홈의 왼쪽 탐색 모음에서 Splunk Add-on for AWS을 클릭한 다음 **Create New Input > Others > SQS**를 클릭.

<table>
<tr><td>Argument in inputs.conf</td><td>Field in Splunk Web</td><td>Description</td></tr>
<tr><td>aws_account</td><td>AWS Account</td><td>The AWS account or EC2 IAM role the Splunk platform uses to access your SQS data. In Splunk Web, select an account from the drop-down list. In aws_sqs_tasks.conf, enter the friendly name of one of the AWS accounts that you configured on the Configuration page or the name of the autodiscovered EC2 IAM role.</td></tr>
<tr><td>aws_region</td><td>AWS Region</td><td>The AWS region that contains the log notification SQS queue. In aws_sqs_tasks.conf, enter the region ID. See the AWS documentation for more information.</td></tr>
<tr><td>sqs_queues</td><td>SQS queues</td><td>The name of the queue to which AWS sends new SQS log notifications. In Splunk Web, you can select a queue from the drop-down list, if your account permissions allow you to list queues, or enter the queue name manually. The queue name is the final segment of the full queue URL. For example, if your SQS queue URL is http://sqs.us-east-1.amazonaws.com/123456789012/testQueue, then your SQS queue name is testQueue.
You can add multiple queues separated by commas.</td></tr>
<tr><td>sourcetype</td><td>Source type</td><td>A source type for the events. Enter a value only if you want to override the default of aws:sqs. Event extraction relies on the default value of source type. If you change the default value, you must update props.conf as well.</td></tr>
<tr><td>index</td><td>Index</td><td>The index name where the Splunk platform puts the SQS data. The default is main.</td></tr>
<tr><td>interval</td><td>Interval</td><td>The number of seconds to wait before the Splunk platform runs the command again. The default is 30 seconds.</td></tr>
</table>

<table>
<tr> <td> Splunk Web의 입력란 </td> <td> </td> </tr>
<td> aws_account </td> <td> AWS 계정 </td> <td> Splunk 플랫폼이 SQS 데이터에 액세스 할 때 사용하는 AWS 계정 또는 EC2 IAM 역할. Splunk Web의 드롭다운 목록에서 계정을 선택. aws_sqs_tasks.conf에서 구성 페이지에서 구성한 AWS 계정 중 하나 또는 자동 검색된 EC2 IAM 역할의 이름을 입력. </td> </tr>
<td> aws_region </td> <td> AWS 지역 </td> <td> 로그 알림 SQS Queue을 포함하는 AWS 지역. aws_sqs_tasks.conf에 지역 ID를 입력. 자세한 내용은 AWS 설명서를 참조. </td> </tr>
<td> sqs_queues </td> <td> SQS Queue </td> <td> AWS가 새 SQS 로그 통지를 보내는 대기열의 이름임. Splunk Web에서 계정 권한으로 대기열을 나열 할 수 있는 경우 드롭다운 목록에서 대기열을 선택하거나 수동으로 대기열 이름을 입력할 수 있음. 큐 이름은 전체 큐 URL의 마지막 세그먼트임. 예를 들어 SQS Queue URL이 http://sqs.us-east-1.amazonaws.com/123456789012/testQueue 인 경우 SQS Queue 이름은 testQueue임.
여러 큐를 쉼표로 구분하여 추가 할 수 있음. </td> </tr>
<td> sourcetype </td> <td> sourcetype </td> <td> 이벤트의 sourcetype. aws:sqs의 기본값을 무시하려는 경우에만 값을 입력. 이벤트 추출은 sourcetype의 기본값에 의존함. 기본값을 변경하면 props.conf도 함께 업데이트해야 함. </td> </tr>
<td> </td> <td> </td> <td> Splunk 플랫폼이 SQS 데이터를 저장하는 인덱스 이름. 기본값은 main임. </td> </tr>
Interval </td> <td> Splunk 플랫폼이 명령을 다시 실행하기까지 대기하는 시간(초). <tr> <td> interval </td> 기본값은 30 초임. </td> </tr>
</table>

### 구성 파일을 사용하여 SQS Input Configuration

구성 파일을 사용하여 입력을 구성하려면 다음 템플리트를 사용하여 `$SPLUNK_HOME/etc/apps/Splunk_TA_aws/local/aws_sqs_tasks.conf`를 작성.

```properties
[<name>]
aws_account = <value>
aws_region = <value>
sqs_queues = <value>
index = <value>
sourcetype = <value>
interval = <value>
```